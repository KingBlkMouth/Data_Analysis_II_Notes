{
  "hash": "7e005f8d7af4c8d6039bdb7a15e87049",
  "result": {
    "markdown": "---\ntitle: \"LearnR 5\"\nexecute: \n  freeze: auto\n---\n\n\n\n\n\n# Count responses\n\nPlease load these libraries that you'll need for this lab:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'arm' was built under R version 4.3.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: MASS\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lme4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\narm (Version 1.14-4, built: 2024-4-1)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWorking directory is C:/Users/cmeck/Desktop/D_Anal/Anal_II/Anal_II_Notes/Data_Analysis_II_Notes\n```\n:::\n\n```{.r .cell-code}\nlibrary(Sleuth3)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.3.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ dplyr::select() masks MASS::select()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(vcdExtra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'vcdExtra' was built under R version 4.3.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: vcd\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'vcd' was built under R version 4.3.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: grid\nLoading required package: gnm\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'gnm' was built under R version 4.3.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'vcdExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n```\n:::\n\n```{.r .cell-code}\nlibrary(magrittr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'magrittr'\n\nThe following object is masked from 'package:purrr':\n\n    set_names\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n:::\n:::\n\n\nIn this lab, we'll go over log linear regression in the case of count data in a little more detail than you saw in the narrated lectures. We'll cover the deviance goodness of fit test (which, remember, is an informal test here) and the drop in deviance test in R;  and we'll discuss residuals and model evaluation. You'll see more about over dispersion in the case of Poisson counts, and we'll cover the negative binomial model for over dispersion. We'll conclude with another example of log linear regression for general contingency tables.\n\n# Salamander Data\n\nThe data that we'll use for this lab concern salamander habitat:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ?case2202\nsalamanders <- case2202\nhead(salamanders)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| Site| Salamanders| PctCover| ForestAge|\n|----:|-----------:|--------:|---------:|\n|    1|          13|       85|       316|\n|    2|          11|       86|        88|\n|    3|          11|       90|       548|\n|    4|           9|       88|        64|\n|    5|           8|       89|        43|\n|    6|           7|       83|       368|\n\n</div>\n:::\n:::\n\n\nAs you can see (and read about in the help file) the `salamanders` data contain counts of salamanders at 47 sites in national forest and parkland; the available explanatory information is `PctCover`, a percentage of canopy cover at the site and `ForestAge`, the age of the forest at the site.  \n\n## Some data exploration\n\nWe'll start with some exploration of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = salamanders, aes(x = PctCover, y = Salamanders)) + geom_point() + ggtitle(\"Salamanders vs Percent Cover\")\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis first figure seems to indicate that there are two distinct types of sites---those with `PctCover` below about 53% and those with `PctCover` greater than 75%. It also seems clear that only sites with `PctCover` greater than 75% have `Salamander` counts higher than 2.\n\nHere's another plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = salamanders, aes(x = ForestAge, y = Salamanders)) + geom_point() + ggtitle(\"Salamanders vs Forest Age\")\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThere doesn't appear to be anything remarkable about this plot, though it's important to notice the range of the x-axis scale -- it's fairly large. This suggests that we might observe something more informative if we look at `ForestAge` on the log scale.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = salamanders, aes(x = log(ForestAge + 1/2), y = Salamanders)) + geom_point() + ggtitle(\"Salamanders vs log(Forest Age)\")\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nNotice that we used `x = log(ForestAge + 1/2)` in the `ggplot()` function call because some of the `ForestAge` values are zero, and `log(0)` is undefined.\n\nThis plot seems to indicate a clearer relationship between `ForestAge` and `Salamanders` -- as `ForestAge` increases on the log scale, the salamander counts tend to increase and they get more variable. Let's also look at the relationship between the two explanatory variables:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(ggplot(data = salamanders, aes(x = log(ForestAge + 1/2), y = PctCover)) + geom_point() + ggtitle(\"Percent Cover vs log(Forest Age\"))\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThis plot tells and interesting story -- almost all of the older sites are those with `PctCover` greater than 75%. For the younger sites, there is a increasing (perhaps curvilinear) relationship with `PctCover`.\n\nRemember that multicollinearity is a problem when two or more explanatory variables are highly correlated. Let's check the correlation between log-transformed `PctCover` and the `ForestAge` variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalamanders %<>% mutate(Site = Site, Salamanders = Salamanders, ForestAge = ForestAge, logPctCover = log(PctCover + 1/2))\ncor(salamanders$ForestAge,salamanders$logPctCover)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5352604\n```\n:::\n:::\n\n\nThe correlation is not actually so high that we should be concerned about it. Remember, too, that correlation tells us about the *linear* association between two variables. In terms of a linear association, these two variables are moderately correlated -- even though from our last plot we see that there is a strong relationship between them.\n\nBecause of the distinctive cut-point in the `PctForest` variable, we'll create a new variable, called `CovGroup`, that just takes the value 0 if `PctCover < 75)` and 1 otherwise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalamanders$CovGroup <- ifelse(salamanders$PctCover < 75,0,1)\n```\n:::\n\n\nFinally, as a last bit of exploration, let's just take a look at the histogram of `Salamander` counts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(salamanders,aes(Salamanders)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nYou can see that there are a lot of zeroes in among the `Salamander` counts. One method for analyzing Poisson count data is to take the log of the counts, and then perform a multiple linear regression. We don't recommend that here, since there are so many zeroes -- you'd have to first add a small amount to the zero counts, then take logs, and that means that interpretations will be difficult.\n\nInstead, we'll turn to fitting the log linear model (another special case of a generalized linear model).\n\n# The Log Linear Model\n\nRemember that for independent Poisson counts, $Y_1,\\ldots,Y_n$, each with rate parameter $\\lambda_i$ for $i = 1,\\ldots,n$, we have\n\n> $log(\\lambda_i) = \\beta_0 + \\beta_1X_{1i} + \\cdots + \\beta_kX_{ki}$\n\nfor explanatory variables, $X_1,\\ldots,X_k$. Let's go ahead and fit some models to the `salamander` data.\n\n## Model Fitting \n\nIn this part of the lab, we'll fit several different models, and make some comparisons among them. This is a little bit of data snooping, and we will likely end up with biased estimates in the model we do select (recall the simulation you saw back in Data Analytics I). So, please, consider this to be the academic exercise it's intended to be! \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model with PctCover only\npois_mod1 <- glm(data = salamanders, Salamanders ~ PctCover, family = poisson)\n\n# model the log(Forest Age + 1/2) only\npois_mod2 <- glm(data = salamanders, Salamanders ~ log(ForestAge + 1/2), family = poisson)\n\n# model with both explanatory variables\npois_mod3 <- glm(data = salamanders, Salamanders ~ PctCover + log(ForestAge + 1/2), family = poisson)\n\n# model with both explanatory variables, plus their interaction\npois_mod4 <- glm(data = salamanders, Salamanders ~ PctCover * log(ForestAge + 1/2), family = poisson)\n\n# comparison of the models\nLRstats(pois_mod1, pois_mod2, pois_mod3, pois_mod4)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|          |      AIC|      BIC| LR Chisq| Df| Pr(>Chisq)|\n|:---------|--------:|--------:|--------:|--:|----------:|\n|pois_mod1 | 210.3639| 214.0642| 121.3050| 45|          0|\n|pois_mod2 | 243.1239| 246.8242| 154.0650| 45|          0|\n|pois_mod3 | 212.0690| 217.6195| 121.0101| 44|          0|\n|pois_mod4 | 213.7578| 221.1584| 120.6989| 43|          0|\n\n</div>\n:::\n:::\n\n\nIn terms of the AIC comparisons, there's not much difference between models 1, 2 and 4; and the same is true if we use the BIC comparisons. This is somewhat surprising -- from the exploratory plots above, you might have suspected that both `PctCover` and `ForestAge`, and maybe even their interaction might be important. Let's take a look at the summary information for `pois_mod4`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(pois_mod4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Salamanders ~ PctCover * log(ForestAge + 1/2), \n    family = poisson, data = salamanders)\n\nCoefficients:\n                               Estimate Std. Error z value Pr(>|z|)   \n(Intercept)                   -0.969454   0.820929  -1.181  0.23763   \nPctCover                       0.029067   0.011184   2.599  0.00935 **\nlog(ForestAge + 1/2)          -0.213107   0.293009  -0.727  0.46704   \nPctCover:log(ForestAge + 1/2)  0.001957   0.003423   0.572  0.56741   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 190.22  on 46  degrees of freedom\nResidual deviance: 120.70  on 43  degrees of freedom\nAIC: 213.76\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\nIt looks like there pretty clear evidence of over dispersion, the residual deviance divided by the residual degrees of freedom is\n\n\n::: {.cell}\n\n```{.r .cell-code}\n120.7/43\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.806977\n```\n:::\n:::\n\n\nThat's pretty big. Before we talk a lot more about model fitting and model comparison in terms of what explanatory information to include, we should address the over dispersion. Remember that we can do this using the `family = quasipoisson` argument to the `glm()` function, or we can do this using the `glm.nb` function. We'll leave it to you to try the quasi-poisson approach, and we'll go over the negative binomial approach here. We'll simply fit the same four models as above, but using the negative binomial likelihood rather than the Poisson likelihood.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model with PctCover only\nnb_mod1 <- glm.nb(data = salamanders, Salamanders ~ PctCover)\n\n# model the log(Forest Age + 1/2) only\nnb_mod2 <- glm.nb(data = salamanders, Salamanders ~ log(ForestAge + 1/2))\n\n# model with both explanatory variables\nnb_mod3 <- glm.nb(data = salamanders, Salamanders ~ PctCover + log(ForestAge + 1/2))\n\n# model with both explanatory variables, plus their interaction\nnb_mod4 <- glm.nb(data = salamanders, Salamanders ~ PctCover * log(ForestAge + 1/2))\n\n# comparison of the models\nLRstats(nb_mod1, nb_mod2, nb_mod3, nb_mod4)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|        |      AIC|      BIC| LR Chisq| Df| Pr(>Chisq)|\n|:-------|--------:|--------:|--------:|--:|----------:|\n|nb_mod1 | 176.9625| 182.5130| 47.60608| 45|  0.3670830|\n|nb_mod2 | 188.2859| 193.8363| 47.99615| 45|  0.3523296|\n|nb_mod3 | 178.8296| 186.2302| 47.56748| 44|  0.3295507|\n|nb_mod4 | 180.5434| 189.7941| 47.48537| 43|  0.2948841|\n\n</div>\n:::\n:::\n\n\nAgain, there's no clear winner here in terms of either AIC or BIC, so we'll go with Occam's Razor and look at results for the simplest model, `nb_mod1`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(nb_mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm.nb(formula = Salamanders ~ PctCover, data = salamanders, \n    init.theta = 1.26199236, link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.416365   0.527696  -2.684  0.00727 ** \nPctCover     0.031513   0.006655   4.735 2.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.262) family taken to be 1)\n\n    Null deviance: 75.691  on 46  degrees of freedom\nResidual deviance: 47.606  on 45  degrees of freedom\nAIC: 176.96\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.262 \n          Std. Err.:  0.478 \n\n 2 x log-likelihood:  -170.963 \n```\n:::\n:::\n\n\nRemember that we still didn't use the `CovGroup` indicator variable that we created above. Let's fit a couple more models using that variable, and see where we are.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model with CovGroup only \nnb_mod5 <- glm.nb(data = salamanders, Salamanders ~ CovGroup)\n\n# model with CovGroup*log(ForestAge + 1/2)\nnb_mod6 <- glm.nb(data = salamanders, Salamanders ~ CovGroup * log(ForestAge + 1/2))\n\n# compare with the other models\nLRstats(nb_mod1,nb_mod2,nb_mod3,nb_mod4,nb_mod5,nb_mod6)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|        |      AIC|      BIC| LR Chisq| Df| Pr(>Chisq)|\n|:-------|--------:|--------:|--------:|--:|----------:|\n|nb_mod1 | 176.9625| 182.5130| 47.60608| 45|  0.3670830|\n|nb_mod2 | 188.2859| 193.8363| 47.99615| 45|  0.3523296|\n|nb_mod3 | 178.8296| 186.2302| 47.56748| 44|  0.3295507|\n|nb_mod4 | 180.5434| 189.7941| 47.48537| 43|  0.2948841|\n|nb_mod5 | 176.7513| 182.3018| 47.17214| 45|  0.3838253|\n|nb_mod6 | 180.7331| 189.9838| 47.16892| 43|  0.3060094|\n\n</div>\n:::\n:::\n\n\nNow it seems like there's really not much difference among any of these models (except that many `nb_mod2` is a clear-ish loser) in terms of AIC or BIC. We'll continue with `nb_mod1` at this point. Let's take a look at the model and it's fit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(nb_mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm.nb(formula = Salamanders ~ PctCover, data = salamanders, \n    init.theta = 1.26199236, link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.416365   0.527696  -2.684  0.00727 ** \nPctCover     0.031513   0.006655   4.735 2.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.262) family taken to be 1)\n\n    Null deviance: 75.691  on 46  degrees of freedom\nResidual deviance: 47.606  on 45  degrees of freedom\nAIC: 176.96\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.262 \n          Std. Err.:  0.478 \n\n 2 x log-likelihood:  -170.963 \n```\n:::\n\n```{.r .cell-code}\nsalamanders$resid <- residuals(nb_mod1)\nfits <- predict.glm(nb_mod1,scale=\"data\",se.fit=TRUE)\nsalamanders$fits <- exp(fits$fit)\nsalamanders$low <- exp(fits$fit-1.96*fits$se.fit)\nsalamanders$upp <- exp(fits$fit+1.96*fits$se.fit)\nggplot(salamanders,aes(PctCover,Salamanders)) + geom_point() +      \n  geom_line(aes(x = PctCover, \n                 y = fits)) + \n  geom_ribbon(aes(x = PctCover, \n                  ymin = low, \n                  ymax = upp),\n                  alpha = 0.2)\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nThe model fit is not bad -- remember that the solid line in the figure above is the model estimate of the Poisson rate parameter at each value of `PctCover`, and the shaded bands are 95% pointwise confidence intervals. The model output gives strong evidence of a positive association between `PctCover` and the number of salamanders at a site. \n\nNotice also that the residual deviance divided by its degrees of freedom for `nb_mod1` is very close to 1. The negative binomial model also gives an estimate of the \"Theta\" parameter.  In the negative binomial model, if the expected count is $E(Y)$, the variance of the count is $Var(Y) = E(Y) + [E(Y)^2]/\\theta$.\n\nSince the negative binomial model uses the log-link as does the Poisson model, the interpretation of the coefficient on `PctCover` is the same as in the Poisson model -- an increase of 1% in forest cover is associated with an $exp(0.0315) = 1.03$-fold increase in the expected number of salamanders.  In other words, a 1% increase in forest cover is associated with a 3% increase in expected number of salamanders at a site.  \n\n## Model Evaluation\n\nRecall that the deviance goodness of fit test compares a fitted model to a saturated model, or one in which there are as many parameters as there are data points. In these goodness of fit comparisons, the null hypothesis corresponds to the fitted model (which is a reduced model relative to the saturated model), and the alternative hypothesis corresponds to the saturated model. In the case of Poisson counts, the goodness of fit should only be used as a guideline, not as a firm decision making tool.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLRstats(nb_mod1)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|        |      AIC|     BIC| LR Chisq| Df| Pr(>Chisq)|\n|:-------|--------:|-------:|--------:|--:|----------:|\n|nb_mod1 | 176.9625| 182.513| 47.60608| 45|   0.367083|\n\n</div>\n:::\n:::\n\n\nThis large p-value may be an indication of an adequate model, but there are many small counts in the `salamanders` data, so we should not rely heavily on this result. \n\n## Drop-in-deviance test\n\nJust a reminder that the drop in deviance test is different from the deviance goodness of fit test. Whereas the deviance goodness of fit test provides a comparison between a single fitted model and a saturated model, a drop in deviance test provides a way to compare two fitted models when one of those models is nested within the other one. Put another way, the drop in deviance test is a comparison between a reduced model (null hypothesis) and a full model (alternative hypothesis) -- and we use it in cases where the reduced model is reduced from (or nested in) the full model.\n\nUsing the models we have already fit, let's use the `anova()` function to perform a drop in deviance test comparing the model that only contains `PctCover` to the one that contains `PctCover`, `ForestAge` and their interaction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(nb_mod1,nb_mod4,test=\"Chisq\")\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Model                           |    theta| Resid. df|    2 x log-lik.|Test   |    df| LR stat.|   Pr(Chi)|\n|:-------------------------------|--------:|---------:|---------------:|:------|-----:|--------:|---------:|\n|PctCover                        | 1.261992|        45|       -170.9625|       |    NA|       NA|        NA|\n|PctCover * log(ForestAge + 1/2) | 1.279151|        43|       -170.5434|1 vs 2 |     2| 0.419181| 0.8109163|\n\n</div>\n:::\n:::\n\n\nThe p-value of the drop in deviance test is rather large, giving us strong evidence that the simpler model is sufficient in this case, as compared to the more complicated model.\n\n## Looking at Residuals\n\nAs in the case of binomial logistic regression, it can be helpful to look at the deviance and/or Pearson residuals from our negative binomial (or Poisson) regression mode to (a) evaluate the model fit and (b) check for outliers. Provided that the counts are fairly large, both the deviance and Pearson residuals should look like draws from a standard Normal distribution, so too many residuals outside of the [-2,2] interval may be cause for concern. Here, we'll look at plots of both the deviance and Pearson residuals.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalamanders$residuals_deviance <- residuals(nb_mod1)\nsalamanders$residuals_pearson <- residuals(nb_mod1, type = \"pearson\")\nggplot(data = salamanders, aes(PctCover,residuals_deviance)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = salamanders, aes(PctCover,residuals_pearson)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-19-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = salamanders, aes(residuals_deviance,residuals_pearson)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](z5_learnR_files/figure-html/unnamed-chunk-19-3.png){width=672}\n:::\n:::\n\n\nFirst, you should notice that there are some distinctive patterns in both the deviance and Pearson residual plots. These kinds of patterns are quite common when we are dealing with count data, and they are result of the discreteness of those counts. In these residual plots, we are more concerned with detecting potential outliers, and there do not appear to be any here.\n\nNext, the plot of the two types of residuals against each other shows the strong relationship between them -- in this case it's not a linear relationship as it was in the case of binomial logistic regression -- but it's a strong relationship nonetheless.\n\n# Log Linear Models for General Contingency Tables\n\nWe'll now turn to an example of using a log linear model for data in general contingency tables. The following table relates education level, religious views, and approval of homosexual marriage for 133 Americans age 18-25 (see example 8.4.2 in Agresti (2013)). In this table \"agree\" indicates that the respondent agrees that homosexual marriage should be allowed in the US.    \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmarriage <- expand.grid(\n  opinion = factor(c(\"Agree\", \"Neutral\", \"Disagree\"), levels = c(\"Agree\", \"Neutral\", \"Disagree\")),\n  relig = factor(c(\"Fundamentalist\", \"Moderate\", \"Liberal\"), c(\"Liberal\", \"Moderate\", \"Fundamentalist\")),\n  educ = factor(c(\"High school or less\", \"At least some college\"), c(\"High school or less\", \"At least some college\"))) \nmarriage$Freq <- c(  6,2,10,8,3,9,11,5,6,4,2,11,21,3,5,22,4,1)\nmarriage_tab <- xtabs(data = marriage, Freq ~ educ + relig + opinion)\nftable(marriage_tab)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                     opinion Agree Neutral Disagree\neduc                  relig                                        \nHigh school or less   Liberal                   11       5        6\n                      Moderate                   8       3        9\n                      Fundamentalist             6       2       10\nAt least some college Liberal                   22       4        1\n                      Moderate                  21       3        5\n                      Fundamentalist             4       2       11\n```\n:::\n:::\n\n\nIf we just think about questions regarding whether and how these three variables are related, we can fit a log linear model, with the count frequencies as the responses, and the levels of three factors as explanatory information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_relig <- glm(data = marriage_tab, Freq ~ relig + educ + opinion, family = poisson)\nsummary(mod_relig)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Freq ~ relig + educ + opinion, family = poisson, \n    data = marriage_tab)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                2.482e+00  1.895e-01  13.095  < 2e-16 ***\nreligModerate             -5.009e-15  2.020e-01   0.000   1.0000    \nreligFundamentalist       -3.365e-01  2.213e-01  -1.520   0.1284    \neducAt least some college  1.961e-01  1.743e-01   1.125   0.2604    \nopinionNeutral            -1.332e+00  2.579e-01  -5.165  2.4e-07 ***\nopinionDisagree           -5.390e-01  1.942e-01  -2.776   0.0055 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 72.362  on 17  degrees of freedom\nResidual deviance: 34.930  on 12  degrees of freedom\nAIC: 111.43\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\nThe results of this model seem to indicate that the only factor that is associated with variation in the table frequencies is the opinion regarding gay marriage. What about the association questions?  \n\n# Lab 5 Assignment \n\n## Questions\n\n1. Fit a model to the gay marriage data that includes all two-way interactions. What do you conclude from this model? Be specific and try to address questions having to do with the association among the three variables.\n\n2. Fit a model that includes all two-way and the three-way interactions. Is there anything problematic about this model? Please explain.\n",
    "supporting": [
      "z5_learnR_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}