[
  {
    "objectID": "z8_learnR.html",
    "href": "z8_learnR.html",
    "title": "LearnR 8",
    "section": "",
    "text": "The topic of this lab is prediction in the generalized linear modeling setting. We’ll first talk about prediction (or classification) in the case of binary categories, and then about classification into \\(k\\) categories. We’ll also talk about prediction in the case of responses that are counts.\nWe’ll look at some R functions that perform cross-validation, and we’ll discuss issues of model comparison on the basis of prediction error.\nTo start off, please load these libraries that you’ll need for this lab. Note that you may have to install some of these packages first.\nlibrary(tidyverse)\nlibrary(openintro) # contains email data\nlibrary(ggplot2)\nlibrary(vcdExtra)\nlibrary(magrittr)\nlibrary(MASS)\nlibrary(lme4)     # access the mixed functions\nlibrary(VGAM)     # contains crash data\nlibrary(tree)     # for classification trees\nlibrary(pROC)     # ROC curves   \nlibrary(boot)     # contains the cv.glm function"
  },
  {
    "objectID": "z8_learnR.html#binary-predictionclassification",
    "href": "z8_learnR.html#binary-predictionclassification",
    "title": "LearnR 8",
    "section": "Binary Prediction/Classification",
    "text": "Binary Prediction/Classification\nWe will use the tree package in R for this part of the lab.\nNote: the email data set has some missing values, which we will ignore to save time. This admittedly is not the wisest thing to do: with an important dataset, you must consider why there are missing values, and take action accordingly. At the very least, in a report, you should tell your readers that you built your model ignoring missing values in the data set.\nFirst, let’s again use 75% of the data for training the model and use the remaining 25% for testing the model that we build, as you saw in the narrated lecture about the Classifier.Rmd code.\n\nset.seed(90210) ## so you get the same results I do\n(n &lt;- dim(email)[1])\n\n[1] 3921\n\n(r &lt;- round(n * .75))\n\n[1] 2941\n\nidx &lt;- 1:n\nnidx &lt;- sample(idx, r, replace = FALSE)\nemail75 &lt;- email[nidx, ]\nemail25 &lt;- email[-nidx, ]\n\nThe tree function follows the same form as a linear regression model: we give the function the response variable to the left of ~ and specify it as a factor so the function knows that the response is not numeric, and then we put all of the predictors to the right of ~.\n\ntr &lt;- tree(as.factor(spam) ~  to_multiple + from + cc + sent_email + \n             image + attach + dollar + winner + inherit +\n             viagra + password + num_char + line_breaks + format +\n             re_subj + exclaim_subj + urgent_subj + exclaim_mess +number, data = email75)\nsummary(tr)\n\n\nClassification tree:\ntree(formula = as.factor(spam) ~ to_multiple + from + cc + sent_email + \n    image + attach + dollar + winner + inherit + viagra + password + \n    num_char + line_breaks + format + re_subj + exclaim_subj + \n    urgent_subj + exclaim_mess + number, data = email75)\nVariables actually used in tree construction:\n[1] \"line_breaks\" \"sent_email\"  \"num_char\"    \"to_multiple\" \"winner\"     \n[6] \"dollar\"      \"format\"      \"number\"     \nNumber of terminal nodes:  14 \nResidual mean deviance:  0.366 = 1071 / 2927 \nMisclassification error rate: 0.08296 = 244 / 2941 \n\n\nThe summary information tells us that there were 8 variables that the function decided were “important” to include in the prediction model: line_breaks, sent_email, num_char, to_multiple, winner, dollar, format, and number (you can see these below the line that says Variables actually used in tree construction in the output above). We also see that on the training data the final tree misclassifies 8.296% of the emails. Let’s plot the tree to have a better idea about how the splits are made.\n\nplot(tr); text(tr)\n\n\n\n\n\n\n\n\nIf you zoom in on the plot above, you can better see what is happening. All emails are classified as not spam except at 5 of the nodes of the tree. Fr example, starting from the base of the tree, if there are less than 49.5 line breaks, the sent_email variable is 0, and the num_char variable is less than 0.7105, then the model calls the email spam. See if you can trace down to the other 4 nodes on the tree to see what other types of emails the model is classifying as spam.\nLet’s now use our the model suggested by tree to make predictions on the test data:\n\nemail.noresp &lt;- email25[, -1] ## dropping the response variable\nmod1 &lt;- glm(spam~line_breaks+sent_email+num_char+to_multiple+format,data=email75,family=\"binomial\")\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\npredictions &lt;- predict(mod1, email.noresp, type = \"link\")\nphats &lt;- plogis(predictions)\n\nNow, let’s take a look at the ROC Curve for this predictive model and see if we can decide on a good classification rule.\n\nroc(email25$spam,phats,plot=T)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\n\n\n\n\n\n\n\n\n\nCall:\nroc.default(response = email25$spam, predictor = phats, plot = T)\n\nData: phats in 892 controls (email25$spam 0) &lt; 88 cases (email25$spam 1).\nArea under the curve: 0.8432\n\n\nIt looks like we can simultaneously maximize specificity and sensitivity if we take the classification cutoff value to be around 0.75 – that is, we’ll classify an email as spam if \\(\\hat{p} \\ge 0.75\\). Then, we can use that to calculate the MSPE.\n\npreds &lt;- ifelse(phats&gt;=0.75,1,0)\n(MSPE &lt;- mean((as.integer(email25$spam) - preds -1)^2))\n\n[1] 0.08979592\n\n\nWe get a MSPE of 0.090. Note that this is slightly higher than the model misclassification rate from the summary(tr). This is typical, as the misclassification rate on the training data should be lower since the training data has an advantage over the test data in that the model is built using the training data.\nThis MSPE is quite similar to the value we calculated for several models in the narrated lectures, indicating that none of these models would necessarily be preferable. Please note that the models that we used in the narrated lectures were trained and tested on a different random split of the data. If we were truly comparing models, we should sure the we used the same training data and test data. The main advantage of the classification tree is its ease of interpretation, especially to someone who might not be familiar with statistics.\n\nWe find the classification tree to be a reasonable way to find a model with good predictive properties. There are certainly other methods of model selection that you can use."
  },
  {
    "objectID": "z8_learnR.html#classification-into-k-categories",
    "href": "z8_learnR.html#classification-into-k-categories",
    "title": "LearnR 8",
    "section": "Classification into \\(k\\) Categories",
    "text": "Classification into \\(k\\) Categories\nClassification trees extend very nicely to incorporating a response variable with more than 2 categories. On the other hand, if taking a more regression oriented approach, we would have to learn multinomial regression. It might not be a bad idea to familiarize yourself with multinomial regression, but the remainder of this section of lab will use classification trees instead.\nTo save the time of looking at a new data set, we will actually just use the email data set again. Now suppose that we want to classify whether emails contain no numbers, a small number, or a big number. I’ll leave it to your own imagination as to why we would want to classify emails into these three categories. Then we will use all of the other variables in the email data set as possible predictors.\nLet’s re-select training and test sets:\n\nset.seed(773355) ## so you get the same results I do\n(n &lt;- dim(email)[1])\n\n[1] 3921\n\n(r &lt;- round(n * .75))\n\n[1] 2941\n\nidx &lt;- 1:n\nnidx &lt;- sample(idx, r, replace = FALSE)\nemail75 &lt;- email[nidx, ]\nemail25 &lt;- email[-nidx, ]\n\nNow, we’ll run the classification tree algorithm using as.factor(number) as the response.\n\ntr2 &lt;- tree(as.factor(number) ~ spam + \n        to_multiple + from + cc + sent_email +\n        image + attach + dollar + winner + inherit +\n        viagra + password + num_char + line_breaks + format +\n        re_subj + exclaim_subj + urgent_subj + exclaim_mess, data = email75)\nsummary(tr2)\n\n\nClassification tree:\ntree(formula = as.factor(number) ~ spam + to_multiple + from + \n    cc + sent_email + image + attach + dollar + winner + inherit + \n    viagra + password + num_char + line_breaks + format + re_subj + \n    exclaim_subj + urgent_subj + exclaim_mess, data = email75)\nVariables actually used in tree construction:\n[1] \"line_breaks\" \"num_char\"    \"re_subj\"     \"spam\"        \"to_multiple\"\n[6] \"format\"     \nNumber of terminal nodes:  8 \nResidual mean deviance:  1.19 = 3490 / 2933 \nMisclassification error rate: 0.2414 = 710 / 2941 \n\n\n\nplot(tr2); text(tr2)\n\n\n\n\n\n\n\n\nWhen zooming in the plot, we see that the model will not classify any emails as containing a big number, but will for instance classify an email as containing no numbers when the number of line breaks is less than 65.5 and the number of characters is less than 0.5315. You can trace the other branches of the tree to see when emails will be classified as having a small number or having no numbers. The misclassification rate is 0.241.\nIn this approach, we’ll just use the default classification rule for tree objects in the predict.tree function:\n\npredictions &lt;- predict(tr2, email25, type = \"class\")\n\nHere, let’s calculate the misclassification rate – we’ll just sum up the number of times the predicted classification does not match the classification in the email25 data.\n\nsum(predictions != email25$number) / length(predictions)\n\n[1] 0.2285714\n\n\nThe misclassification rate is 0.229, which is actually quite similar to the misclassification rate provided in the output of the summary for the training data for this particular response. While this is unusual, it is not impossible: perhaps in this case, the test data set was just relatively easy to predict.\nWe will stop here with classification, but you can imagine a few extensions. What if we care more about an email being misclassified as having no numbers than an email being misclassified as having a large number? Then we might want to change our model to reflect this preference."
  },
  {
    "objectID": "z6_learnR.html",
    "href": "z6_learnR.html",
    "title": "6 Zero Inflation",
    "section": "",
    "text": "Please load these libraries that you’ll need for this lab:\n\nlibrary(arm)\nlibrary(Sleuth3)\nlibrary(tidyverse)\nlibrary(vcdExtra)\nlibrary(magrittr)\nlibrary(MASS)\nlibrary(pscl)\nlibrary(VGAM)\n\nIn this lab, we’ll cover some more details about zero-inflated and hurdle models. We will discuss why zero-inflated models are sometimes needed, the difference between zero-inflated models and hurdle models, how to compare various types of fitted models, and how to check residuals to assess model assumptions."
  },
  {
    "objectID": "z6_learnR.html#some-data-exploration",
    "href": "z6_learnR.html#some-data-exploration",
    "title": "6 Zero Inflation",
    "section": "Some data exploration",
    "text": "Some data exploration\n\n# ?quine\nschools &lt;- quine\nhead(schools)\n\n\n\n\n\nEth\nSex\nAge\nLrn\nDays\n\n\n\n\nA\nM\nF0\nSL\n2\n\n\nA\nM\nF0\nSL\n11\n\n\nA\nM\nF0\nSL\n14\n\n\nA\nM\nF0\nAL\n5\n\n\nA\nM\nF0\nAL\n5\n\n\nA\nM\nF0\nAL\n13\n\n\n\n\n\n\nFor each child in the data set, we have information on the child’s Ethnicity, Sex, Age, Learning Disability Status, and Days absent from school (which we will treat as the response variable). All of the explanatory variables are categorical with two categories each, except for Age which has four categories.\nWe’ll start with some exploration of the data.\n\nggplot(data = schools, aes(x = Days, y = after_stat(density))) +\n    geom_histogram(bins = 12, colour = \"black\", fill = \"white\") +\n    ggtitle(\"Days Absent from School\")\n\n\n\n\n\n\n\n\nYou can see from the histogram above that most of the children only missed between 5 and 10 days of school. However, there are perhaps more 0’s than we would expect from a standard Poisson or Negative Binomial Model. It’s rather difficult to tell what will be the best model for these data just based on this simple histogram, but we will investigate the various models proposed in lecture throughout the rest of the lab.\nNext, let’s next create some side-by-side boxplots to explore how each of the categorical explanatory variables is associated with the response.\n\nggplot(data = schools, aes(x = Eth, y = Days)) +\n    geom_boxplot() +\n    ggtitle(\"Days Absent vs. Ethnicity\") +\n    scale_x_discrete(labels = c(\"Aboriginal\", \"Not Aboriginal\"))\n\n\n\n\n\n\n\n\nHere is looks like there are generally higher numbers of days absent among the Aboriginal students, and there’s also more variability in that group.\n\nggplot(data = schools, aes(x = Sex, y = Days)) +\n    geom_boxplot() +\n    ggtitle(\"Days Absent vs. Gender\") +\n    scale_x_discrete(labels = c(\"Female\", \"Male\"))\n\n\n\n\n\n\n\n\nIt’s difficult to detect large differences here, though there is some indication of more variation in the distribution of male students.\n\nggplot(data = schools, aes(x = Age, y = Days)) +\n    geom_boxplot() +\n    ggtitle(\"Days Absent vs. Age\") +\n    scale_x_discrete(labels = c(\"Primary\", \"F1\", \"F2\", \"F3\"))\n\n\n\n\n\n\n\n\nThere seems to be some skewness in the F1 distribution, and you could investigate that further by cross-tabulating Age with some of the other explanatory variables.\n\nggplot(data = schools, aes(x = Lrn, y = Days)) +\n    geom_boxplot() +\n    ggtitle(\"Days Absent vs. Learning\") +\n    scale_x_discrete(labels = c(\"Average Learner\", \"Slow Learner\"))\n\n\n\n\n\n\n\n\nFinally, there are not clear differences in these two distributions, but we should investigate some more by fitting some models.\nOne thing to notice about many of the boxplots is that there are (at least what R is declaring to be) outliers on the upper end of all of the boxplots. But remember that count distributions tend to be right skewed (just revisit the histogram above!), and so these may not really be outliers, but rather just large counts that we can expect from some count distributions.\nAn as aside, take a look at the help file for the geom_boxplot() function.\n\n# ?geom_boxplot\n\nIf you scroll down in the help file to where it describes the “Computed Variables,” you’ll see that after_stat(ymax) is defined as “upper whisker = largest observation less than or equal to upper hinge + 1.5 * IQR” (“upper hinge” is the 75th percentile). This is a rather standard, though arbitrary rule for declaring something an outlier. Also remember that with Poisson count data, as the counts increase, so does the variance. Therefore, when looking at boxplots of count data, an “outlier” may simply be an indication of large variance, or it may be an indication of over dispersion."
  },
  {
    "objectID": "z6_learnR.html#zero-inflated-models",
    "href": "z6_learnR.html#zero-inflated-models",
    "title": "6 Zero Inflation",
    "section": "Zero-Inflated Models",
    "text": "Zero-Inflated Models\nRecall from the Module 6 lectures that the zero-inflated Poisson regression model is a two part model with:\n\\(logit(\\pi_i) = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + \\beta_4 X_{4i} + \\beta_5 X_{5i} + \\beta_6 X_{6i}\\)\nand\n\\(log(\\lambda_i) = \\gamma_0 + \\gamma_1 X_{1i} + \\gamma_2 X_{2i} + \\gamma_3 X_{3i} + \\gamma_4 X_{4i} + \\gamma_5 X_{5i} + \\gamma_6 X_{6i}\\)\nwith \\(X_1\\) as the indicator for Ethnicity, \\(X_2\\) as the indicator for Sex, \\(X_3\\), \\(X_4\\), \\(X_5\\) as the three indicator variables for Age, and \\(X_6\\) as the indicator variable for Learning Status.\nNote 1: As usual, for categorical variables, we need \\(k - 1\\) indicator variables in the model for each explanatory variable, where \\(k\\) is the number of categories for a particular explanatory variable.\nIf we expect there to be over dispersion in the counts, we might also consider fitting a zero-inflated negative binomial model. This is really quite similar to the idea of the zero-inflated Poisson model (we even have the same link function, the log-link). The only difference is that the negative binomial model has an extra parameter to estimate and allows for the possibility of over dispersion in the counts."
  },
  {
    "objectID": "z6_learnR.html#hurdle-models",
    "href": "z6_learnR.html#hurdle-models",
    "title": "6 Zero Inflation",
    "section": "Hurdle Models",
    "text": "Hurdle Models\nThe purpose of hurdle models is the same as the purpose of zero-inflated models: to account for excess 0’s. As discussed in the Sarul and Sahin reading, the results of the models can actually give quite different results sometimes.\nNote 2: As with the previous lab, fitting all of the different models we are about to fit does actually qualify as data snooping. In reality, we would want to think about whether a hurdle model or a zero-inflated Poisson model or a zero-inflated negative binomial model, etc., is most reasonable for the particular data we have before doing any model fitting."
  },
  {
    "objectID": "z6_learnR.html#model-evaluation-comparison-and-information-criteria",
    "href": "z6_learnR.html#model-evaluation-comparison-and-information-criteria",
    "title": "6 Zero Inflation",
    "section": "Model Evaluation, Comparison, and Information Criteria",
    "text": "Model Evaluation, Comparison, and Information Criteria\nLet’s first fit a zero-inflated Poisson model using all four covariates, and compare it to the usual poisson regression model.\n\nmod.pois0 &lt;- zeroinfl(Days ~ Eth + Sex + Age + Lrn,\n  dist = \"poisson\", data = schools)\nsummary(mod.pois0)\n\n\nCall:\nzeroinfl(formula = Days ~ Eth + Sex + Age + Lrn, data = schools, dist = \"poisson\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-4.3969 -1.8974 -0.7468  1.4181  9.4340 \n\nCount model coefficients (poisson with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.71883    0.06480  41.956  &lt; 2e-16 ***\nEthN        -0.44061    0.04190 -10.517  &lt; 2e-16 ***\nSexM         0.18904    0.04253   4.445 8.77e-06 ***\nAgeF1       -0.32048    0.06968  -4.599 4.24e-06 ***\nAgeF2        0.24602    0.06212   3.960 7.49e-05 ***\nAgeF3        0.43720    0.06781   6.447 1.14e-10 ***\nLrnSL        0.34400    0.05155   6.674 2.50e-11 ***\n\nZero-inflation model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.799218   1.398261  -3.432 0.000599 ***\nEthN         2.061952   1.079103   1.911 0.056030 .  \nSexM         1.010530   0.759919   1.330 0.183588    \nAgeF1       -0.005473   1.050231  -0.005 0.995842    \nAgeF2       -0.326430   1.074230  -0.304 0.761224    \nAgeF3        0.061397   1.119582   0.055 0.956266    \nLrnSL        0.213368   0.862528   0.247 0.804618    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 14 \nLog-likelihood: -1047 on 14 Df\n\n\nRecall that when we run the zero-inflated model, we get estimated regression coefficients for the zero-inflated part of the model and separate estimated regression coefficients for the Poisson part of the model.\n\nmod.pois &lt;- glm(Days ~ Eth + Sex + Age + Lrn,\n  family = \"poisson\", data = schools)\nsummary(mod.pois)\n\n\nCall:\nglm(formula = Days ~ Eth + Sex + Age + Lrn, family = \"poisson\", \n    data = schools)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.71538    0.06468  41.980  &lt; 2e-16 ***\nEthN        -0.53360    0.04188 -12.740  &lt; 2e-16 ***\nSexM         0.16160    0.04253   3.799 0.000145 ***\nAgeF1       -0.33390    0.07009  -4.764 1.90e-06 ***\nAgeF2        0.25783    0.06242   4.131 3.62e-05 ***\nAgeF3        0.42769    0.06769   6.319 2.64e-10 ***\nLrnSL        0.34894    0.05204   6.705 2.02e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2073.5  on 145  degrees of freedom\nResidual deviance: 1696.7  on 139  degrees of freedom\nAIC: 2299.2\n\nNumber of Fisher Scoring iterations: 5\n\n\nWe see that the zero-inflated model has a much lower AIC than the usual Poisson model; also, as expected, the zero-inflated model uses twice as many degrees of freedom as the usual Poisson model since we have twice as many parameters to estimate in the zero-inflated model.\nWe can also repeat what we did above using a negative binomial model to account for the (possible) overdispersion.\n\nmod.nb0 &lt;- zeroinfl(Days ~ Eth + Sex + Age + Lrn,\n  dist = \"negbin\", data = schools)\nsummary(mod.nb0)\n\n\nCall:\nzeroinfl(formula = Days ~ Eth + Sex + Age + Lrn, data = schools, dist = \"negbin\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.1836 -0.7060 -0.2712  0.5118  3.5941 \n\nCount model coefficients (negbin with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.88387    0.21756  13.256  &lt; 2e-16 ***\nEthN        -0.50956    0.14979  -3.402  0.00067 ***\nSexM         0.16743    0.15760   1.062  0.28808    \nAgeF1       -0.44161    0.22856  -1.932  0.05335 .  \nAgeF2        0.05128    0.23216   0.221  0.82519    \nAgeF3        0.30937    0.23604   1.311  0.18996    \nLrnSL        0.28252    0.17544   1.610  0.10732    \nLog(theta)   0.39640    0.13171   3.010  0.00262 ** \n\nZero-inflation model coefficients (binomial with logit link):\n            Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept) -26.6848   484.4629  -0.055    0.956\nEthN         13.7292   424.5594   0.032    0.974\nSexM         11.7614   233.3545   0.050    0.960\nAgeF1         0.1852     1.4154   0.131    0.896\nAgeF2        -1.1579     1.6862  -0.687    0.492\nAgeF3        -0.7733     1.5920  -0.486    0.627\nLrnSL        -0.6861     1.3114  -0.523    0.601\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta = 1.4865 \nNumber of iterations in BFGS optimization: 33 \nLog-likelihood: -542.1 on 15 Df\n\n# compare to the negative binomial model without zero-inflation\n\nmod.nb &lt;- glm.nb(Days ~ Eth + Sex + Age + Lrn, data = schools)\nsummary(mod.nb)\n\n\nCall:\nglm.nb(formula = Days ~ Eth + Sex + Age + Lrn, data = schools, \n    init.theta = 1.274892646, link = log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.89458    0.22842  12.672  &lt; 2e-16 ***\nEthN        -0.56937    0.15333  -3.713 0.000205 ***\nSexM         0.08232    0.15992   0.515 0.606710    \nAgeF1       -0.44843    0.23975  -1.870 0.061425 .  \nAgeF2        0.08808    0.23619   0.373 0.709211    \nAgeF3        0.35690    0.24832   1.437 0.150651    \nLrnSL        0.29211    0.18647   1.566 0.117236    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.2749) family taken to be 1)\n\n    Null deviance: 195.29  on 145  degrees of freedom\nResidual deviance: 167.95  on 139  degrees of freedom\nAIC: 1109.2\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.275 \n          Std. Err.:  0.161 \n\n 2 x log-likelihood:  -1093.151 \n\n\nThe structure of the output for these two models looks very similar to the structure of output for the Poisson regression models, except one additional parameter is estimate in each model (as compared to the analogous Poisson model): \\(\\theta\\), the dispersion parameter. In both models, \\(\\hat\\theta\\) is larger than 1, indicating that there is some over dispersion of the counts. We will test this more formally using a drop-in-deviance test in a moment, but for completeness, let’s also fit the Poisson hurdle model and the negative binomial hurdle model.\n\nmod.pois.hurdle &lt;- hurdle(Days ~ Eth + Sex + Age + Lrn,\n  dist = \"poisson\", data = schools)\nsummary(mod.pois.hurdle)\n\n\nCall:\nhurdle(formula = Days ~ Eth + Sex + Age + Lrn, data = schools, dist = \"poisson\")\n\nPearson residuals:\n   Min     1Q Median     3Q    Max \n-4.397 -1.897 -0.747  1.418  9.434 \n\nCount model coefficients (truncated poisson with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.71879    0.06481  41.953  &lt; 2e-16 ***\nEthN        -0.44065    0.04190 -10.517  &lt; 2e-16 ***\nSexM         0.18907    0.04253   4.446 8.76e-06 ***\nAgeF1       -0.32057    0.06969  -4.600 4.23e-06 ***\nAgeF2        0.24600    0.06212   3.960 7.50e-05 ***\nAgeF3        0.43725    0.06782   6.448 1.14e-10 ***\nLrnSL        0.34408    0.05156   6.674 2.49e-11 ***\nZero hurdle model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.799162   1.398219   3.432 0.000598 ***\nEthN        -2.062031   1.079091  -1.911 0.056018 .  \nSexM        -1.010397   0.759840  -1.330 0.183601    \nAgeF1        0.005372   1.050158   0.005 0.995918    \nAgeF2        0.326481   1.074203   0.304 0.761182    \nAgeF3       -0.061336   1.119559  -0.055 0.956309    \nLrnSL       -0.213461   0.862480  -0.247 0.804524    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 12 \nLog-likelihood: -1047 on 14 Df\n\nmod.nb.hurdle &lt;- hurdle(Days ~ Eth + Sex + Age + Lrn,\n  dist = \"negbin\", data = schools)\nsummary(mod.nb.hurdle)\n\n\nCall:\nhurdle(formula = Days ~ Eth + Sex + Age + Lrn, data = schools, dist = \"negbin\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.1934 -0.7283 -0.2897  0.4978  3.6377 \n\nCount model coefficients (truncated negbin with log link):\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.85794    0.21858  13.075  &lt; 2e-16 ***\nEthN        -0.49846    0.15231  -3.273  0.00107 ** \nSexM         0.14525    0.15953   0.910  0.36257    \nAgeF1       -0.45409    0.23094  -1.966  0.04927 *  \nAgeF2        0.07481    0.23408   0.320  0.74926    \nAgeF3        0.35777    0.23801   1.503  0.13280    \nLrnSL        0.31736    0.17734   1.790  0.07352 .  \nLog(theta)   0.39929    0.15466   2.582  0.00983 ** \nZero hurdle model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.799162   1.398219   3.432 0.000598 ***\nEthN        -2.062031   1.079091  -1.911 0.056018 .  \nSexM        -1.010397   0.759840  -1.330 0.183601    \nAgeF1        0.005372   1.050158   0.005 0.995918    \nAgeF2        0.326481   1.074203   0.304 0.761182    \nAgeF3       -0.061336   1.119559  -0.055 0.956309    \nLrnSL       -0.213461   0.862480  -0.247 0.804524    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta: count = 1.4908\nNumber of iterations in BFGS optimization: 14 \nLog-likelihood: -542.5 on 15 Df\n\n\nWe can now compare all six of these models using AIC or BIC to see if any of the models are preferable. Based on intuition, we would expect the negative binomial models to be better than the Poisson models since, from the exploratory analysis, we expected there to be over dispersion in the counts of days missed from school.\n\nAIC(mod.pois0, mod.pois, mod.pois.hurdle, mod.nb0, mod.nb, mod.nb.hurdle)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nmod.pois0\n14\n2121.462\n\n\nmod.pois\n7\n2299.184\n\n\nmod.pois.hurdle\n14\n2121.451\n\n\nmod.nb0\n15\n1114.118\n\n\nmod.nb\n8\n1109.151\n\n\nmod.nb.hurdle\n15\n1115.070\n\n\n\n\n\n\nAs expected, the negative binomial models all have much lower AIC than the Poisson models. However, after we account for this over dispersion, the three negative binomial models are relatively similar in terms of AIC. Therefore, we would probably prefer the simplest model (the model that does not incorporate zero-inflation) here.\nWe mentioned above that, sometimes the hurdle model gives very similar estimates and results as the zero-inflated model, but sometimes the results are quite different. We can compare the zero-inflated negative binomial model to the negative binomial hurdle model here to see if there are any major differences in the coefficient estimates and/or their standard errors. Again, this is just an academic exercise, because based on the AIC analysis above, we’d recommend using the model without zero-inflation.\n\ntab1 &lt;- cbind(round(summary(mod.nb0)$coefficients[[1]][, 1], 3),\n    round(summary(mod.nb.hurdle)$coefficients[[1]][, 1], 3))\ncolnames(tab1) &lt;- c(\"Zero-Inf Coefs\", \"Hurdle Coefs\")\ntab1\n\n            Zero-Inf Coefs Hurdle Coefs\n(Intercept)          2.884        2.858\nEthN                -0.510       -0.498\nSexM                 0.167        0.145\nAgeF1               -0.442       -0.454\nAgeF2                0.051        0.075\nAgeF3                0.309        0.358\nLrnSL                0.283        0.317\nLog(theta)           0.396        0.399\n\ntab2 &lt;- cbind(round(summary(mod.nb0)$coefficients[[1]][, 2], 3),\n    round(summary(mod.nb.hurdle)$coefficients[[1]][, 2], 3))\ncolnames(tab2) &lt;- c(\"Zero-Inf SEs\", \"Hurdle SEs\")\ntab2\n\n            Zero-Inf SEs Hurdle SEs\n(Intercept)        0.218      0.219\nEthN               0.150      0.152\nSexM               0.158      0.160\nAgeF1              0.229      0.231\nAgeF2              0.232      0.234\nAgeF3              0.236      0.238\nLrnSL              0.175      0.177\nLog(theta)         0.132      0.155\n\n\nIn this particular instance, the coefficients for the negative binomial part of the model and their standard errors are quite similar. You are asked to compare the coefficients and their standard errors for the “extra zero” part of these two models at the end of the lab.\nLet’s next carry out a more formal Vuong test to compare the zero-inflated negative binomial model to the usual negative binomial model.\n\nVuong test\nBecause the zero-inflated poisson model and the usual Poisson model do not nest, we can’t use a drop in deviance test to compare the models (and same goes for the negative binomial model vs. the zero-inflated negative binomial model).\nThe Vuong test has a null hypothesis that the models are indistinguishable with a large positive test statistic indicating that the first model that is input into the function is better (below, we put the zero-inflated model first) and a large negative test statistic indicating that the second model is better.\n\nvuong(mod.nb0, mod.nb)\n\nVuong Non-Nested Hypothesis Test-Statistic: \n(test-statistic is asymptotically distributed N(0,1) under the\n null that the models are indistinguishible)\n-------------------------------------------------------------\n              Vuong z-statistic             H_A    p-value\nRaw                    1.315020 model1 &gt; model2   0.094252\nAIC-corrected         -0.723184 model2 &gt; model1   0.234783\nBIC-corrected         -3.763784 model2 &gt; model1 8.3681e-05\n\n\nNote 1: The Vuong test is asymptotic so, if the sample size of the data set is not very large, then the test is unreliable and should not be used.\nNote 2: We can also use the test to compare the Poisson models just for fun.\n\nvuong(mod.pois0, mod.pois)\n\nVuong Non-Nested Hypothesis Test-Statistic: \n(test-statistic is asymptotically distributed N(0,1) under the\n null that the models are indistinguishible)\n-------------------------------------------------------------\n              Vuong z-statistic             H_A   p-value\nRaw                    2.667898 model1 &gt; model2 0.0038164\nAIC-corrected          2.473082 model1 &gt; model2 0.0066977\nBIC-corrected          2.182454 model1 &gt; model2 0.0145380\n\n\nHere, there is fairly strong evidence that the zero-inflated Poisson model is better than the non-zero inflated Poisson model. However, as discussed above, neither seem appropriate since there is over dispersion in the counts of days absent from school.\nTo conclude, it seems evident that there is over dispersion in the days absent variable, but that these counts are not zero-inflated. In this instance the appropriate model to use for interpretation and inference is the negative binomial regression model.\n\n\nCoefficient Interpretation\nEven though zero-inflation is not apparent in the days absent counts, we’re going to proceed with interpreting the estimated regression coefficients for the zero-inflated negative binomial model just so you can see one approach. Recall that the coefficient estimates for this model are:\n\nsummary(mod.nb0)$coefficients[[1]][, 1]\n\n(Intercept)        EthN        SexM       AgeF1       AgeF2       AgeF3 \n  2.8838678  -0.5095556   0.1674285  -0.4416084   0.0512790   0.3093699 \n      LrnSL  Log(theta) \n  0.2825202   0.3964049 \n\nsummary(mod.nb0)$coefficients[[2]][, 1]\n\n(Intercept)        EthN        SexM       AgeF1       AgeF2       AgeF3 \n-26.6847779  13.7291994  11.7614329   0.1852184  -1.1578503  -0.7732624 \n      LrnSL \n -0.6861468 \n\n\nThe first set of coefficients is from the negative binomial part of the model and the second set of coefficients is from the zero-inflation part of the model. If we think in the framework of some of the zeros as true zeros and some of the zeros as excess zeros, then we might interpret the Ethnicity coefficient estimate in the negative binomial model, -0.5096, in the following way:\n“A person of non-Aboriginal descent is predicted to be absent from school \\(1 - exp(-0.5096) = 39.93%\\) less than a person of Aboriginal descent at this particular school among all of those with a risk of being absent (i.e., among all of those that are not the excess zeroes), provided these two people are of the same gender, age and learner status.\nThat’s rather a mouthful of an interpretation, but we have to be careful when interpreting regression coefficient estimates from a model with multiple explanatory variables – the interpretation of a single coefficient estimate has to be made while holding the values of the other explanatory variables fixed.\nNotice that this interpretation is exactly the same as the interpretation in the usual negative binomial model except for the extra parenthetical we added about the excess zeroes.\nSimilarly, we interpret regression coefficient estimates from the zero-inflated part of the model in the same way that we would interpret estimates from a logistic regression model.\n\n\nLooking at Residuals\nLet’s new consider a few residual plots from the zero-inflated negative binomial model.\n\nschools$residuals.pearson &lt;- residuals(mod.nb0, type = \"pearson\")\nschools$fitted.vals &lt;- mod.nb0$fitted.values\nggplot(data = schools, aes(x = Eth, y = residuals.pearson)) +\n    geom_point()\n\n\n\n\n\n\n\nggplot(data = schools, aes(x = Sex, y = residuals.pearson)) +\n    geom_point()\n\n\n\n\n\n\n\nggplot(data = schools, aes(x = Age, y = residuals.pearson)) +\n    geom_point()\n\n\n\n\n\n\n\nggplot(data = schools, aes(x = Lrn, y = residuals.pearson)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(data = schools, aes(x = fitted.vals, y = residuals.pearson)) +\n    geom_point()\n\n\n\n\n\n\n\n\nWe see from these residual plots that there are a few residuals that are larger than 3. However, given such a large sample, it is not too surprising that a few points have large residuals. We also see in the residuals vs. fitted values plot, that the spread of the residuals is relatively constant across all fitted values. Overall, there is no cause for concern in using the zero-inflated negative binomial model for this data. As discussed above, however, since the zero-inflated model has a similar AIC (actually a slightly larger AIC) than the non-zero-inflated model, we would probably prefer the simpler non-zero-inflated model."
  },
  {
    "objectID": "z6_learnR.html#make-three-histograms",
    "href": "z6_learnR.html#make-three-histograms",
    "title": "6 Zero Inflation",
    "section": "1 Make three histograms",
    "text": "1 Make three histograms\nRun the above code and then make three histograms of the three sets of simulated data. Also, get summary statistics for each of the three sets of simulations.\n\nhist(pois)\n\n\n\n\n\n\n\nhist(pois0)\n\n\n\n\n\n\n\nhist(negbin)\n\n\n\n\n\n\n\n\n\nsummary(pois)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.000   5.000   4.947   6.000  13.000 \n\nsummary(pois0)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   3.000   5.000   4.913   7.000  11.000 \n\nsummary(negbin)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    1.25    3.00    5.34    8.00   27.00"
  },
  {
    "objectID": "z6_learnR.html#section",
    "href": "z6_learnR.html#section",
    "title": "6 Zero Inflation",
    "section": "2",
    "text": "2\nWhat are some of the differences between the three histograms? Also, what do you notice about the negative binomial simulated data? (which applies to our data analysis above)\nPois is somewhat normal. Pois0 is somewhat normal with more zeroes. Negbin is exponential. The negative binomial has a lower median and higher max. It is more dispersed."
  },
  {
    "objectID": "z6_learnR.html#section-1",
    "href": "z6_learnR.html#section-1",
    "title": "6 Zero Inflation",
    "section": "3",
    "text": "3\nRepeat the simulation of the negative binomial data, but try changing the size parameter to a few different values. What does the size parameter seem to control?\n\nhist(rnbinom(n*1000, mu = 5, size = 1))\n\n\n\n\n\n\n\nhist(rnbinom(n*1000, mu = 5, size = 1.4))\n\n\n\n\n\n\n\nhist(rnbinom(n*1000, mu = 5, size = 3))\n\n\n\n\n\n\n\nhist(rnbinom(n*1000, mu = 5, size = 5))\n\n\n\n\n\n\n\nhist(rnbinom(n*1000, mu = 5, size = 1400))\n\n\n\n\n\n\n\n\nIt seems to control the number of zeroes."
  },
  {
    "objectID": "z6_learnR.html#section-2",
    "href": "z6_learnR.html#section-2",
    "title": "6 Zero Inflation",
    "section": "4",
    "text": "4\nFinally, simulate some data from a zero-inflated negative binomial distribution using the rzinegbin function in the VGAM package.\n\n# ?rzinegbin\nsim.df$negbin0 &lt;- rzinegbin(n = n, size = 1.4, munb = 5, pstr0 = 0.2)\n\nTry plotting a histogram of the zero-inflated negative binomial data. Is it easy or difficult to tell based on these histograms whether data come from the poisson, negative binomial, zero-inflated poisson, or zero-inflated negative binomial models?\n\nhist(sim.df$negbin)\n\n\n\n\n\n\n\nhist(sim.df$negbin0)\n\n\n\n\n\n\n\n\n\nhist(rzinegbin(n = 10000, size = 1.4, munb = 5, pstr0 = 0.2))\n\n\n\n\n\n\n\n\nThe sets with lots of zeroes seem easy enough to pick out. Yes, I think they are easy to distinquish baesd on the histograms."
  },
  {
    "objectID": "z4_learnR.html",
    "href": "z4_learnR.html",
    "title": "4 Log Reg II",
    "section": "",
    "text": "Please load these libraries that you’ll need for this lab:\n\nlibrary(arm)\nlibrary(Sleuth3)\nlibrary(tidyverse)\nlibrary(vcdExtra)\nlibrary(magrittr)\nlibrary(datasets)\n\nIn this lab, We’ll cover the drop in deviance and deviance goodness of fit tests, and show how to perform them using R. We’ll also talk more about residuals from binomial logistic regression and about the dispersion parameter and over dispersion. Two additional topics are (1) a pathological (but not altogether rare) situation that can arise in logistic regression (2) using logistic regression to perform a test of the difference in two proportions."
  },
  {
    "objectID": "z4_learnR.html#aflatoxin-data",
    "href": "z4_learnR.html#aflatoxin-data",
    "title": "4 Log Reg II",
    "section": "Aflatoxin data",
    "text": "Aflatoxin data\nIn this lab we will continue with the ex2116 data from Sleuth3, introduced in lecture. Each of 20 tanks was stocked with fishes that had been exposed as embryos to one of 5 doses of a carcinogen. When the fishes were dissected a year later, the number of fishes that had developed liver tumors was recorded.\n\ndata(ex2116)\ntumors &lt;- ex2116\nhead(tumors)\n\n\n\n\n\nDose\nTumor\nTotal\n\n\n\n\n0.010\n9\n87\n\n\n0.010\n5\n86\n\n\n0.010\n2\n89\n\n\n0.010\n9\n85\n\n\n0.025\n30\n86\n\n\n0.025\n41\n86\n\n\n\n\n\n\nHere we’ll add a column that records the number of fish in each tank which did not develop liver tumors, and a column that assigns a unique label to each of the 20 tanks. We’ll also add a column for log(Dose) and log(Dose)^2 since we used those as explanatory variables in the model you saw in the narrated lectures.\n\ntumors %&lt;&gt;% mutate(Dose = Dose, Tumor = Tumor, NoTumor = Total - Tumor, TankID = factor(1:nrow(tumors)),logDose = log(Dose), logDose2 = log(Dose)^2)\nhead(tumors)\n\n\n\n\n\nDose\nTumor\nTotal\nNoTumor\nTankID\nlogDose\nlogDose2\n\n\n\n\n0.010\n9\n87\n78\n1\n-4.60517\n21.20759\n\n\n0.010\n5\n86\n81\n2\n-4.60517\n21.20759\n\n\n0.010\n2\n89\n87\n3\n-4.60517\n21.20759\n\n\n0.010\n9\n85\n76\n4\n-4.60517\n21.20759\n\n\n0.025\n30\n86\n56\n5\n-3.68888\n13.60783\n\n\n0.025\n41\n86\n45\n6\n-3.68888\n13.60783\n\n\n\n\n\n\nWe’ll also create a case-format version that records the binary status (tumor or not) for each of the 1739 individual fishes.\ncheck code tumors_case$Outcome should be a factor\n\n# The syntax dplyr::select() ensures that the select() function from the dplyr package is \n# used instead of the select() function from the MASS package, in case you still have MASS\n# loaded in the library.\ntumors_freq &lt;- tumors %&gt;% dplyr::select(-Total) %&gt;%\n pivot_longer(Tumor:NoTumor,names_to=\"Outcome\",values_to=\"Freq\",cols_vary = \"slowest\") %&gt;%\n mutate(Outcome=as.factor(Outcome))\ntumors_case &lt;- expand.dft(tumors_freq) %&gt;%\n mutate(Outcome=as.factor(Outcome))\nhead(tumors_case)\n\n\n\n\n\nDose\nTankID\nlogDose\nlogDose2\nOutcome\n\n\n\n\n0.01\n1\n-4.60517\n21.20759\nTumor\n\n\n0.01\n1\n-4.60517\n21.20759\nTumor\n\n\n0.01\n1\n-4.60517\n21.20759\nTumor\n\n\n0.01\n1\n-4.60517\n21.20759\nTumor\n\n\n0.01\n1\n-4.60517\n21.20759\nTumor\n\n\n0.01\n1\n-4.60517\n21.20759\nTumor\n\n\n\n\n\n\n(With most of the lab examples so far oriented around examples of death, discrimination, and disease, you might accuse us statisticians of attempting to usurp from economics the title of “dismal science”! (Economists think they’re pessimists. what they call “maximizing utility”, statisticians call “minimizing loss”). We promise nobody dies in the next lab. Probably."
  },
  {
    "objectID": "z4_learnR.html#binary-vs-binomial",
    "href": "z4_learnR.html#binary-vs-binomial",
    "title": "4 Log Reg II",
    "section": "Binary vs binomial",
    "text": "Binary vs binomial\nThere are several equivalent ways of fitting a logistic regression model with glm() to data such as the ex2116 data. We will see why the fitting methods that preserve information about the counts within each tank are preferable for our purposes.\n\nModeling a binomial count for each tank\nFirst, the response can be specified as a 2-column matrix containing counts of successes in the first column and counts of failures in the second.\n\nmod1 &lt;- glm(data = tumors, cbind(Tumor, NoTumor) ~ logDose + logDose2, family = \"binomial\")\nsummary(mod1)\n\n\nCall:\nglm(formula = cbind(Tumor, NoTumor) ~ logDose + logDose2, family = \"binomial\", \n    data = tumors)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49343   2.086  0.03699 *  \nlogDose     -1.03048    0.35743  -2.883  0.00394 ** \nlogDose2    -0.39195    0.06136  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: 119.45\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe response can also be specified as a vector of proportions of successes in each group, with the total in each group given through the weights argument:\n\nmod2 &lt;- glm(data = tumors, Tumor/Total ~ logDose + logDose2, weights = Total, family = \"binomial\")\nsummary(mod2)\n\n\nCall:\nglm(formula = Tumor/Total ~ logDose + logDose2, family = \"binomial\", \n    data = tumors, weights = Total)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49343   2.086  0.03699 *  \nlogDose     -1.03048    0.35743  -2.883  0.00394 ** \nlogDose2    -0.39195    0.06136  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: 119.45\n\nNumber of Fisher Scoring iterations: 4\n\n\nBe sure to verify that mod1 and mod2 are equivalent.\n\n\nModeling a binary outcome for each fish\nWe have converted the data to case format, where each row contains an individual binary outcome corresponding to an individual fish. These outcomes can be modeled directly, just as we saw with the (ungrouped) Donner data in Lab 3.\n\nmod3 &lt;- glm(data = tumors_case, Outcome ~ logDose + logDose2, family = \"binomial\")\nsummary(mod3)\n\n\nCall:\nglm(formula = Outcome ~ logDose + logDose2, family = \"binomial\", \n    data = tumors_case)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49341   2.086  0.03698 *  \nlogDose     -1.03048    0.35740  -2.883  0.00394 ** \nlogDose2    -0.39195    0.06135  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2395.8  on 1738  degrees of freedom\nResidual deviance: 1754.7  on 1736  degrees of freedom\nAIC: 1760.7\n\nNumber of Fisher Scoring iterations: 4\n\n\nMake a quick comparison of the coefficient estimates from mod2 and mod3:\n\ncbind(coefficients(mod2),coefficients(mod3))\n\n                  [,1]      [,2]\n(Intercept)  1.0292126  1.029213\nlogDose     -1.0304804 -1.030480\nlogDose2    -0.3919491 -0.391949\n\n\nThe two models give the same coefficient estimates, and you can also verify that the corresponding standard errors are the same. Therefore, in terms of inferences about the regression coefficients, treating the data as binary (one 0/1 outcome for each fish) or binomial (one count outcome for each tank) doesn’t seem to matter.\nBut, let’s remember that when we looked at the binomial logistic regression model in class, we noticed some over dispersion in the counts. We’ll first examine one more approach to modeling the binomial counts, and then turn to talking about the over dispersion.\n\n\nModeling as binomial counts within each Dose\nNote that “TankID” is not a term in any of the models we fit above. The binomial logistic models treat the 4 tanks in each of the 5 dose groups as independent binomial observations. Within each Dose level, the 4 tanks are supposed to be draws from 4 independent binomial random variables, with potentially different \\(n\\) (different number of fish in each tank) but all with the same \\(p\\). In the binary logistic model, the tanks are ignored and the fish-level outcomes are treated as independent Bernoulli random variables, with a common \\(p\\) at each Dose. In either form, a single \\(p\\) applies to every fish in the Dose level, regardless of tank. Indeed, we can explicitly collapse across the tanks before fitting the model, without affecting any of the inferences:\n\n(summed_tumor &lt;- summarize(group_by(tumors, Dose, logDose, logDose2), sum(Tumor), sum(NoTumor)))\n\n`summarise()` has grouped output by 'Dose', 'logDose'. You can override using\nthe `.groups` argument.\n\n\n\n\n\n\nDose\nlogDose\nlogDose2\nsum(Tumor)\nsum(NoTumor)\n\n\n\n\n0.010\n-4.605170\n21.207592\n25\n322\n\n\n0.025\n-3.688880\n13.607832\n132\n214\n\n\n0.050\n-2.995732\n8.974412\n226\n127\n\n\n0.100\n-2.302585\n5.301898\n281\n74\n\n\n0.250\n-1.386294\n1.921812\n286\n52\n\n\n\n\n\n\nNotice that we’ve now reduced the dataset down to five observations! And now we’ll fit the model to these summed responses:\n\nmod4 &lt;- glm(data = summed_tumor, cbind(`sum(Tumor)`, `sum(NoTumor)`) ~ logDose + logDose2, family = \"binomial\")\nsummary(mod4)\n\n\nCall:\nglm(formula = cbind(`sum(Tumor)`, `sum(NoTumor)`) ~ logDose + \n    logDose2, family = \"binomial\", data = summed_tumor)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49343   2.086  0.03699 *  \nlogDose     -1.03048    0.35743  -2.883  0.00394 ** \nlogDose2    -0.39195    0.06136  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 641.234089  on 4  degrees of freedom\nResidual deviance:   0.086879  on 2  degrees of freedom\nAIC: 35.091\n\nNumber of Fisher Scoring iterations: 3\n\n\nAnd compare coefficient estimates:\n\ncbind(coefficients(mod2),coefficients(mod3),coefficients(mod4))\n\n                  [,1]      [,2]       [,3]\n(Intercept)  1.0292126  1.029213  1.0292126\nlogDose     -1.0304804 -1.030480 -1.0304804\nlogDose2    -0.3919491 -0.391949 -0.3919491\n\n\nAnd once again you can verify that all of the corresponding standard errors are also the same. So what’s going on here, and which of these models is “the best one” to use?\n\n\nOk, so now what?!\nThe parameter estimates and standard errors are all identical. We reach the same conclusions from each model. But let’s look at the residual deviances for each of the models:\n\ncbind(deviance(mod2),deviance(mod3),deviance(mod4))\n\n         [,1]     [,2]       [,3]\n[1,] 26.04806 1754.692 0.08687945\n\n\nIt’s also important to recognize that in mod2, mod3 and mod4, the sample sizes are n = 20, n = 1739 and n = 5, respectively. And, the null deviances for each model are also substantially different; again in order of mod2, mod3 and mod4 these are 667.20, 2395.84 and 641.23. The difference in deviance (the deviance accounted for by a model), however, is the same for every form of the model.\nTo see more plainly that the methods above are equivalent, we can view minimal summaries from each using the display() function from arm. The abbreviated output (compared to summary) facilitates comparison between several models on the same page.\n\n# counts in tanks\ndisplay(mod2)\n\nglm(formula = Tumor/Total ~ logDose + logDose2, family = \"binomial\", \n    data = tumors, weights = Total)\n            coef.est coef.se\n(Intercept)  1.03     0.49  \nlogDose     -1.03     0.36  \nlogDose2    -0.39     0.06  \n---\n  n = 20, k = 3\n  residual deviance = 26.0, null deviance = 667.2 (difference = 641.1)\n\n# binary outcomes per fish\ndisplay(mod3)\n\nglm(formula = Outcome ~ logDose + logDose2, family = \"binomial\", \n    data = tumors_case)\n            coef.est coef.se\n(Intercept)  1.03     0.49  \nlogDose     -1.03     0.36  \nlogDose2    -0.39     0.06  \n---\n  n = 1739, k = 3\n  residual deviance = 1754.7, null deviance = 2395.8 (difference = 641.1)\n\n# counts in dose level ignoring tanks\ndisplay(mod4)\n\nglm(formula = cbind(`sum(Tumor)`, `sum(NoTumor)`) ~ logDose + \n    logDose2, family = \"binomial\", data = summed_tumor)\n            coef.est coef.se\n(Intercept)  1.03     0.49  \nlogDose     -1.03     0.36  \nlogDose2    -0.39     0.06  \n---\n  n = 5, k = 3\n  residual deviance = 0.1, null deviance = 641.2 (difference = 641.1)\n\n\nAll the same assumptions go into each of these ways of fitting the models, and all the same inferences come out. In particular, we are always assuming that once we know the Dose a fish received, knowing the particular tank in which that fish was housed cannot give us any more information about that fish’s chance of having a tumor – not even if we know that the fish came from a tank in which an especially large (or small) number of other fish got tumors, compared to other tanks within the same dose level. In the binomial-tank-counts model, this assumption reads like “every binomial within a dose level has the same \\(p\\).” In the binary-fish model, it reads “every Bernoulli within a dose level has the same \\(p\\).” In the binomial-dose-count model, it reads “the Bernoulli’s across all tanks within a dose must be independent.” We could call this the assumption of “irrelevant groups (tanks).”\nIf we have some grouping at all, however, we often suspect that this last assumption about independence is not sound. Fish in the same tank are expected to be more similar to one another than fish in different tanks. That is, we should not expect same binomial \\(p\\) in every tank, nor should we suppose that all the Bernoulli responses in a dose level are independent, regardless of tank.\nIn what follows, we will see that fitting the model in the “tank-count” binomial form, as opposed to per-fish binary form or the dose-count binomial form, is the way that will allow us to check whether the group-irrelevance of assumption is reasonable. We’ll see that not making this assumption comes with a steep price, and preview another technique that will sometimes allow us to avoid paying it."
  },
  {
    "objectID": "z4_learnR.html#empirical-logits",
    "href": "z4_learnR.html#empirical-logits",
    "title": "4 Log Reg II",
    "section": "Empirical logits",
    "text": "Empirical logits\nThe empirical logit is just the logit transformation applied to the proportion within a bin (this isn’t the log-odds of the probability within the bin, it’s just an estimate based on the observed proportion, hence “empirical”).\nRemember the logit transformation of a proportion/probability is given by qlogis():\n\ntumors\n\n\n\n\n\nDose\nTumor\nTotal\nNoTumor\nTankID\nlogDose\nlogDose2\n\n\n\n\n0.010\n9\n87\n78\n1\n-4.605170\n21.207592\n\n\n0.010\n5\n86\n81\n2\n-4.605170\n21.207592\n\n\n0.010\n2\n89\n87\n3\n-4.605170\n21.207592\n\n\n0.010\n9\n85\n76\n4\n-4.605170\n21.207592\n\n\n0.025\n30\n86\n56\n5\n-3.688880\n13.607832\n\n\n0.025\n41\n86\n45\n6\n-3.688880\n13.607832\n\n\n0.025\n27\n86\n59\n7\n-3.688880\n13.607832\n\n\n0.025\n34\n88\n54\n8\n-3.688880\n13.607832\n\n\n0.050\n54\n89\n35\n9\n-2.995732\n8.974412\n\n\n0.050\n53\n86\n33\n10\n-2.995732\n8.974412\n\n\n0.050\n64\n90\n26\n11\n-2.995732\n8.974412\n\n\n0.050\n55\n88\n33\n12\n-2.995732\n8.974412\n\n\n0.100\n71\n88\n17\n13\n-2.302585\n5.301898\n\n\n0.100\n73\n89\n16\n14\n-2.302585\n5.301898\n\n\n0.100\n65\n88\n23\n15\n-2.302585\n5.301898\n\n\n0.100\n72\n90\n18\n16\n-2.302585\n5.301898\n\n\n0.250\n66\n86\n20\n17\n-1.386294\n1.921812\n\n\n0.250\n75\n82\n7\n18\n-1.386294\n1.921812\n\n\n0.250\n72\n81\n9\n19\n-1.386294\n1.921812\n\n\n0.250\n73\n89\n16\n20\n-1.386294\n1.921812\n\n\n\n\n\nempirical_logits &lt;- with(tumors, qlogis(Tumor/Total))\nempirical_logits\n\n [1] -2.15948425 -2.78501124 -3.77276094 -2.13350876 -0.62415431 -0.09309042\n [7] -0.78170058 -0.46262352  0.43363599  0.47378435  0.90078655  0.51082562\n[13]  1.42946653  1.51787072  1.03889305  1.38629436  1.19392247  2.37157796\n[19]  2.07944154  1.51787072\n\n\nWe plot the empirical logits against Dose to see the shape of the relationship we’re trying to capture on the log-odds scale, along with a loess smooth.\n\nggplot(data = tumors, aes(x = Dose, y = empirical_logits))+ \n geom_jitter(width = 0.005, height = 0.01) + \n geom_smooth(se = FALSE) +\n ggtitle(\"Empirical Logits vs Dose\") \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis appearance of a logarithmic relationship between the Dose and the logits prompts the a log-transformation of the dose to straighten it out (that is, it suggests that the odds of tumor are nearly linear in dose).\n\nggplot(data = tumors, aes(x = logDose, y = empirical_logits)) + \n geom_jitter(width = 0.1, height = 0.1) + \n geom_smooth(se = FALSE) +\n ggtitle(\"Empirical Logits vs log(Dose)\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis plot suggests that a logistic regression model which includes both log(Dose) and log(Dose)^2 would be appropriate to capture the observed trend in the empirical logits. Unlike with binary logistic regression, the binomial model lets us measure the lack-of-fit to a proposed model, and compare the fit between models."
  },
  {
    "objectID": "z4_learnR.html#deviance-goodness-of-fit-lack-of-fit.",
    "href": "z4_learnR.html#deviance-goodness-of-fit-lack-of-fit.",
    "title": "4 Log Reg II",
    "section": "Deviance goodness of fit , lack of fit.",
    "text": "Deviance goodness of fit , lack of fit.\nRecall that the deviance goodness of fit test compares a fitted model to a saturated model, or one in which there are as many parameters as there are data points. In these goodness of fit comparisons,\nthe null hypothesis corresponds to the fitted model (which is a reduced model relative to the saturated model), and the alternative hypothesis corresponds to the saturated model. Therefore, a small p-value indicating evidence for rejection of the fitted model in favor of the saturated model is evidence of lack of fit.\nThe LRstats() from vcdExtra function shows a convenient summary of the fits of one or more model objects.\n\nmod5 &lt;- glm(data = tumors, (Tumor/Total) ~ Dose, weights = Total, family = \"binomial\")\nmod6 &lt;- glm(data = tumors, (Tumor/Total) ~ logDose, weights = Total, family = \"binomial\")\nmod7 &lt;- glm(data = tumors, (Tumor/Total) ~ logDose + logDose2, weights = Total, family = \"binomial\")\nLRstats(mod5, mod6, mod7)\n\n\n\n\n\n\nAIC\nBIC\nLR Chisq\nDf\nPr(&gt;Chisq)\n\n\n\n\nmod5\n368.4449\n370.4364\n277.04682\n18\n0.0000000\n\n\nmod6\n160.2947\n162.2862\n68.89661\n18\n0.0000001\n\n\nmod7\n119.4461\n122.4333\n26.04806\n17\n0.0735894\n\n\n\n\n\n\nThe LR Chisq is the residual deviance, which is the sum of the squared deviance residuals. For instance, for mod5, the residual deviance value of 277 comes can be obtained as\n\nresid(mod5, type = 'deviance') %&gt;% raise_to_power(2) %&gt;% sum\n\n[1] 277.0468\n\n\nor as\n\nmod5$deviance\n\n[1] 277.0468\n\n\nThis quantity has an approximate chi-squared distribution if the model is correct, which is the basis for the deviance goodness of fit test. Pr(&gt;Chisq) provides the p-value for this test. For mod6, let’s check that this is equivalent to doing this test “by hand,” using the residual deviance and residual df:\n\npchisq(mod6$deviance, df = mod6$df.residual, lower.tail = FALSE)\n\n[1] 6.940025e-08\n\n\nEach successive model shows a better fit, as evidenced by the successively larger p-values from the goodness of fit tests."
  },
  {
    "objectID": "z4_learnR.html#drop-in-deviance-test",
    "href": "z4_learnR.html#drop-in-deviance-test",
    "title": "4 Log Reg II",
    "section": "Drop-in-deviance test",
    "text": "Drop-in-deviance test\nJust a reminder that the drop in deviance test is different from the deviance goodness of fit test. Whereas the deviance goodness of fit test provides a comparison between a single fitted model and a saturated model, a drop in deviance test provides a way to compare two fitted models when one of those models is nested within the other one. Put another way, the drop in deviance test is a comparison between a reduced model (null hypothesis) and a full model (alternative hypothesis) and we use it in cases where the reduced model is reduced from (or nested in) the full model.\nUsing the models we have already fit, let’s use the anova() function to perform a drop in deviance test comparing a reduced model (only logDose included) to a full model (logDose and logDose2 included):\n\nanova(mod6, mod7,test=\"Chisq\")\n\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n18\n68.89661\nNA\nNA\nNA\n\n\n17\n26.04806\n1\n42.84856\n0\n\n\n\n\n\n\nThe p-value of the drop in deviance test is quite small, p &lt; 0.0001. This provides convincing evidence in favor of the full model; namely, the one that includes logDose and logDose2."
  },
  {
    "objectID": "z4_learnR.html#information-criteria-for-model-comparison",
    "href": "z4_learnR.html#information-criteria-for-model-comparison",
    "title": "4 Log Reg II",
    "section": "Information criteria for model comparison",
    "text": "Information criteria for model comparison\nLet’s look at the LRstats again, this time with a focus on the first two columns:\n\nLRstats(mod5, mod6,mod7)\n\n\n\n\n\n\nAIC\nBIC\nLR Chisq\nDf\nPr(&gt;Chisq)\n\n\n\n\nmod5\n368.4449\n370.4364\n277.04682\n18\n0.0000000\n\n\nmod6\n160.2947\n162.2862\n68.89661\n18\n0.0000001\n\n\nmod7\n119.4461\n122.4333\n26.04806\n17\n0.0735894\n\n\n\n\n\n\nThe AIC and BIC, as you may recall from Data Analytics I, are likelihood-based methods for comparing models. Both penalize models with more parameters, but the BIC generally applies a larger penalty (and hence promotes selection of simpler models). Models with smaller values are preferred. The AIC or BIC of a single model is not a measure of the goodness of fit for that model the information criteria are only meaningful as comparisons between models. The information criteria can be applied to compare models which are not nested (neither model’s parameters are a strict subset of the other’s), as long as each model has a likelihood.\n\nWhich of these three candidate models would we choose, based on the information criteria? Does this align with the conclusion from the drop-in-deviance test, given that mod6 is nested within mod7?"
  },
  {
    "objectID": "z4_learnR.html#deviance-residuals-pearson-residuals---dispersion-parameter-estimated-from-pearson-chi-squared",
    "href": "z4_learnR.html#deviance-residuals-pearson-residuals---dispersion-parameter-estimated-from-pearson-chi-squared",
    "title": "4 Log Reg II",
    "section": "Deviance residuals, Pearson residuals - dispersion parameter estimated from Pearson – chi squared",
    "text": "Deviance residuals, Pearson residuals - dispersion parameter estimated from Pearson – chi squared\nIn the case of binomial logistic regression it can be helpful to look at the deviance and/or Pearson residuals to (a) evaluate the model fit and (b) check for outliers. Provided that the binomial counts are fairly large, both the deviance and Pearson residuals should look like draws from a standard Normal distribution, so too many residuals outside of the [-2,2] interval may be cause for concern. Here’ we’ll look at a few plots of both the deviance and Pearson residuals.\n\ntumors$residuals_deviance &lt;- residuals(mod7)\ntumors$residuals_pearson &lt;- residuals(mod7, type = \"pearson\")\nggplot(data = tumors, aes(logDose,residuals_deviance)) + geom_point()\n\n\n\n\n\n\n\nggplot(data = tumors, aes(logDose,residuals_pearson)) + geom_point()\n\n\n\n\n\n\n\nggplot(data = tumors, aes(residuals_deviance,residuals_pearson)) + geom_point()\n\n\n\n\n\n\n\n\nThere are no obvious patterns in either of the plots showing the residuals against logDose, and there are also no outliers. This is all good, it suggests that we’ve done a good job at modeling the log odds of tumors (although we still have to talk about the over dispersion). We created the scatterplot of the Pearson residuals versus the deviance residuals just so you could see how similar they are. For the most part, they fall along the y = x diagonal.\nWhen looking at residuals, it can also be useful to plot the residuals versus the fitted values of a model. Again, we’re hoping that we don’t see any patterns in such a plot:\n\ntumors$fitted = predict.glm(mod7,scale=\"link\")\nggplot(data = tumors, aes(fitted,residuals_deviance)) + geom_point()\n\n\n\n\n\n\n\n\nThere are no clear patterns or problems with this plot, so again we have confirmation that we’re using a decent model at this point."
  },
  {
    "objectID": "z4_learnR.html#question",
    "href": "z4_learnR.html#question",
    "title": "4 Log Reg II",
    "section": "Question",
    "text": "Question\nHere we will return to the UCBAdmissions dataset and fit a logistic regression model for the count of students admitted (out of the total applicants) for each combination of the factors gender and department.\n\n\n\n\n\n\nSome tips for part (a):\n\n\n\n\n\n\nYou can use the group argument to geom_line() to connect points within a group for instance, given a plot with Gender on the x axis and a variable called eLogits on the y, you could add geom_line(aes(group = Dept, x = Gender, y = eLogits)), where the slope of the connecting lines would correspond to the sign and magnitude of the difference in empirical logits (log of observed odds ratio) between genders within each department.\nYou can also incorporate information about the total number of applicants to each department into your plot. For instance, supposing you had a data frame with separate columns containing counts of “Admitted” and “Rejected” by sex and department, you could map the number of applicants to the size of the plot points using geom_point(size = Admitted + Rejected)."
  },
  {
    "objectID": "z4_learnR.html#a-plot",
    "href": "z4_learnR.html#a-plot",
    "title": "4 Log Reg II",
    "section": "a Plot",
    "text": "a Plot\nFit a logistic regression model for the count of students admitted (out of the total applicants) for each combination of the factors gender and department.\n\nConstruct an informative ggplot() of the empirical logits of admission proportion vs gender and department. It’s up to you what aesthetics to map to which variables, there is more than one right answer here.\n\n\nrm(list = ls())\ndata(\"UCBAdmissions\")\n\ndf &lt;- UCBAdmissions\ndf &lt;- df |&gt; as.data.frame()\ndf &lt;- expand.dft(df)\n\nadmitted &lt;- df |&gt; filter(Admit == \"Admitted\") \nadmitted &lt;- admitted |&gt; dplyr::select(-Admit)\n\n\nb &lt;- admitted |&gt; group_by(Dept) |&gt; dplyr::summarise(\n  tot = n())\n\nb &lt;- left_join(admitted, b, by = \"Dept\")\na &lt;- b |&gt; group_by(Dept, Gender) |&gt; reframe(\n  tot = tot,\n  counts = ifelse(Gender == \"Female\", \n                  sum(ifelse(Gender == \"Female\", 1, 0)), \n                  sum(ifelse(Gender == \"Female\", 0, 1)))\n  )\na &lt;- a |&gt; unique()\na &lt;- a |&gt; mutate(elog = log((counts)/(tot-counts))\n            )\n\n\na |&gt; ggplot() + \n  aes(x = Gender, y = elog, color = Dept, group = Dept) + \n  geom_point(aes(size = as.factor(tot))) + \n  geom_line() + \n  labs(\n    title = \"Difference in the estimated log proportions admitted by gender and department\", \n    subtitle = \"The size of the points reflects the number of students admitted \"\n  )\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\nb &lt;- df |&gt; group_by(Dept, Admit, Gender) |&gt; reframe(\n  tot = n()) |&gt; unique()\n\nb &lt;- b |&gt; pivot_wider(names_from = \"Admit\", values_from = \"tot\")\nc &lt;- b |&gt; group_by(Dept) |&gt; reframe(tot_a = sum(Admitted), \n                               tot_r = sum(Rejected))\nb &lt;- left_join(b,c, by = \"Dept\") |&gt; \n  mutate(tot = tot_a + tot_r, \n         tot_f = Admitted + Rejected\n         )\nb |&gt; head()\n\n\n\n\n\nDept\nGender\nAdmitted\nRejected\ntot_a\ntot_r\ntot\ntot_f\n\n\n\n\nA\nFemale\n89\n19\n601\n332\n933\n108\n\n\nA\nMale\n512\n313\n601\n332\n933\n825\n\n\nB\nFemale\n17\n8\n370\n215\n585\n25\n\n\nB\nMale\n353\n207\n370\n215\n585\n560\n\n\nC\nFemale\n202\n391\n322\n596\n918\n593\n\n\nC\nMale\n120\n205\n322\n596\n918\n325\n\n\n\n\n\n\n\na &lt;- b |&gt; mutate(\n  elog_a = log((Admitted)/(tot_a)),\n  elog_r = log((Rejected)/(tot_r))\n            )\n\n\na |&gt; ggplot() + \n  aes(x = Gender, y = elog_a, color = Dept, group = Dept) + \n  geom_point(aes(size = as.factor(tot_f))) + \n  geom_line() + \n  labs(\n    title = \"Difference in the estimated log proportions admitted by gender and department\", \n    subtitle = \"The size of the points reflects the number of students who applied\"\n  ) +\n  guides(size = \"none\")\n\nWarning: Using size for a discrete variable is not advised."
  },
  {
    "objectID": "z4_learnR.html#b-variability-in-admissions",
    "href": "z4_learnR.html#b-variability-in-admissions",
    "title": "4 Log Reg II",
    "section": "b variability in admissions",
    "text": "b variability in admissions\n\nBased on your plot from (a), which variable (gender or department) appears to account for more of the variability in admissions? Explain.\n\nIt looks like regardless of department, the number of people admitted depends more on the number of applicants than it does on gender. Different departments seem to have a larger gender disparity. Departments A and B account for most of the variability."
  },
  {
    "objectID": "z4_learnR.html#c-fit",
    "href": "z4_learnR.html#c-fit",
    "title": "4 Log Reg II",
    "section": "c Fit",
    "text": "c Fit\n\nFit an appropriate (binomial) logistic regression model for admissions. What is the estimated dispersion parameter? Is there evidence of lack of fit?\n\nFitting a logistic regression model for the count of students admitted (out of the total applicants) for each combination of the factors gender and department.\n\nc &lt;- a |&gt; dplyr::select(Dept, Gender, admit = Admitted, rej = Rejected, tot = tot_f, tot_a, elog_a, elog_r)\n# str(c)\nc &lt;- c |&gt; mutate(Dept = factor(Dept), \n                 Gender = factor(Gender))\nc |&gt; head()\n\n\n\n\n\nDept\nGender\nadmit\nrej\ntot\ntot_a\nelog_a\nelog_r\n\n\n\n\nA\nFemale\n89\n19\n108\n601\n-1.9099586\n-2.8606960\n\n\nA\nMale\n512\n313\n825\n601\n-0.1602703\n-0.0589318\n\n\nB\nFemale\n17\n8\n25\n370\n-3.0802897\n-3.2911965\n\n\nB\nMale\n353\n207\n560\n370\n-0.0470349\n-0.0379192\n\n\nC\nFemale\n202\n391\n593\n322\n-0.4662838\n-0.4215331\n\n\nC\nMale\n120\n205\n325\n322\n-0.9870598\n-1.0672307\n\n\n\n\n\n\n\nm1 &lt;- glm(\n  data = c, \n  family = \"binomial\",\n  cbind(admit, rej) ~ Gender + Dept)\nsummary(m1)\n\n\nCall:\nglm(formula = cbind(admit, rej) ~ Gender + Dept, family = \"binomial\", \n    data = c)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.68192    0.09911   6.880 5.97e-12 ***\nGenderMale  -0.09987    0.08085  -1.235    0.217    \nDeptB       -0.04340    0.10984  -0.395    0.693    \nDeptC       -1.26260    0.10663 -11.841  &lt; 2e-16 ***\nDeptD       -1.29461    0.10582 -12.234  &lt; 2e-16 ***\nDeptE       -1.73931    0.12611 -13.792  &lt; 2e-16 ***\nDeptF       -3.30648    0.16998 -19.452  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 877.056  on 11  degrees of freedom\nResidual deviance:  20.204  on  5  degrees of freedom\nAIC: 103.14\n\nNumber of Fisher Scoring iterations: 4\n\n\n\\(\\hat{\\psi} = 20.204/5 =\\)\n\n20.204/5\n\n[1] 4.0408\n\n\nThere appears to be considerable dispersion\n\npchisq(20.204, 5, lower.tail = F)\n\n[1] 0.001144215\n\n\nThere is evidence of lack of fit. The p-value is low."
  },
  {
    "objectID": "z4_learnR.html#d-plot-of-residuals-vs-fitted-values",
    "href": "z4_learnR.html#d-plot-of-residuals-vs-fitted-values",
    "title": "4 Log Reg II",
    "section": "d plot of residuals vs fitted values",
    "text": "d plot of residuals vs fitted values\n\nConstruct a plot of residuals vs fitted values (try just plot-ing your fitted model object). From this plot, can you identify a source for any fit problems encountered in part (c)?\n\n\nc$fitted &lt;- predict.glm(m1, scale = \"link\")\nc$resids_d &lt;- residuals(m1)\nc$resids_p &lt;- residuals(m1, type = \"pearson\")\nggplot(c) + \n  aes(tot_a, resids_d) + \n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(c) + \n  aes(tot_a, resids_p) + \n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(c) + \n  aes(fitted, resids_d) + \n  geom_point(aes(color = Dept, size = Gender))\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\nThere is an outlier in Department A females. The other departments accepted roughly equal proportions by gender, but dept A accepted about 20% more for female applicants.\n\nc |&gt; mutate(prop = admit/tot) |&gt; relocate(prop, .after = tot) |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDept\nGender\nadmit\nrej\ntot\nprop\ntot_a\nelog_a\nelog_r\nfitted\nresids_d\nresids_p\n\n\n\n\nA\nFemale\n89\n19\n108\n0.8240741\n601\n-1.9099586\n-2.8606960\n0.6819215\n3.7189203\n3.5186674\n\n\nA\nMale\n512\n313\n825\n0.6206061\n601\n-0.1602703\n-0.0589318\n0.5820514\n-1.2486740\n-1.2538077\n\n\nB\nFemale\n17\n8\n25\n0.6800000\n370\n-3.0802897\n-3.2911965\n0.6385236\n0.2706080\n0.2689516\n\n\nB\nMale\n353\n207\n560\n0.6303571\n370\n-0.0470349\n-0.0379192\n0.5386535\n-0.0560085\n-0.0560205\n\n\nC\nFemale\n202\n391\n593\n0.3406408\n322\n-0.4662838\n-0.4215331\n-0.5806765\n-0.9243398\n-0.9207783\n\n\nC\nMale\n120\n205\n325\n0.3692308\n322\n-0.9870598\n-1.0672307\n-0.6805466\n1.2533375\n1.2628723"
  },
  {
    "objectID": "z4_learnR.html#d2-refit",
    "href": "z4_learnR.html#d2-refit",
    "title": "4 Log Reg II",
    "section": "d2 Refit",
    "text": "d2 Refit\n\nRefit the binomial model above, but excluding the data from department A. Now what is the estimated dispersion parameter? Based on the p-value, what would you conclude about the effect of Gender on admissions (to departments other than A) using this model?\n\n\nd &lt;- c |&gt; filter(Dept != \"A\")\n\n# m1 &lt;- glm(\n#   data = c, \n#   family = \"binomial\",\n#   cbind(admit, rej) ~ Gender + Dept)\n# summary(m1)\n\nm2 &lt;- glm(cbind(admit, rej) ~ Gender + Dept, \n          family = \"binomial\", \n          data = d)\nsummary(m2)\n\n\nCall:\nglm(formula = cbind(admit, rej) ~ Gender + Dept, family = \"binomial\", \n    data = d)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.51349    0.11936   4.302 1.69e-05 ***\nGenderMale   0.03069    0.08676   0.354    0.724    \nDeptC       -1.14008    0.12188  -9.354  &lt; 2e-16 ***\nDeptD       -1.19456    0.11984  -9.968  &lt; 2e-16 ***\nDeptE       -1.61308    0.13928 -11.581  &lt; 2e-16 ***\nDeptF       -3.20527    0.17880 -17.927  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 539.4581  on 9  degrees of freedom\nResidual deviance:   2.5564  on 4  degrees of freedom\nAIC: 71.791\n\nNumber of Fisher Scoring iterations: 3\n\n\nNow what is the estimated dispersion parameter? Based on the p-value, what would you conclude about the effect of Gender on admissions (to departments other than A) using this model?\n\\(\\hat{\\psi} = 2.5564/4 =\\)\n\n2.5564/4\n\n[1] 0.6391\n\n\nThere is now no extra binomial variation\n\n# 2.5564  on 4\npchisq(2.5564, 4, lower.tail = F)\n\n[1] 0.6345658\n\n\nThere is no evidence of lack of fit. It appears there is no evidence of discrimination on the basis of gender outside of department A."
  },
  {
    "objectID": "z4_learnR.html#e-confint",
    "href": "z4_learnR.html#e-confint",
    "title": "4 Log Reg II",
    "section": "e Confint",
    "text": "e Confint\n\nThe approach in part (d) allowed us to keep the binomial likelihood model, but only by performing an unprincipled exclusion of some apparently-legitimate data that happened to be “outlying”.\n\nTo avoid this, we’ll refit the model for all departments with the quasibinomial family.\nUsing the quasibinomial model for all departments, what do you conclude about the effect of Gender on admissions? Support your conclusion by constructing and interpreting a 95% confidence interval for\n\\(P_{diff} = [P(Admit | (Department, Male)) - P(Admit | (Department, Female))]\\)\nThat is, construct an interval on the model scale, then back-transform to the data scale. Be careful with the direction (male higher or female higher) of the observed difference in conditional probability of admission.\n\nfit a quasibinomial\nconclusion for gender on admissions.\nconstruct CI for difference in probability m - f, and interpret\n\n\nconsruct on model scale\nback-transform to data scale\ncare for direction\n\n\n1. fit a quasibinomial\n\nc &lt;- c |&gt; dplyr::select(dept = Dept, gender = Gender, admit, rej, tot, tot_a, elog_a, elog_r)\nc &lt;- c |&gt; mutate(prop = admit/tot) |&gt; relocate(prop, .after = tot)\n\n# m1 &lt;- glm(\n#   data = c, \n#   family = \"binomial\",\n#   cbind(admit, rej) ~ Gender + Dept)\n\nm3 &lt;- glm(data = c, \n          family = \"quasibinomial\", \n          cbind(admit, rej) ~ gender + dept)\ns3 &lt;- summary(m3)\ns3\n\n\nCall:\nglm(formula = cbind(admit, rej) ~ gender + dept, family = \"quasibinomial\", \n    data = c)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.68192    0.19231   3.546 0.016458 *  \ngenderMale  -0.09987    0.15687  -0.637 0.552355    \ndeptB       -0.04340    0.21312  -0.204 0.846672    \ndeptC       -1.26260    0.20690  -6.102 0.001711 ** \ndeptD       -1.29461    0.20533  -6.305 0.001477 ** \ndeptE       -1.73931    0.24470  -7.108 0.000854 ***\ndeptF       -3.30648    0.32982 -10.025 0.000169 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasibinomial family taken to be 3.764856)\n\n    Null deviance: 877.056  on 11  degrees of freedom\nResidual deviance:  20.204  on  5  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nlogistic &lt;- function(x){exp(x)/(1 + exp(x))}\nodds &lt;- exp(m3$coefficients)\nprob &lt;- logistic(m3$coefficients)\nodds\n\n(Intercept)  genderMale       deptB       deptC       deptD       deptE \n 1.97767415  0.90495497  0.95753028  0.28291804  0.27400567  0.17564230 \n      deptF \n 0.03664494 \n\n# prob\n# plogis(m3$coefficients)\n\n\n\n2. conclusion for gender on admissions.\nUsing the quasibinomial model for all departments, what do you conclude about the effect of Gender on admissions?\n\nlogodds_admit &lt;- function(f=0,m=0, B=0,C=0,D=0,E=0,F_=0) {\n  (0.68192148*f) + ((0.68192148 - 0.09987009)*m) + \n  (-0.04339793*B) + (-1.26259802*C) + \n  (-1.29460647*D) + (-1.73930574*E) + \n  (-3.30648006*F_)\n}\n\n\nfemale &lt;- c(\nlogodds_admit(f= 1),\nlogodds_admit(f=1, B= 1),\nlogodds_admit(f=1, C= 1),\nlogodds_admit(f=1, D= 1),\nlogodds_admit(f=1, E= 1),\nlogodds_admit(f=1, F_=1))\n\nmale &lt;- c(\nlogodds_admit(m=1),\nlogodds_admit(m=1, B= 1),\nlogodds_admit(m=1, C= 1),\nlogodds_admit(m=1, D= 1),\nlogodds_admit(m=1, E= 1),\nlogodds_admit(m=1, F_= 1))\n\nf_odds &lt;- female |&gt; exp()\nm_odds &lt;- male|&gt; exp()\n# f_odds\n# m_odds\n\nround(plogis(female)*100, 2)\n\n[1] 66.42 65.44 35.88 35.14 25.78  6.76\n\nround(plogis(male)*100, 2)\n\n[1] 64.15 63.15 33.61 32.90 23.92  6.15\n\n\nThe probability of males or females making it into any given departments are estimated to be roughly equal.\n\n\n3. construct CI\n\nconstruct CI for difference in probability m - f, and interpret\n\n\nconsruct on model scale\nback-transform to data scale\ncare for direction\n\nSupport your conclusion by constructing and interpreting a 95% confidence interval for\n\\(P_{diff} = [P(Admit | (Department, Male)) - P(Admit | (Department, Female))]\\)\n\nci3 &lt;- confint.default(m3)\nci3\n\n                 2.5 %     97.5 %\n(Intercept)  0.3049994  1.0588436\ngenderMale  -0.4073263  0.2075862\ndeptB       -0.4611114  0.3743155\ndeptC       -1.6681191 -0.8570769\ndeptD       -1.6970492 -0.8921637\ndeptE       -2.2189109 -1.2597006\ndeptF       -3.9529149 -2.6600453\n\n# ci3 |&gt; exp()\n# (ci3 |&gt; exp())^-1\n\nci3[2] |&gt; exp()\n\n[1] 0.665427\n\nci3[9] |&gt; exp()\n\n[1] 1.230704\n\n\n\n0.665427^-1\n\n[1] 1.502794\n\n1.230704\n\n[1] 1.230704\n\n\nThe ratio of students admitted by sex is estimated to be 1.11 females per male. With 95% confidence, the upper and lower bounds of the ratio of admitted students is between 1.5 females per male and 1.23 males per female. Department doesn’t matter.\n\ncoefs &lt;- m3$coefficients\ncoefs\n\n(Intercept)  genderMale       deptB       deptC       deptD       deptE \n 0.68192148 -0.09987009 -0.04339793 -1.26259802 -1.29460647 -1.73930574 \n      deptF \n-3.30648006 \n\n0.68192148 -0.09987009\n\n[1] 0.5820514\n\nexp(-0.09987009)^-1\n\n[1] 1.105027\n\n\n\n1.35662419*0.66542700 \n\n[1] 0.9027344\n\n\n\n2.88303501*1.23070375\n\n[1] 3.548162\n\n\n\n2.038727/(2.038727+1)\n\n[1] 0.6709148\n\n\n\nlogodds_admit &lt;- function(f=0,m=0, B=0,C=0,D=0,E=0,F_=0) {\n  (0.68192148*f) + ((0.68192148 - 0.09987009)*m) + \n  (-0.04339793*B) + (-1.26259802*C) + \n  (-1.29460647*D) + (-1.73930574*E) + \n  (-3.30648006*F_)\n}\n\n\nfemale &lt;- c(\nlogodds_admit(f= 1),\nlogodds_admit(f=1, B= 1),\nlogodds_admit(f=1, C= 1),\nlogodds_admit(f=1, D= 1),\nlogodds_admit(f=1, E= 1),\nlogodds_admit(f=1, F_=1))\n\nmale &lt;- c(\nlogodds_admit(m=1),\nlogodds_admit(m=1, B= 1),\nlogodds_admit(m=1, C= 1),\nlogodds_admit(m=1, D= 1),\nlogodds_admit(m=1, E= 1),\nlogodds_admit(m=1, F_= 1))\n\nf_odds &lt;- female |&gt; exp()\nm_odds &lt;- male|&gt; exp()\n# f_odds\n# m_odds\n\nround(plogis(female)*100, 2)\n\n[1] 66.42 65.44 35.88 35.14 25.78  6.76\n\nround(plogis(male)*100, 2)\n\n[1] 64.15 63.15 33.61 32.90 23.92  6.15\n\n\n\ncoefs &lt;- m3$coefficients\ncoefs\n\n(Intercept)  genderMale       deptB       deptC       deptD       deptE \n 0.68192148 -0.09987009 -0.04339793 -1.26259802 -1.29460647 -1.73930574 \n      deptF \n-3.30648006 \n\nest &lt;- s3$coefficients[1:7]\nest\n\n[1]  0.68192148 -0.09987009 -0.04339793 -1.26259802 -1.29460647 -1.73930574\n[7] -3.30648006\n\nSE &lt;- s3$coefficients[8:14]\nSE\n\n[1] 0.1923107 0.1568683 0.2131230 0.2069023 0.2053317 0.2447010 0.3298197\n\nci3 &lt;- confint.default(m3)\nci3\n\n                 2.5 %     97.5 %\n(Intercept)  0.3049994  1.0588436\ngenderMale  -0.4073263  0.2075862\ndeptB       -0.4611114  0.3743155\ndeptC       -1.6681191 -0.8570769\ndeptD       -1.6970492 -0.8921637\ndeptE       -2.2189109 -1.2597006\ndeptF       -3.9529149 -2.6600453\n\n\n\ncoefs[1]\n\n(Intercept) \n  0.6819215 \n\nSE[1]\n\n[1] 0.1923107\n\ncoefs[1] + SE[1]*qnorm(.975)\n\n(Intercept) \n   1.058844 \n\ncoefs[1] - SE[1]*qnorm(.975)\n\n(Intercept) \n  0.3049994 \n\n\n\ntest &lt;- data.frame(group = c(\"fa\",\"ma\", 'fb', 'fc', 'fd', 'fe', 'ff'),\n                   est = est, \n                   se = SE, \n                   crt_v = rep(qnorm(.975), 7))\n\ntest &lt;- test |&gt; mutate(low = est - se*crt_v,\n                       upp = est + se*crt_v)\n\n\n# test2 |&gt; dplyr::select(gro)\n\n\nfemale\n\n[1]  0.6819215  0.6385235 -0.5806765 -0.6126850 -1.0573843 -2.6245586\n\n\n\nci3\n\n                 2.5 %     97.5 %\n(Intercept)  0.3049994  1.0588436\ngenderMale  -0.4073263  0.2075862\ndeptB       -0.4611114  0.3743155\ndeptC       -1.6681191 -0.8570769\ndeptD       -1.6970492 -0.8921637\ndeptE       -2.2189109 -1.2597006\ndeptF       -3.9529149 -2.6600453\n\n\n\nfemale\n\n[1]  0.6819215  0.6385235 -0.5806765 -0.6126850 -1.0573843 -2.6245586\n\nmale\n\n[1]  0.5820514  0.5386535 -0.6805466 -0.7125551 -1.1572544 -2.7244287\n\nround(plogis(female)*100, 2)\n\n[1] 66.42 65.44 35.88 35.14 25.78  6.76\n\nround(plogis(male)*100, 2)\n\n[1] 64.15 63.15 33.61 32.90 23.92  6.15\n\n\n\nDiff in prob m - f\n\ncoefs\n\n(Intercept)  genderMale       deptB       deptC       deptD       deptE \n 0.68192148 -0.09987009 -0.04339793 -1.26259802 -1.29460647 -1.73930574 \n      deptF \n-3.30648006 \n\n\n\nf &lt;- c()\nf &lt;- append(f, logodds_admit(f=1))\nf &lt;- append(f, logodds_admit(f=1, B = 1))\nf &lt;- append(f, logodds_admit(f=1, C = 1))\nf &lt;- append(f, logodds_admit(f=1, D = 1))\nf &lt;- append(f, logodds_admit(f=1, E = 1))\nf &lt;- append(f, logodds_admit(f=1, F_= 1))\n\nm &lt;- c()\nm &lt;- append(m, logodds_admit(m=1))\nm &lt;- append(m, logodds_admit(m=1, B = 1))\nm &lt;- append(m, logodds_admit(m=1, C = 1))\nm &lt;- append(m, logodds_admit(m=1, D = 1))\nm &lt;- append(m, logodds_admit(m=1, E = 1))\nm &lt;- append(m, logodds_admit(m=1, F_= 1))\n\nf\n\n[1]  0.6819215  0.6385235 -0.5806765 -0.6126850 -1.0573843 -2.6245586\n\nm\n\n[1]  0.5820514  0.5386535 -0.6805466 -0.7125551 -1.1572544 -2.7244287\n\n\n\nexp(m)\n\n[1] 1.78970605 1.71369775 0.50634014 0.49038961 0.31434809 0.06558366\n\nexp(0.58205)\n\n[1] 1.789704\n\n\n\nplogis(male) \n\n[1] 0.64153929 0.63149912 0.33613931 0.32903451 0.23916654 0.06154717\n\nplogis(female)\n\n[1] 0.6641674 0.6544196 0.3587769 0.3514470 0.2578096 0.0675745\n\n# Pr(Admit|Male) - Pr(Admit|Female)\n(plogis(male) - plogis(female))*100\n\n[1] -2.2628122 -2.2920508 -2.2637625 -2.2412452 -1.8643101 -0.6027326\n\n\nFemales are estimated to be favored by about 2% in all departments except F. There they are only favored by about 0.6%\n\nfemale |&gt; exp()\n\n[1] 1.97767415 1.89368289 0.55951970 0.54189393 0.34736323 0.07247174\n\nmale |&gt; exp()\n\n[1] 1.78970605 1.71369775 0.50634014 0.49038961 0.31434809 0.06558366\n\nexp(-0.09987009)\n\n[1] 0.904955\n\n\n\n1.97767415 *0.904955\n\n[1] 1.789706\n\n\n\n1.89368289 *0.904955\n\n[1] 1.713698"
  },
  {
    "objectID": "z4_learnR.html#probs",
    "href": "z4_learnR.html#probs",
    "title": "4 Log Reg II",
    "section": "Probs",
    "text": "Probs\n\\(P_{diff} = [P(Admit | (Department, Male)) - P(Admit | (Department, Female))]\\)\n\n# male v female department a\n# plogis(0.68192) # P(a|f,a)\nplogis(j[1]) # P(a|f,a)\n\n(Intercept) \n  0.6641674 \n\n# plogis(0.68192-0.09987)# P(a|m,a)\nplogis(j[1] + j[2])\n\n(Intercept) \n  0.6415393 \n\n\nThe difference for all sets below favor the females.\n\nplogis(j[1] + j[2]) - plogis(j[1])\n\n(Intercept) \n-0.02262812 \n\n\nIn department a female has slightly higher probability of admittance.\n\n# m v f, dept b\nplogis(j[2] + j[3]) - plogis(j[1] + j[3])\n\ngenderMale \n-0.1901755 \n\n\nIn department B, female has more probability of admittance.\n\n# # m v f, dept c\nplogis(j[2] + j[4])- plogis(j[1] + j[4])\n\ngenderMale \n-0.1549375 \n\n\nAgain, female is more probale.\n\n# # m v f, dept d\nplogis(j[2] + j[5])- plogis(j[1] + j[5])# P(a|f,d)\n\ngenderMale \n-0.1527529 \n\n\n\n# # m v f, dept e\nplogis(j[2] + j[6])- plogis(j[1] + j[6])# P(a|f,e)\n\ngenderMale \n-0.1206608 \n\n\n\n# # m v f, dept e\nplogis(j[2] + j[7])- plogis(j[1] + j[7])# P(a|f,f)\n\ngenderMale \n-0.0354769 \n\n\n\nci3 |&gt; exp()\n\n                 2.5 %     97.5 %\n(Intercept) 1.35662419 2.88303501\ngenderMale  0.66542700 1.23070375\ndeptB       0.63058244 1.45399583\ndeptC       0.18860147 0.42440082\ndeptD       0.18322338 0.40976816\ndeptE       0.10872746 0.28373897\ndeptF       0.01919866 0.06994506"
  },
  {
    "objectID": "z2_learnR.html",
    "href": "z2_learnR.html",
    "title": "2 Odds and risks",
    "section": "",
    "text": "In the previous lab, we showed how to produce descriptive statistics that quantify relationships between categorical variables observed on a given sample. No formal attempt was made to extend conclusions beyond the sample. In this lab, we will explore methods for making inference about the association between two categorical variables in a larger population of interest. The usual caveats apply, including but not limited to:\n\nThese methods cannot be interpreted in a straightforward way unless the data are an independent sample from a well-defined population of interest, obtained using a probability (random) mechanism.\nThese methods are not necessarily robust to extreme outliers or large quantities of missing data. Intending to do inference does not eliminate the need for exploratory checks on data quality.\nThe probabilistic “guarantees” attached to these inferential methods do not hold in the context of using the same data to generate hypotheses and test them. See R for Data Science, Chapter 22 for advice about using “holdout data” when you’re serious about formal inference.\n\n\n\n\n\n\n\nNotation for I x J Tables\n\n\n\n\n\nHere is a glossary of terms and notation that we’ll use throughout the lab (and the course).\nMathematical expressions are formatted with dollar signs for improved appearance in the HTML document. When reading the .Rmd script, in RStudio, moving your cursor over something between dollar signs “pops out” the formatted mathematical expression from that location on the screen.\n\n\\(I\\) denotes the number of rows in a 2-way table of counts, \\(J\\) denotes the number of columns\n\\(X\\) denotes the “row variable” – a categorical random variable (factor) taking on I possible values \\(x_1, ..., x_I\\)\n\\(Y\\) denotes the “column variable” – a categorical random variable taking on \\(J\\) possible values \\(y_1,...,y_J\\)\nThe cells in a 2-way table are indexed by \\(i\\) and \\(j\\), where \\(i\\) in \\(1:I\\) is the row index and \\(j\\) in \\(1:J\\) is the column index\n\\(N\\) is the total count over the whole table, and \\(n_{ij}\\) is the count in the \\(i,j\\) cell. That is, the number of observation for which \\(X = x_i\\) and \\(Y = y_j\\)\n\\(p_{ij}\\) is the proportion, out of the N observations, which fall in the \\(i,j\\) cell (so \\(p_{ij} = n_{ij}/N\\))\n\\(p_i.\\) is the ith row proportion, and \\(p._j\\) the \\(j\\)th column proportion – the . notation suggests that we’ve summed over/collapsed the index it replaces\n\n\n\n\n\n\nWe’ll use the following packages in this lab:\n\nlibrary(magrittr)\nlibrary(vcdExtra)\nlibrary(tidyverse)"
  },
  {
    "objectID": "z2_learnR.html#load-packages-for-the-lab",
    "href": "z2_learnR.html#load-packages-for-the-lab",
    "title": "2 Odds and risks",
    "section": "",
    "text": "We’ll use the following packages in this lab:\n\nlibrary(magrittr)\nlibrary(vcdExtra)\nlibrary(tidyverse)"
  },
  {
    "objectID": "z2_learnR.html#statistical-independence-for-contingency-tables",
    "href": "z2_learnR.html#statistical-independence-for-contingency-tables",
    "title": "2 Odds and risks",
    "section": "Statistical Independence for Contingency Tables",
    "text": "Statistical Independence for Contingency Tables\nIn terms of the sample proportions that we can estimate from an \\(I \\times J\\) contingency table, the independence relation is (check the Notation Section above):\n\\[p_{ij} = p_i.p._j\\]\nIn words: the cell probability for the \\(i,j\\) cell is equal to the marginal probability of the \\(i^{th}\\) row times the marginal probability of the \\(j^{th}\\) column.\nBecause we don’t know the underlying joint probability distribution that leads to a specific, observed contingency table, we can only evaluate the independence assumption on the basis of the sample independence relation, \\(p_ij = p_i.p._j\\). We say that a contingency table is the most consistent with statistical independence if \\(p_{ij} = p_i.p._j\\) for all \\(i,j\\). And, the extent to which the observed counts in a table deviate from \\(p_{ij} = p_i.p._j\\) for all \\(i,j\\) provides us with evidence against the statistical independence hypothesis."
  },
  {
    "objectID": "z2_learnR.html#plots",
    "href": "z2_learnR.html#plots",
    "title": "2 Odds and risks",
    "section": "Plots",
    "text": "Plots\nYou can use mosaic plots to get a sense for the independence or lack of independence in \\(I \\times J\\) tables. In general, when the two variables of an \\(I \\times J\\) table are independent, then the vertical splits in the mosaic plot of that table should (approximately) line up. Actually, depending on the complexity of the mosaic plot, it may be that you’re looking for the horizontal splits to line up, but in the examples here, it’s the vertical splits.\nRun the following chunk of R code to see some examples.\n\n# Approximately independent \n tab1 &lt;- matrix(c(45,10,50,14,35,12),3,2,byrow=TRUE)\n mosaic(tab1)\n\n\n\n\n\n\n\n# Probably not independent\n tab2 &lt;- matrix(c(45,10,14,50,35,12),3,2,byrow=TRUE)\n mosaic(tab2)\n\n\n\n\n\n\n\n\nIntuitively, the closer the vertical splits are to being aligned, the closer the observed table of counts will be to the expected table of counts. You can play around with adjusting the cell counts in the code above give yourself a better understanding of the mosaic plot as a tool for evaluating statistical independence visually.\nA closely-related visualization is the sieve plot, which first draws the outline of the mosaic plot that we would expect to see under the assumption of independence (i.e., with the splits lined up). It then fills in each cell of this outline with a grid of squares, scaled so that \\(n_{ij}\\) squares fit within the \\(ij^{th}\\) cell. Thus, cells with bigger-than-expected counts are filled with denser grids, and cells with smaller-than-expected counts are filled with sparser grids. For extra clarity, the “underfilled” cells are shaded red and the “overfilled” cells shaded blue.\n\n# Approximately independent \n sieve(tab1, shade = TRUE)\n\n\n\n\n\n\n\n# Probably not independent\n sieve(tab2, shade = TRUE)\n\n\n\n\n\n\n\n\nThe grid sizes on the first sieve plot are approximately the same, indicating independence; whereas the grid sizes on the second plot are different, indicating a departure from independence."
  },
  {
    "objectID": "z2_learnR.html#standard-case-large-sample-size",
    "href": "z2_learnR.html#standard-case-large-sample-size",
    "title": "2 Odds and risks",
    "section": "Standard Case (large sample size)",
    "text": "Standard Case (large sample size)\nWhen the sample size is large, the reference distribution for the chi-squared statistic is a Chi-squared distribution with \\((I-1) \\times (J-1)\\) degrees of freedom.\nYou saw the Berkeley Admissions data in the M1L4 narrated lecture. These data are available in R as the object UCBAdmissions. We’ll use the UCBAdmissions data collapsed over department to consider the independence of admission and gender (we know that department matters here, but using the aggregated table is useful as an illustration).\nUCBAdmissions stores the data in a 2 x 2 x 6 array, so we’ll first collapse over the third dimension (department) using the margin.table() function, and then perform the \\(\\chi^2\\) test. Please run this chunk of R code (if you haven’t already).\n\n(UCBA_sum &lt;- margin.table(UCBAdmissions,c(1,2)))\n\n          Gender\nAdmit      Male Female\n  Admitted 1198    557\n  Rejected 1493   1278\n\nchisq.test(UCBA_sum)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  UCBA_sum\nX-squared = 91.61, df = 1, p-value &lt; 2.2e-16\n\n\nThere are several things to notice.\n\nThe R output for the test is titled Pearson's Chi-squared test with Yates' continuity correction. We’ll have some comments about the continuity correction below.\nNotice that the value of X-squared, which is the chi-squared statistic is 91.61, df = 1 since UCBA_sum is a 2 x 2 table.\nThe p-value associated with this test statistic is very small. We can report it as p &lt; 0.0001. This provides convincing evidence that admission and gender are not independent. Let’s also take a quick look at the mosaic plot:\n\n\nmosaic(UCBA_sum)\n\n\n\n\n\n\n\n\nThe vertical split between Male and Female in the Admitted group is substantially farther to the right than the vertical split between Male and Female in the Rejected group. Evidence that the two variables, Admit and Gender, are not independent.\nWhat about the continuity correction? There’s actually quite a bit of data in the UCBAdmissions dataset, with N = 4526. In this case, the continuity correction doesn’t make that much difference. In fact, run the following code and compare the X-squared values and the p-values when correct = TRUE (the default) and when correct = FALSE.\n\nchisq.test(UCBA_sum)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  UCBA_sum\nX-squared = 91.61, df = 1, p-value &lt; 2.2e-16\n\nchisq.test(UCBA_sum,correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  UCBA_sum\nX-squared = 92.205, df = 1, p-value &lt; 2.2e-16\n\n\nYou should notice that the X-squared value changed a little bit without the continuity correction, but the p-value didn’t change at all. This is fairly typical with really large sample sizes like we have here. The continuity correction doesn’t really make any difference for our inference we still have really strong evidence that admission and gender are not independent.\nThe continuity correction was introduced to accommodate the use of a continuous probability distribution (the \\(\\chi^2\\) distribution) as the reference distribution for a statistic calculated from non-continuous (i.e., categorical) data. Simply put, it makes the performance of the \\(\\chi^2\\) statistic better (in terms of type II error) when the sample size is of moderate size. We recommend that you simply use the default, correct = TRUE.\nThe \\(\\chi^2\\) test is also called a test for homogeneity in some situations, and the UCBAdmissions dataset provides a good example. Another way that we could consider the independence (or lack of association) between admission and gender is to ask whether the proportion of males admitted is the same as the proportion of females admitted. Put another way, we ask whether the proportions of admits are the same (homogeneous) between the two groups, males and females:\n\n# transpose the UCBA_sum matrix, so Gender is row the variable:\n(UCBA_sum2 &lt;- t(UCBA_sum))\n\n        Admit\nGender   Admitted Rejected\n  Male       1198     1493\n  Female      557     1278\n\n# perform the test for a difference in two proportions: \nprop.test(UCBA_sum2)\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  UCBA_sum2\nX-squared = 91.61, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.1129887 0.1703022\nsample estimates:\n   prop 1    prop 2 \n0.4451877 0.3035422 \n\n\nWhen you run this R chunk, you see the identical X-squared statistic to what we got from running chisq.test(UCBA_sum).\nYou’ll also get some output that tells you about the difference between the two admit proportions. That the 95% confidence interval for the difference in the two proportions, 0.113 to 0.170, does not contain zero is another way for us to communicate that we have strong evidence that the two admit proportions are not the same, i.e. that the two genders are not homogeneous in terms of admissions.\nRecall again: simply summarizing this particular dataset using this 2 x 2 table is perilous we know there’s more to the story here. Indeed, if we collapsed over the admission decision to see the total numbers of applicants within each department, we could use the chi-squared test on this table to see that gender-specific application rates are not homogeneous, which suggests that collapsing over the departments could be a problem.\n\n(UCBApplicants &lt;- margin.table(UCBAdmissions, c(2,3)))\n\n        Dept\nGender     A   B   C   D   E   F\n  Male   825 560 325 417 191 373\n  Female 108  25 593 375 393 341\n\nchisq.test(UCBApplicants)\n\n\n    Pearson's Chi-squared test\n\ndata:  UCBApplicants\nX-squared = 1068.4, df = 5, p-value &lt; 2.2e-16\n\n\nNevertheless, it’s been useful to use the summary data for illustrating equivalence between the chi-squared test and the difference in proportions test."
  },
  {
    "objectID": "z2_learnR.html#data-lady-tasting-tea",
    "href": "z2_learnR.html#data-lady-tasting-tea",
    "title": "2 Odds and risks",
    "section": "Data: Lady Tasting Tea",
    "text": "Data: Lady Tasting Tea\nThe Lady Tasting Tea is a classic (and classically British) example given by Sir Ronald Fisher to motivate the “exact test” which now bears his name. Briefly, in the tea-tasting experiment, a woman was presented with eight cups of tea four of which she knew to have had the tea poured first, and four of which she knew to have had the milk poured first, and she was asked to distinguish which cups had tea first and which had milk first.\nThe data from this experiment naturally fall into a 2x2 table where one dimension represents the lady’s guesses and the other dimension represents the truth. See the Examples in the help file for fisher.test() for a full description of these data.\n\nThere’s also a good book called, not surprisingly, “The Lady Tasting Tea,” by David Salsburg that gives an entertaining early history of Statistics.\n\nThe following R chunk recreates the Lady Tasting Tea data.\n\nTeaTasting &lt;-\nmatrix(c(3, 1, 1, 3),\n    nrow = 2,\n    dimnames = list(Guess = c(\"Milk\", \"Tea\"),\n            Truth = c(\"Milk\", \"Tea\")))\nTeaTasting\n\n      Truth\nGuess  Milk Tea\n  Milk    3   1\n  Tea     1   3\n\n\nThere’s nothing to prevent us from applying the chisq.test() function to the TeaTasting data:\n\nchisq.test(TeaTasting, correct = FALSE)\n\nWarning in chisq.test(TeaTasting, correct = FALSE): Chi-squared approximation\nmay be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  TeaTasting\nX-squared = 2, df = 1, p-value = 0.1573\n\n\nWe do get an answer, but also the helpful warning that “Chi-squared approximation may be incorrect.” Why so? (It’s not because we said correct = FALSE the same warning will appear either way).\nWe now present a simulation that should give you some insight into the problem here."
  },
  {
    "objectID": "z2_learnR.html#parametric-bootstrapping",
    "href": "z2_learnR.html#parametric-bootstrapping",
    "title": "2 Odds and risks",
    "section": "Parametric bootstrapping",
    "text": "Parametric bootstrapping\nThe hypothesis of row-column independence can be expressed mathematically in terms of a probability distribution over the cell counts in a table. With R, if you can “draw” a new table from that distribution, you can draw a thousand. Then, you can compute a \\(\\chi^2\\) statistic for each new table, and it turns out that you can use all of those recomputed statistics to approximate the sampling (reference) distribution of that statistic.\nThis idea (sample from a known distribution, calculate a test statistic, repeat) is closely related to the (perhaps familiar) idea of bootstrapping, in which a test statistic is calculated on re-samples (with replacement) from the original sample of data. There are entire books written about bootstrapping, and it’s well beyond the scope of this course to go into details here. We use this technique here to help illustrate the limitations of the Chi-squared distribution as the reference distribution for the \\(\\chi^2\\) statistic in the case of small counts.\nThe essential result is that the reference distribution we get using our re-sampling technique is closer to the true reference distribution of the \\(\\chi^2\\) statistic than is the \\(\\chi^2\\) distribution when the sample size is small (simulation works just fine when the sample size is large as well, it’s just a waste of computation when the known large-sample distribution applies).\nThere are some other tricky details here, because there are multiple probability distributions over cell counts that are consistent with the verbal statement “rows and columns are independent.” For now we’ll just take the simulation script below as given. If you’re interested in some of these details, please see the optional “Sampling Models” section below.\nOnce the re-sampling script computes a lot of chi-squared statistics (stored in resamp$stats) for tables drawn under the hypothesis of independence, we see where we stand by plotting the distribution of those re-sampled chi-squared statistics, and comparing it to the theoretical Chi-squared distribution on a plot.\n\nRunning this R chunk just creates the function we need for re-sampling.\n\n\ntwo_way_resample &lt;- function(tab, nsim = 2000, fixed_margins = \"none\") {\n  \n  \n  stopifnot(fixed_margins %in% c(\"none\", \"columns\", \"rows\", \"both\"))\n  \n  new_two_way &lt;- function(tab, fixed_margins = \"none\"){\n    I &lt;- nrow(tab)\n    J &lt;- ncol(tab) \n    n_i. &lt;- rowSums(tab) \n    n._j &lt;- colSums(tab)\n    N &lt;- sum(tab)\n    null_probs &lt;- (n_i. %*% t(n._j))/(N^2)\n    new_table &lt;- matrix(0, I, J)\n    \n    # Generate random table as SINGLE multinomial sample of size N, preserving neither row nor column margins.\n    if(fixed_margins == \"none\"){\n      new_table &lt;- rmultinom(n = 1, size = N, as.vector(null_probs)) %&gt;% matrix(nrow = I, ncol = J)\n      } \n    # Generate random table as independent multinomial samples in each ROW, preserving original row margins.\n    else if(fixed_margins == \"rows\"){\n      for(i in 1:I){\n        new_table[i, ] &lt;- rmultinom(n = 1, size = n_i.[i], prob = null_probs[i ,]) # rmultinom automatically renormalizes the row i probs.\n      }\n      new_table %&lt;&gt;% matrix(nrow = I, ncol = J)\n    }\n    # Generate random table as independent multinomial samples in each COLUMN, preserving original column margins.\n    else if(fixed_margins == \"columns\"){\n      for(j in 1:J){\n        new_table[, j] &lt;- rmultinom(n = 1, size = n._j[j], prob = null_probs[, j]) # rmultinom automatically renormalizing the column j probs.\n      }\n      new_table %&lt;&gt;% matrix(nrow = I, ncol = J)\n    }\n    # Generate random table by sampling from among all possible I x J tables with the given row and column margins.\n    else if(fixed_margins == \"both\"){\n      new_table &lt;- r2dtable(n = 1, r = n_i., c = n._j)[[1]]\n    }\n    return(new_table)\n  }\n  \n  chisqs &lt;- rep(NA, nsim) \n  \n  for(j in 1:nsim){\n    chisqs[j] &lt;- new_two_way(tab, fixed_margins) %&gt;% chisq_stat0\n  }\n  \n  obs_chisq &lt;- chisq_stat0(tab)\n  pval &lt;- sum(chisqs &gt;= obs_chisq)/nsim # One-sided\n  return(list(stats = chisqs, obs_chisq = obs_chisq, pval = pval))\n\n}"
  },
  {
    "objectID": "z2_learnR.html#sampling-models-optional",
    "href": "z2_learnR.html#sampling-models-optional",
    "title": "2 Odds and risks",
    "section": "Sampling Models (Optional)",
    "text": "Sampling Models (Optional)\nIn this section, we describe some of the details of the code for re-sampling, in particular the different types of probability distributions from which we can draw the re-samples. In the example of running the code below for the Lady Tasting Tea data, we perform the re-sampling only based on the method imposed by the experimental design in the actual Lady Tasting Tea experiment.\nAs mentioned above, to use the re-sampling function, we need to make the verbal statement “sample a new 2-way table under the hypothesis of independence” precise enough to do some computing. There are several different ways that the Lady Tasting Tea experiment could have been carried out. Each possible sampling model below corresponds to a different way the tea-tasting experiment could have been designed and performed statistical analysis depends on the experiment design (as it should!). We’ll also point out which way the experiment was actually performed.\n\nUnrestricted Sampling\nConsider this scenario: we give the lady however many cups of tea she feels like tasting, and we don’t tell her anything about how many of each type (milk-first or tea-first) there are. This “unrestricted” sampling can be modeled using a Poisson distribution.\n[This case is included for sake of completeness, in the context of inference, this and the next situation, where the total sample size is fixed can be treated the same.]\n\n\nTotal Sample Size Fixed\nNow consider this scenario: The lady is to be presented with eight cups of tea, but the number that are milk-first is not predetermined. In the actual Lady Tasting Tea data, there were four milk-first cups, but in this scenario, there could have been two, five, eight, any number between zero and eight. In this scenario, the lady is not told how many cups of each type (milk-first or tea-first) there were. To perform this sampling, we use a multinomial distribution for the entire table (i.e., with N = 8 and four categories).\n\n\nOne Margin Fixed\nIn another scenario that could have produced the Lady Tasting Tea data, suppose there are four cups of each type of tea, but the lady doesn’t know there are four of each. In this case “The Truth” margins are fixed (at four), but the “Guess” margins are not. For this type of sampling, we use independent multinomials within rows or within columns (i.e., with N = 4 and two categories).\n\n\nBoth Margins Fixed\n\nThis is the actual situation of Fisher’s original Lady Tasting Tea experiment. Four cups of each type were presented, and the lady knew that she would taste four of each. Because of this, the row margins are fixed at four and the column margins also fixed at four. In this case, we base the sampling on (generalized) hypergeometric distribution."
  },
  {
    "objectID": "z2_learnR.html#examples-of-re-sampling-lady-tasting-tea",
    "href": "z2_learnR.html#examples-of-re-sampling-lady-tasting-tea",
    "title": "2 Odds and risks",
    "section": "Examples of Re-sampling: Lady Tasting Tea",
    "text": "Examples of Re-sampling: Lady Tasting Tea\nIn the following R chunk, we re-sample the Lady Tasting Tea data, based on the sampling design imposed by the original experimental setup (both margins fixed). Go ahead and run the R chunk and take a look at the resulting plot.\n\nresamp_tea &lt;- two_way_resample(TeaTasting, nsim = 2000, fixed_margins = \"both\") \n\nchisq_val &lt;- seq(0,8,length=2000)\n\nchisq_theory &lt;- dchisq(chisq_val,1)\n\n# fix both row and column margins\n\nggplot() +\n ggtitle(\"Re-sampling distribution of chi-squared stat vs \n    theoretical chi-squared distribution\") +\n xlab(expression(X^2)) +\n ylab(\"\") +\n geom_line(mapping = aes(x = chisq_val, y = chisq_theory), color = \"blue\") +\n geom_density(mapping = aes(x = resamp_tea$stats), bw = 0.05) + \n geom_vline(aes(xintercept = chisq_stat0(TeaTasting)), color = \"red\")\n\n\n\n\n\n\n\n\nIn this plot, the smooth blue line is the theoretical Chi-squared (df = 1) reference distribution. The black line with a few spikes is the reference distribution we get by running the re-sampling code. There are actually only a few values of the chi-squared statistic that are possible with such a sparse table. Finally, the vertical red line is the value of the chi-squared statistic calculated from the observed table.\nThe problem here is that with such small counts in the table, there are only a small number of rearranged (re-sampled) tables possible. There just aren’t that many ways to rearrange eight cups of tea into a 2x2 table of counts, especially if we also fix both column and row totals! Therefore, only a limited number of tables, and an even more limited number of chi-squared statistics, can possibly be obtained.\nThis is precisely why using the large sample reference distribution (blue line) isn’t such a good idea here, because is does a really poor job of approximating the resampled reference distribution (black line).\nIt might seem like it was overkill to simulate 2000 samples and calculate the chi-squared statistic for each one, when there were actually only three possible chi-squared statistics for this situation! That is, maybe there is some way we could have have worked this out by hand. Indeed, working it out “exactly” by hand is what Fisher did. His test involves (essentially) listing every way that the chi-squared statistic could have been bigger than it was, and calculating the probability of each of those ways.\nExecute the following R chunk, which applies Fisher’s Exact Test to the Lady Tasting Tea data.\n\nfisher.test(TeaTasting)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  TeaTasting\np-value = 0.4857\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n   0.2117329 621.9337505\nsample estimates:\nodds ratio \n  6.408309 \n\n\nFisher’s Exact Test agrees pretty closely with the final simulation above because Fisher’s exact test supposes that both rows and columns of the tables are fixed by design. Restricting it in this way, as we see above, reduces the number of possible tables to deal with, which makes it easier to calculate the p-value “by hand.” And in the tea-tasting example, these restrictions actually do make sense. There are 4 cups of each kind of tea, the lady knows there are 4 of each, there are only a few ways this thing can go.\nWe’d also like to call your attention to the odds ratio and 95% confidence interval estimates that appear in the fisher.test() output. Rather than using a chi-squared statistic for making inference, the fisher.test() function uses an odds ratio test.\n\nImportant note: tests for equal odds ratios, equal proportions and homogeneity will yield similar inferences in the case of 2x2 tables. You just have to sort out which procedure makes the most sense for the data you are dealing with."
  },
  {
    "objectID": "z2_learnR.html#beyond-fixed-margins",
    "href": "z2_learnR.html#beyond-fixed-margins",
    "title": "2 Odds and risks",
    "section": "Beyond Fixed Margins",
    "text": "Beyond Fixed Margins\nIn many (most) cases, the assumption that all the row and column totals are fixed doesn’t make sense and isn’t needed. For example, in a medical study, we might recruit 30 people with a disease; give treatment A to half of them and treatment B to the other half; and record whether or not they were cured after some period of time. In this case, we’ve fixed the row totals by design, because we put 15 patients in each group, but we haven’t fixed the column totals, we can’t say in advance know how many patients will be cured under either treatment. And, in this case, we still have the potential problem of small cell counts.\nFisher’s exact test was designed for precisely the situation of the Lady Tasting Tea (statistically, both margins are fixed). Nevertheless, it is used in many cases to test independence when the cell counts are small, as in the hypothetical medical study just described.\nYou are welcome to replicate the call to the two_way_resample() function, changing the fixed_margins = \"both\" argument to any of \"none\", \"rows\" or \"columns\". Using the Lady Tasting Tea data, you’ll see that the Chi-squared (df = 1) distribution gives a poor approximation to the re-sampled distribution, because the cell counts are so small!"
  },
  {
    "objectID": "z2_learnR.html#beyond-2-x-2-tables",
    "href": "z2_learnR.html#beyond-2-x-2-tables",
    "title": "2 Odds and risks",
    "section": "Beyond 2 x 2 Tables",
    "text": "Beyond 2 x 2 Tables\nYou can apply chisq.test() and fisher.test() to general \\(I \\times J\\) tables, but you will only learn about the independence hypothesis. That is, you will not get any estimates. For estimates proportions and odds ratios from \\(I \\times J\\) tables, we have to turn to more sophisticated statistical models such as generalized linear models."
  },
  {
    "objectID": "z2_learnR.html#r-markdown-for-submission",
    "href": "z2_learnR.html#r-markdown-for-submission",
    "title": "2 Odds and risks",
    "section": "R Markdown for submission",
    "text": "R Markdown for submission\nLast week’s instructions are repeated here for your convenience.\nNOTE: If you are reading these instructions from the HTML preview in the Viewer pane, they will be overwritten in the following steps. You can avoid this by “popping out” the current HTML preview into an external browser window, by clicking the the “Show in new window” icon (to the right of the broom icon in the Viewer pane). \nAlternatively, you can read the instructions right from the .Rmd script, keeping in mind that you will need to switch back to the lab script tab to view the rest of the instructions once you create a new script. You could also copy and paste the whole Lab 2 Assignment Instructions section into your new document while you’re working on it, and then delete the instructions before you submit it.\nClick “File” -&gt; “New File” -&gt; “R Markdown”, and dialog box will pop up. Change the title to “Lab Assignment 1” and name yourself as author. Select PDF as the Default Output Format, then click OK. The header of your new file should look something like this:\n---\ntitle: \"Lab Assignment 2\"\nauthor: \"Ronald Fisher\"\ndate: \"2024-05-17\"\noutput: pdf_document\n---\n\nThe file will initially contain some examples to get you started with RMarkdown, which you should replace with your lab content. Save the notebook as something like “Lab_Assignment_1” using “File” –&gt; “Save As…”\nIn your new .Rmd script, answer the questions in the “Questions” section below. Include all the code you need to produce the requested outputs. Your script should include a top-level section heading for each question, for example:\n# Question 1\n\nstuff here\n\n# Question 2\n\nother stuff\nWhether or not you include the text of the questions in your script is up to you.\n\nDo be sure to include, near the top of your script, a code chunk that loads any non-default packages you use (such as vcdExtra or Sleuth3).\n\nWithin the question sections, you can chunk your code in whatever way seems reasonable. Incorporate any written answers outside the code chunks using Markdown formatting as needed (see “Help” -&gt; “RMarkdown Quick Reference” for text formatting help).\nTo ensure that your .Rmd script will be fully self-contained (i.e. it will not depend on objects that were defined during the lab, and could be run as-is if you sent it to someone else), you should clear the workspace before you begin.\n\nTo clear the workspace, click the broom icon in the Environment pane.\n\nOnce you’ve answered the questions in your new .Rmd script and you have verified your code is self contained, you should Run -&gt; Run All Chunks and generate a .pdf file of your document, to check that everything looks like you want it to. Having concluded that your .Rmd script produces a pdf document that includes all the output you want, submit both the Lab_Assignment_2.Rmd file and the pdf document on Canvas as your Lab Assignment 2.\nFeel free to post on the discussion board if you have any questions or encounter any difficulties with this process."
  },
  {
    "objectID": "z2_learnR.html#q1.",
    "href": "z2_learnR.html#q1.",
    "title": "2 Odds and risks",
    "section": "Q1.",
    "text": "Q1.\nThe following data come from one of Gregor Mendel’s famous experiments with pea plants. In this particular experiment, Mendel examined two categorical traits in pea seeds, each with two possible values: seed color, yellow or green, and seed shape, round or angular.\nAccording to Mendel’s hypothesis, the inheritance pattern of these traits was characterized by “independent assortment”, that is, there was no “genetic linkage” between these traits.\n\nmendel &lt;- as.table(\n matrix(c(315, 108, 101, 32),\n     nrow = 2,\n     dimnames = \n      list(Color= c(\"Yellow\", \"Green\"),\n        Shape = c(\"Round\", \"Angular\"))))\nmendel\n\n        Shape\nColor    Round Angular\n  Yellow   315     101\n  Green    108      32\n\n\nHow consistent are these data with Mendel’s hypothesis of independence? \nIs a Chi-squared test appropriate here? Why or why not?\nNotice that in this particular case, we’re not interested in a departure from independence, but rather a confirmation of independence.\nCells are at least 5, the chi-squared test should be adequate, but I’ll confirm with Fisher.\nThe null is that the proportions at each shape are the same for both colors, The proportion of round and yellow is the same as round and green.\n\nmosaic(mendel)\n\n\n\n\n\n\n\n\nThey look independent based on the alignment.\n\nchisq.test(mendel)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  mendel\nX-squared = 0.051332, df = 1, p-value = 0.8208\n\n\np-value = 0.8208 indicates that there’s evidence of independence of color and shape.\nchisq.test() and fisher.test()\n\nprop.test(t(mendel))\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  t(mendel)\nX-squared = 0.051332, df = 1, p-value = 0.8208\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.10334886  0.07391357\nsample estimates:\n   prop 1    prop 2 \n0.7446809 0.7593985 \n\n\nprop test confidence interval contains zero, that is further evidence these groups are the same. Shape is homogeneous in terms of color.\nFor Fisher, the null is the proportions at one variable are the same for different values of the second variable.\n\nfisher.test(mendel)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  mendel\np-value = 0.819\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.5667874 1.4806148\nsample estimates:\nodds ratio \n 0.9242126 \n\n\nFisher agrees that the proportions are the same."
  },
  {
    "objectID": "z2_learnR.html#q2.",
    "href": "z2_learnR.html#q2.",
    "title": "2 Odds and risks",
    "section": "Q2.",
    "text": "Q2.\nWe mentioned previously, and it’s mentioned in the narrated lecture materials that there’s an equivalence between the Chi-squared test and the difference in proportions test in the case of 2x2 tables. Take a look for the Mendel data:\n\nchisq.test(mendel, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  mendel\nX-squared = 0.11634, df = 1, p-value = 0.733\n\n\n\nprop.test(mendel, correct = FALSE)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  mendel\nX-squared = 0.11634, df = 1, p-value = 0.733\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.09506177  0.06662771\nsample estimates:\n   prop 1    prop 2 \n0.7572115 0.7714286 \n\n\nThe output from the prop.test chunk refers to a two.sided test, with an interpretation in terms of a signed difference between two proportions, whereas the chisq.test() is a one-sided test, with an interpretation involving deviation from the hypothesis of independent rows and columns.\nIt’s not entirely obvious why these results should be the same. The following exercise can help you see what’s going on.\nUse rnorm() and rchisq() to produce and store the following vectors:\n1000 draws from the standard normal distribution, 1000 draws from the Chi-squared distribution with 1 degree of freedom.\n\nnorm &lt;- rnorm(10000, mean = 0, sd = 1)\nchi &lt;- rchisq(10000, df = 1)\n\n\nConstruct separate histograms/density plots of the raw chi-squared values and the squares of the standard normal values.\n\nWhat do you observe?\n\nsquared &lt;- norm^2\n\n# plot(density(norm),\n#      xlim = c(-10,10),\n#      ylim = c(0,1), \n#      main = \"Normal\")\n\n\nplot(density(chi, bw = 0.1354),\n     xlim = c(0,10),\n     ylim = c(0,1), \n     main = \"Chi^2\")\n\n\n\n\n\n\n\nplot(density(squared, bw = 0.1354),\n     xlim = c(0,10),\n     ylim = c(0,1), \n     main = \"Norm^2\")\n\n\n\n\n\n\n\n\nThey are very similar. The chi squared graph is a little more left and taller.\n\nRecall (or obtain from qnorm(0.975) that the 2-sided 95% critical values for the standard normal distribution are ± 1.96.\n\nUse qchisq() to compare the square of these 2-sided 95% critical values from the standard normal to the one-sided 95% critical value for the Chi-squared(1).\nWhat does this suggest about tests based on these two reference distributions?\n\ncrit_z &lt;- qnorm(0.975)\ncrit_chi &lt;- qchisq(0.95, df = 1)\n\ncrit_z^2\n\n[1] 3.841459\n\ncrit_chi\n\n[1] 3.841459\n\n\nAt least at where chi-squared has one degree of freedom, these two tests are equivilent.\n\nggplot() +\n  aes(norm^2) +\n  geom_density() +\n  geom_vline(xintercept = qnorm(0.975)^2, color = \"red\")\n\n\n\n\n\n\n\nggplot() +\n  aes(chi) +\n  geom_density() +\n  geom_vline(xintercept = qchisq(0.95, df = 1), color = \"red\")\n\n\n\n\n\n\n\n\nEND REQUIRED QUESTIONS\n\nThe next two questions are optional, you do not need to submit anything about them for your assignment."
  },
  {
    "objectID": "z2_learnR.html#q3.",
    "href": "z2_learnR.html#q3.",
    "title": "2 Odds and risks",
    "section": "Q3.",
    "text": "Q3.\nThis isn’t actually a question, just some reading and code to work through. It’s an interesting continuation of Mendel’s independence hypothesis, and a slightly different application of chisq.test() in R.\nMendel actually had a more sophisticated hypothesis than “seed color and seed shape are independent”, he knew how they should be independent based on his mechanistic understanding of the process of inheritance of dominant and recessive traits. On these grounds, Mendel hypothesized specific proportions for each cell in this particular table. He knew that if his ideas were correct, the cell proportions for his experiment should have been, specifically:\n\n(mendel_expect &lt;- cbind(c(9, 3), c(3,1)))/16\n\n       [,1]   [,2]\n[1,] 0.5625 0.1875\n[2,] 0.1875 0.0625\n\n\nThis is a more stringent requirement than row/column independence, since there would be many possible tables consistent with some kind of independence relationship, but radically inconsistent with Mendel’s scientific understanding. For instance, if the upper right and lower left cell counts had been reversed, we would get the same chi-squared statistic for the table (check!) but seeing this would have suggested that Mendel was somehow seriously mistaken.\nHere, we need a different approach than the chi-squared test of independence. We want to test an entire proposed distribution over the 4 cells. The tool for this job is the chi-squared test of goodness of fit, which in R is also performed by chisq.test().\nThe goodness of fit test is supposed to test the distribution of a single variable, so chisq.test() will perform the goodness of fit test if the data are provided as a single vector, rather than as a 2 x 2 table. Since we have particular distribution in mind, we’ll need to provide those hypothesized probabilities as well:\n\n(mendel_vec &lt;- as.vector(mendel)) # stretch out the table and make sure we know HOW it was stretched out, in order to get the hypothesized probabilities associated with the correct table cells.\n\n[1] 315 108 101  32\n\n\nAnd now preform the Chi-squared test passing in the vector of observed counts and the vector of specific proportions:\n\nchisq.test(mendel_vec, p = c(9/16, 3/16, 3/16, 1/16))\n\n\n    Chi-squared test for given probabilities\n\ndata:  mendel_vec\nX-squared = 0.47002, df = 3, p-value = 0.9254\n\n\nNote that the degrees of freedom are different – 4-1 = 3 instead of (2-1)(2-1) = 1. A very rough idea of why this should be is that with a more specific hypothesis (“each cell probability should be exactly so”) there are more ways the data could deviate from it.\nAn interesting historical note: R.A. Fisher, when reviewing Mendel’s original data, applied the chi-squared test to some data like these, and reached the conclusion that deviations were too small to have arisen by chance. He thought that the independence model fit so closely that Mendel’s data must have been deliberately doctored though in his great respect for Mendel, Fisher laid the blame on “some gardening assistant” who must have known too well what his supervisor hoped to see."
  },
  {
    "objectID": "z2_learnR.html#q4.",
    "href": "z2_learnR.html#q4.",
    "title": "2 Odds and risks",
    "section": "Q4.",
    "text": "Q4.\nSuppose we performed the tea-tasting experiment, and produced a table with 4’s in the diagonal and 0’s in the off-diagonal cells – that is, suppose the lady performed as well as the experiment allowed. If we had observed this (best possible) performance under the fixed-columns design (where the lady didn’t know the number of cups of each type), what p-value would she score? (use resampling script). What if we observed this same performance under the fixed-rows and fixed-columns design (where she knew there were 4 cups of each)?\nDoes it make sense that the best-possible performance earns a smaller p-value under the more “challenging” experimental setup than under the “easier” one? What does this say about which design we might prefer to use?"
  },
  {
    "objectID": "z0_learnR.html",
    "href": "z0_learnR.html",
    "title": "LearnR 0",
    "section": "",
    "text": "Learn R 0"
  },
  {
    "objectID": "z0_learnR.html#viewing-html",
    "href": "z0_learnR.html#viewing-html",
    "title": "LearnR 0",
    "section": "Viewing HTML",
    "text": "Viewing HTML\nWithin RStudio, generate an HTML preview from the Rmd script by clicking the “Preview” icon, located at the top of source (code) pane. If you don’t see a “Preview” icon, you may need to update RStudio. Check your RStudio version with “Help” -&gt; “About RStudio.” The current version is 2023.03.0.\nBy default, the preview will appear in RStudio Viewer pane (usually found in the lower right-hand section of the RStudio window), so that you can see the two versions (Rmd and HTML) side by side. If the preview doesn’t appear (or pops out in its own window), check the preview settings, in the dropdown menu from the gear icon next to the Preview icon. If you want, you can customize the arrangement of the four RStudio panes through “Tools” -&gt; “Global Options” -&gt; “Pane Layout”.\nThe HTML preview will contain text and code, along with the output of any code chunks that were run before the preview was created. You can refresh the preview at any time without affecting the script. If the preview doesn’t appear after you click the “Preview” icon, please click it once more.\n\nIf you prefer to view complete code output (including graphs) in your HTML view, select “Knit to HTML” from the “Preview” dropdown menu."
  },
  {
    "objectID": "z0_learnR.html#navigation",
    "href": "z0_learnR.html#navigation",
    "title": "LearnR 0",
    "section": "Navigation",
    "text": "Navigation\nWithin the R Markdown script, you can jump to another section by clicking on “Navigation” (or some of you might see “#”) in the lower left corner of the source pane.\nPressing Alt+Shift+K brings up a pane that lists all of the RStudio keyboard shortcuts (you can also access this from the RStudio Help menu – Keyboard Shortcuts Help). One problem is that the command sequences on the Windows, iOS and Linux platforms can be slightly different. If you want to use these navigation shortcuts, please familiarize yourselves with what’s appropriate for your operating system. Press Esc to close the shortcut pane.\nSome examples of keyboard shortcuts: Ctrl+1 and Ctrl+2 switch the cursor location between the console and the source windows, and Ctrl+Shift+0 restores all windows (in case some have been minimized or pushed out of sight)."
  },
  {
    "objectID": "z0_learnR.html#folds",
    "href": "z0_learnR.html#folds",
    "title": "LearnR 0",
    "section": "Folds",
    "text": "Folds\nA “fold” is a subset of the R Markdown (Rmd) file that you can collapse and expand. This is not necessary to do, but it can be useful if you’re working on just one portion of your document. For example, place your cursor HERE in the R Markdown file, and use the collapse fold command (Alt+L) and see what happens. You can expand the fold again using the expand fold command (Shift+Alt+L). You can also collapse and expand folds by clicking on the small triangles (downward pointing when the fold is expanded; pointing right when the fold is collapsed) in the left hand margin of the R Markdown file, just to the right of the line numbers.\nThere is also a keyboard shortcut to “collapse all folds.” For a “cleaner” viewing experience, you may wish to collapse all folds at the beginning of each lab, and expand individual sections as you work through them. Note that collapsing or expanding only applies to the R Markdown and does not affect the HTML preview (even if you generate it again after collapsing or expanding).\nOccasionally, expanding and collapsing too much too fast can lead to persistent screen artifacts that interfere with the usability of the notebook. If this happens, you can select “Clear All Output” from the gear icon at the top of the source pane, and proceed."
  },
  {
    "objectID": "z0_learnR.html#chunks",
    "href": "z0_learnR.html#chunks",
    "title": "LearnR 0",
    "section": "Chunks",
    "text": "Chunks\n“Chunks” in the R Markdown file are delimited by three backticks: ```. For example, below is a chunk of R code.\nExecute the code chunk by placing your cursor inside the chunk (i.e., in the light gray area) and pressing Ctrl+Shift+Enter, or by clicking the green arrow in the upper right corner of the chunk.\n\nimage(volcano)\n\n\n\n\n\n\n\n\n\nIn general, you should run each successive code chunk as you encounter it.\n\nIf you prefer, you can produce all the lab output in advance using “Run All Chunks” (from the “Run” menu at the top of the source pane), but we recommend trying the interactive experience.\nWhen you execute a code chunk in an R Notebook, the result appears inline directly beneath chunk. If you did not see a plot appear beneath the chunk when you execute it, you may need to update RStudio. Assuming the output appeared, it can be hidden again by clicking on the “x” in upper right hand corner of the output area.\nIf you would like to see code output in the HTML preview, after executing the chunk, click Preview again to refresh the HTML. Over in the HTML preview, you’ll see the volcano image, and you’ll see the R code that created that image. You have the option in the HTML preview to hide the code by clicking the “Hide” button above the code. You can specify that code from a particular chunk is not to be included in the HTML by heading the chunk with {r, echo=F}, instead of just {r}. Go ahead and try this if you want, remembering that you have to execute the chunk and then refresh the Preview.\nThe {r} (or {R}) after the backticks in the first line of the chunk is essential – it specifies that this chunk of the R Markdown file should be interpreted as R code. R Markdown documents can also contain chunks of code written in some other languages (like {python} and {sql}). However, in this class, we will only use R code. Contents of chunks without an {r} will not be evaluated as R code. For example:\n# Here is some code that opens a new tab in RStudio,\n# which could disrupt the flow of the lab if it were executed by default.  \n# You can make the chunk executable by putting an {r} after the first ``` that delimits the chunk.\n\nView(mtcars)\nNotice that without the {r} after the opening backticks, you don’t even have the option of executing the code. Similarly, code written outside a code chunk will not be interpreted. For example, the following line is valid R code:\ny &lt;- c(1,2)\nyet it will not be executed in this script, because it is not enclosed in an R code chunk.\n\nR Chunks and Global Propagation\nWhile chunk output will (typically) appear inline in the script (i.e., in the R Markdown file), the actions taken within a chunk propagate globally – once a chunk is executed, the variables assigned, functions defined, etc, are available in R’s global environment for the current project, and are therefore accessible from the console window.\nHere’s an example. The following code chunk simulates rolling a fair 6-sided die 20 times, and shows different representations of the outcomes. Notice that several of the commands in the R chunk below are enclosed in parentheses (e.g., (die &lt;- 1:6)). This is a nice feature in that it will not only assign the variable as directed by the code inside the parentheses, but it also then prints the value of that variable. Go ahead and execute the chunk and take a look at the inline output below it.\n\n# Simulate 20 rolls of a fair 6-sided die\nset.seed(1066)\nk &lt;- 6 # number of sides\nn &lt;- 20 # number of trials\n\n# Possible outcomes for each trial\n(sides &lt;- 1:k)\n\n[1] 1 2 3 4 5 6\n\n# Vector of equal probabilities for each outcome\n(p_vec &lt;- rep(1/k, k)) \n\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n# Use the sample function to simulate n trials\n(outcomes &lt;- sample(sides, n, replace = TRUE, prob = p_vec))\n\n [1] 3 6 5 3 3 1 5 4 6 6 3 6 1 2 2 2 1 1 5 3\n\n# Frequency of each outcome\n(counts &lt;- table(outcomes)) \n\noutcomes\n1 2 3 4 5 6 \n4 3 5 1 3 4 \n\n\nNow type in barplot(counts) at the console. You should get a plot – but it will not appear inline beneath the chunk, since it was not called from within the chunk. Objects like counts that are defined in a script chunk can be accessed from the console, and when you access those objects from the console, they behave like any other objects in the global environment.\n\n\nManipulating Chunks\nDuring every lab, you are encouraged to experiment in the console and/or source panes. You can modify existing chunks, at the minor risk of breaking the lab script and necessitating a reload. Preferably, you can create your own chunks anywhere within the document, by typing out the triple backticks and bracketed {r} as above. As a shortcut, you can Insert a new chunk by pressing Ctrl+Alt+I (or the equivalent on your system).\nYou can use the console to access objects defined in the chunks, but using the console to modify such objects is generally inadvisable – you don’t want the contents of an apparently-self-contained chunk of script to depend on unrecorded console activity. This is actually quite important to keep in mind throughout your work in this course.\n\nChunks should either be self-contained or depend only on chunks above them.\n\nAs a corollary to the statement above: if you ever wish to skip some material and resume the lab activity at further down, you can “Run All Chunks Above” (in the “Run” menu in the upper right corner of the source pane), to ensure that any objects defined in the skipped portion are available going forward.\nIf you want to the modify objects in a code chunk, edit the chunk itself (or a copy of it) so that the behavior of each chunk remains clear.\n\nIn the Rmd script, copy the previous chunk of R code here, modify it so that it simulates 50 flips of a fair coin, and execute it. For simplicity, regard an outcome of 1 as “heads” and an outcome of 2 as “tails”. (Hint: you only need to change 2 characters in the whole chunk to accomplish this).\n\nObserve that running the modified chunk has changed the state of outcomes, counts, etc. If you scroll back up and re-run the original chunk, these will be changed back to their previous states.\nFor more information about using the RMarkdown format, see the Markdown Quick Reference, the RMarkdown Reference Guide, and/or the RMarkdown Cheatsheet – all available from within the RStudio Help menu."
  },
  {
    "objectID": "z0_learnR.html#upgrading-visualizations-from-qplot-to-ggplot",
    "href": "z0_learnR.html#upgrading-visualizations-from-qplot-to-ggplot",
    "title": "LearnR 0",
    "section": "Upgrading Visualizations from qplot() to ggplot()",
    "text": "Upgrading Visualizations from qplot() to ggplot()\nIn previous labs, you’ve seen the qplot() function, which is a simplified wrapper for ggplot(). In this class, we will sometimes need to draw on the full power of ggplot() for more customized visualizations.\nTo illustrate, we’ll bring in a data set you will see again in Lab 3 – the Donner Party data from the vcdExtra package.\n\nhead(Donner)\n\n\n\n\n\n\nfamily\nage\nsex\nsurvived\ndeath\n\n\n\n\nAntoine\nOther\n23\nMale\n0\n1846-12-29\n\n\nBreen, Edward\nBreen\n13\nMale\n1\nNA\n\n\nBreen, Margaret I.\nBreen\n1\nFemale\n1\nNA\n\n\nBreen, James\nBreen\n5\nMale\n1\nNA\n\n\nBreen, John\nBreen\n14\nMale\n1\nNA\n\n\nBreen, Mary\nBreen\n40\nFemale\n1\nNA\n\n\n\n\n\n\nWe want a plot that shows whether individuals survived, as a function of their sex and age. With qplot(), we could do this as follows:\n\nqplot(data = Donner, x = age, y = survived, color = sex, geom = \"point\", main = \"Needs some jitter\") \n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\nBut there’s a subtle problem with this plot. There are 90 observations in this data set,\n\nnrow(Donner) \n\n[1] 90\n\n\nbut it looks like there are a lot fewer than 90 points on that plot. There must be some overplotting happening – that is, there must be some combinations of age and survived that contain contain multiple individuals, and those individuals are not being distinguished in the plot.\nHere’s a table that shows the number of individuals at each unique combination of age and survived.\n\nxtabs(data = Donner, ~ survived + age) # you will learn how to use xtabs() in Lab 1; don't worry about it now\n\n        age\nsurvived 1 2 3 4 5 6 7 8 9 11 12 13 14 15 18 20 21 22 23 24 25 27 28 30 32 35\n       0 5 0 3 1 2 0 0 0 0  0  2  0  0  1  0  0  0  0  3  2  6  1  2  3  0  1\n       1 2 1 2 2 1 2 2 2 4  1  1  3  3  1  1  3  1  1  2  1  2  0  2  2  3  0\n        age\nsurvived 36 40 44 45 46 47 51 57 60 62 65 70\n       0  1  1  1  1  0  1  0  1  1  1  1  1\n       1  0  1  0  0  1  0  1  0  0  0  0  0\n\n\nThis table shows the number of individuals who must be represented by each unique point on the current plot. Whenever a number is &gt;1, there’s overplotting happening.\nWith qplot(), we can jitter the points with geom = \"jitter\" to help with this overplotting:\n\nqplot(data = Donner, x = age, y = survived, color = sex, geom = \"jitter\", main = \"Way too much jitter\")\n\n\n\n\n\n\n\n\nBut this plot looks terrible – we need finer control over the degree of jitter. To achieve this, we’ll have to step up from qplot() to full ggplot(), where we’ll specify the jittering parameters in a separate geom, outside the main plot call.\n\nggplot(data = Donner, mapping = aes(x = age, y = survived, color = sex)) + \n  geom_jitter(height = 0.05, width = 0.5) + # see ?geom_jitter for details\n  ggtitle(\"Reasonable jitter\")\n\n\n\n\n\n\n\n\nThe pseudocode blocks below compare the structure of a basic qplot() call and basic ggplot() call:\nqplot(\ndata = &lt;yourdata&gt;, \n&lt;plot attribute&gt; = &lt;variable&gt;\n&lt;another plot attribute&gt; = &lt;another variable&gt;, \ngeom = \"&lt;typeofplot&gt;\"\n)\nggplot(\ndata = &lt;yourdata&gt;, \nmapping = aes(\n          &lt;plot attribute&gt; = &lt;variable&gt;,\n          &lt;another plot attribute&gt; = &lt;another variable&gt;\n          )\n) + geom_&lt;typeofplot&gt;(\n                      &lt;special plotting arguments&gt;\n                      )\nFor quick reference, see the cheatsheet, accessible in RStudio via “Help” -&gt; “Cheatsheets” -&gt; “Data Visualization with ggplot2. For more in-depth coverage, see R for Data Science, Chapter 3."
  },
  {
    "objectID": "z0_learnR.html#transforming-data-with-tidyr-and-dplyr",
    "href": "z0_learnR.html#transforming-data-with-tidyr-and-dplyr",
    "title": "LearnR 0",
    "section": "Transforming Data with tidyr and dplyr",
    "text": "Transforming Data with tidyr and dplyr\ndplyr and tidyr are tidyverse packages containing utilities for manipulating data frames – these are the “spreadsheet” functions, which let you do in R what you might otherwise be inclined to do in Excel. Here’s brief summary of the 7 key data-manipulation functions, all of which take a data frame as input and produce a data frame as output.\nThe first two functions are from the tidyr package, which helps you get your data frame into what’s known as the “tidy format”:\n\nTidy data has one column for each variable and one row for each observation\n\nThese functions help fix the two most obvious ways that a data set can be untidy. Some of this may seem rather abstract at this point, but you will see concrete examples as the course progresses.\n\npivot_longer() collects a variable whose values occupy multiple columns into one column. Thus, it makes “wide” data frames “taller” by stacking them up into more rows.\npivot_wider() is the reverse of pivot_longer(). It collects observations whose values occupy multiple rows. Thus, it makes “tall” data frames “wider” by spreading them out over more columns.\n\nThe next five functions are from the dplyr package.\n\nmutate() creates new columns as a function of existing columns.\nsummarize() calculates group-level summaries for some column, within groups defined by another column.\nselect() subsets columns by name (as opposed to subsetting by column number with brackets with [, x])\nfilter() subsets the rows by a logical condition about the columns (as opposed to subsetting by row number with [x, ])\narrange() reorders rows – for instance, sort the whole data frame by order of the values from a chosen column\n\nFor quick reference on these functions, see the cheatsheet accessible in RStudio via “Help” -&gt; Cheatsheets” -&gt; “Data transformation with dplyr” and Data tidying with tidyr. For more in-depth coverage, see R for Data Science, Chapter 5.\n\nIf you have not used dplyr before, you are encouraged read Chapter 5 of R for Data Science and practice some of the exercises therein to familiarize yourself with these utilities.\n\nNo discussion of using RStudio like a spreadsheet would be complete with mentioning View(). Using this on any data frame will bring up a new tab with a simple spreadsheet-like interface (not editable, but with built-in sorting and filtering capabilities).\nNote: View() can only display the first 100 columns of a data frame, and does not explicitly warn you of this limitation. If you want to View() a data frame with more than 100 columns, you’ll need to choose which set of 100 or fewer to View() at one time.\n\nThe Pipe Operator\nAll of the data-manipulation functions described are designed to work best with the pipe operator %&gt;%, described in next section (optional, though a useful reference going forward). The pipe provides a particularly convenient syntax for chaining together a sequence of data-manipulation steps.\nPerhaps the shortest useful description of the pipe is that, given functions f and g and an object x, it lets you express this:\ng(f(x))\nlike this:\nx %&gt;% f %&gt;% g\nThis is more useful than it looks, as described in the next (optional) section.\nIf you prefer to skip that last section, you’re done and you can move on to Lab 1. There is nothing you need to submit for Lab 0, although you may wish to return to it later if you need to remind yourself how to use some features of the R notebook system. There will be a short graded assignment attached to the end of each subsequent lab, starting with Lab 1.\nRemember post to the discussion board if you were unable to install required packages. Do try updating R and RStudio first, though."
  },
  {
    "objectID": "z0_learnR.html#composing-functions-with-the-pipe-optional",
    "href": "z0_learnR.html#composing-functions-with-the-pipe-optional",
    "title": "LearnR 0",
    "section": "Composing Functions with The Pipe (optional)",
    "text": "Composing Functions with The Pipe (optional)\n\nPrograms should be written for people to read, and only incidentally for machines to execute - SICP.\n\nWhen we use the output of one function as the input of another function, we call that composing one function with the other – read f(g(x)) as “f composed with g applied to x”. In later labs we will make extensive use of the generalized linear model, which extends the regular linear model by composing a nonlinear function with the usual linear function of the predictors. Deep neural networks implement extremely complex classification rules that ultimately consist of thousands of simpler functions composed together. Function composition is a powerful concept – it’s what allows us to build up bigger and better functions out of simple, re-usable components. In this section we’ll introduce a convenient idiom for expressing function composition in R.\nLet’s start with a simple example of ordinary function composition. We’ll compose the log() function with the factorial() function:\n\nlog(factorial(5))\n\n[1] 4.787492\n\n\nYou can think of this as taking the output of the factorial function and feeding it in as the input to the log function. You can also think of it as effectively applying a whole new “log-factorial” function,\n\nlog.factorial &lt;- function(x)log(factorial(x))\nlog.factorial(5)\n\n[1] 4.787492\n\n\nSame difference.\nThis is also an example of function composition:\n\nexp(2 * (7 + 1))\n\n[1] 8886111\n\n\nBut what are the functions? We could write it out in a less familiar but more “standard” way like so:\n\nexp(multiply_by(2, add(7, 1))) # you can see that `+` and `*` operators are really just functions with a weird syntax.  ?extract shows a full list of available 'functional aliases' for common operators (like the subsetting brackets, []).\n\n[1] 8886111\n\n\nEvidently we’re composing all the time, without even thinking about it. Unfortunately, it’s not always so easy. The more operations we want to compose, the more nesting parentheses we’ll need, and less readable our nested expression becomes. As a rather silly example, imagine if we didn’t have the + syntax for addition, and adding up the numbers 1:5 looked like this:\n\nadd(5, add(4, add(3, add(2, 1)))) # We need to go deeper!\n\n[1] 15\n\n\nAlternatively, we could avoid that by reassigning each intermediate step to a placeholder, which might look like this:\n\nu &lt;- 1\nu &lt;- add(u, 2)\nu &lt;- add(u, 3)\nu &lt;- add(u, 4)\nu &lt;- add(u, 5)\nu\n\n[1] 15\n\n\nWhile both of those approaches have their places, sometimes we’d like something else.\n\nThe %&gt;% operator pipes the output of any function into the input of another.\n\nWe can replace repeated + with piped add() like so:\n\n1 %&gt;% add(2) %&gt;% add(3) %&gt;% add(4) %&gt;% add(5)\n\n[1] 15\n\n\nadd() takes two inputs and produces one output. Each pipe sends output of evaluating the thing to the left into the first open argument position of the function to the right. The numbers in parentheses supply the second arguments to each add function.\nOf course, we could have done that all with +, or even more easily with sum(). Here’s an example with a sequence of different functions, where such an approach isn’t available.\n\n# Illustration of the same computation using progressively more pipe/less parentheses:\nx &lt;- 7\nexp(((x + 1)/2)^2)\n\n[1] 8886111\n\n(((x + 1)/2)^2) %&gt;% exp()\n\n[1] 8886111\n\n((x + 1)/2) %&gt;% raise_to_power(2) %&gt;% exp()\n\n[1] 8886111\n\n(x + 1) %&gt;% divide_by(2) %&gt;% raise_to_power(2)  %&gt;% exp()\n\n[1] 8886111\n\nx %&gt;% add(1) %&gt;% divide_by(2) %&gt;% raise_to_power(2) %&gt;% exp()\n\n[1] 8886111\n\n\nAs mentioned above, by default, the output from the left is piped into the first open argument position of the function on the right. What if you wanted to pipe an output into a different argument of the right-hand function? You could try to pipe a data frame\n\ndf &lt;- data.frame(x = 1:10, y = rnorm(10))\n\ninto qplot(), but it will fail:\n# Running this will produce an error\ndf %&gt;% qplot(x, y)\nThis fails because qplot() doesn’t understand that we’re trying to send df into the data argument of qplot(). We can fix that by specifying the correct argument explicitly with the . placeholder:\n\ndf %&gt;% qplot(x, y, data = .)\n\n\n\n\n\n\n\n\nOf course, in this example, df already had a name, so we could have used that directly in the data argument. In the context of a data-processing pipeline, df could have been the unnamed output of a chain of previous piped operations, and the . would be a convenient handle.\nThis concludes Lab Zero. Don’t forget to work through Lab 1 as well this week."
  },
  {
    "objectID": "aHW_8.html",
    "href": "aHW_8.html",
    "title": "ST-518 HW 8",
    "section": "",
    "text": "output: pdf_document"
  },
  {
    "objectID": "aHW_8.html#r-question",
    "href": "aHW_8.html#r-question",
    "title": "ST-518 HW 8",
    "section": "R Question",
    "text": "R Question\n\n(5 points) Consider the crashi data in the VGAM library that we examined in Lab. Sometimes people will fit multiple linear regression models to data like this, not recognizing that the responses are counts.\n\nUsing the Time.Cat and Day.Cat variables that we created in Lab, fit a multiple linear regression model to the counts—be sure to include the interaction between Time.Cat and Day.Cat just as we did in the lab. How does the model fit compare to the negative binomial regression model that you fit in lab? Please explain.\nNow compare the predicted number of crashes in the early morning on Saturdays using your model from part (a) and the negative binomial model from the Lab. Are they the same? Different?\nNow examine the standard errors associated with the predictions from part (b). Are they the same? Different? Which model do you prefer? Please explain."
  },
  {
    "objectID": "aHW_8.html#conceptual-question",
    "href": "aHW_8.html#conceptual-question",
    "title": "ST-518 HW 8",
    "section": "Conceptual Question",
    "text": "Conceptual Question\n\n(5 points) Please find an article or web posting in which the authors discuss the statistical issues with large datasets. Write a short paragraph in which you identify at least one of the issues that the authors raise. Also please comment on whether you agree with or disagree with their assessment. Please submit either a PDF copy of the article you read, or a web link to the article or post."
  },
  {
    "objectID": "aHW_6.html",
    "href": "aHW_6.html",
    "title": "ST-518 HW 6",
    "section": "",
    "text": "output: pdf_document"
  },
  {
    "objectID": "aHW_6.html#model-the-number-of-visits",
    "href": "aHW_6.html#model-the-number-of-visits",
    "title": "ST-518 HW 6",
    "section": "1. Model the number of visits",
    "text": "1. Model the number of visits\n(5 points) Consider data on 4406 individuals, aged 66 and over, who are covered by Medicare, a public insurance program, in the file DT.rda. The objective is to model the number of physician/non-physician office and hospital outpatient visits using available covariate information for the patients. The covariates include health status variables hosp (number of hospital stays), health (self-perceived health status), numchron (number of chronic conditions), as well as socioeconomic variables gender, school (number of years of education), and privins (private insurance indicator). Once you download the DT.rda file, you can load it into R using load(\"DT.rda\").\n\nload(\"../../Data/DT.rda\")\n\n\na. Produce a histogram\nProduce a histogram of the dependent variable. What types of statistical models (.e.g, Poisson regression, hurdle Poisson model, etc.) should you consider for these data? Give a brief justification for your answer.\n\ndf &lt;- dt\n# str(dt)\nhist(df$ofp)\n\n\n\n\n\n\n\n\nLots of zeroes and long tail means Negative Binomial, probably zero inflated\n\n\nb. Fit the models\nFit the models you indicated in part (a), using the identical set of explanatory variables in each, and report the AIC for each.\n\n# names(dt)\nmod.nb0 &lt;- zeroinfl(ofp ~ hosp + health + numchron + gender + school + privins, \n                    dist = \"negbin\", \n                    data = dt)\n\nmod.nb &lt;- glm.nb(ofp ~ hosp + health + numchron + gender + school + privins, \n                 data = dt)\n\n\nsummary(mod.nb0)\n\n\nCall:\nzeroinfl(formula = ofp ~ hosp + health + numchron + gender + school + \n    privins, data = dt, dist = \"negbin\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.1966 -0.7097 -0.2784  0.3256 17.7661 \n\nCount model coefficients (negbin with log link):\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      1.193466   0.056737  21.035  &lt; 2e-16 ***\nhosp             0.201214   0.020392   9.867  &lt; 2e-16 ***\nhealthpoor       0.287190   0.045940   6.251 4.07e-10 ***\nhealthexcellent -0.313540   0.062977  -4.979 6.40e-07 ***\nnumchron         0.128955   0.011938  10.802  &lt; 2e-16 ***\ngendermale      -0.080093   0.031035  -2.581  0.00986 ** \nschool           0.021338   0.004368   4.886 1.03e-06 ***\nprivinsyes       0.126815   0.041687   3.042  0.00235 ** \nLog(theta)       0.394731   0.035145  11.231  &lt; 2e-16 ***\n\nZero-inflation model coefficients (binomial with logit link):\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.06354    0.27668  -0.230  0.81837    \nhosp            -0.81760    0.43875  -1.863  0.06240 .  \nhealthpoor       0.10178    0.44071   0.231  0.81735    \nhealthexcellent  0.10488    0.30965   0.339  0.73484    \nnumchron        -1.24630    0.17918  -6.956 3.51e-12 ***\ngendermale       0.64937    0.20046   3.239  0.00120 ** \nschool          -0.08481    0.02676  -3.169  0.00153 ** \nprivinsyes      -1.15808    0.22436  -5.162 2.45e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta = 1.484 \nNumber of iterations in BFGS optimization: 31 \nLog-likelihood: -1.209e+04 on 17 Df\n\n\n\nsummary(mod.nb)\n\n\nCall:\nglm.nb(formula = ofp ~ hosp + health + numchron + gender + school + \n    privins, data = dt, init.theta = 1.206603534, link = log)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      0.929257   0.054591  17.022  &lt; 2e-16 ***\nhosp             0.217772   0.020176  10.793  &lt; 2e-16 ***\nhealthpoor       0.305013   0.048511   6.288 3.23e-10 ***\nhealthexcellent -0.341807   0.060924  -5.610 2.02e-08 ***\nnumchron         0.174916   0.012092  14.466  &lt; 2e-16 ***\ngendermale      -0.126488   0.031216  -4.052 5.08e-05 ***\nschool           0.026815   0.004394   6.103 1.04e-09 ***\nprivinsyes       0.224402   0.039464   5.686 1.30e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.2066) family taken to be 1)\n\n    Null deviance: 5743.7  on 4405  degrees of freedom\nResidual deviance: 5044.5  on 4398  degrees of freedom\nAIC: 24359\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.2066 \n          Std. Err.:  0.0336 \n\n 2 x log-likelihood:  -24341.1070 \n\n\n\nAIC(mod.nb0, mod.nb)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nmod.nb0\n17\n24215.29\n\n\nmod.nb\n9\n24359.11\n\n\n\n\n\n\n\n\nc. interpretation of the models\nBased on parts (a) and (b) and considering interpretation of the models in the context of the data, write a sentence summarizing your findings in terms of which model seems most appropriate for these data.\n\nvuong(mod.nb, mod.nb0)\n\nVuong Non-Nested Hypothesis Test-Statistic: \n(test-statistic is asymptotically distributed N(0,1) under the\n null that the models are indistinguishible)\n-------------------------------------------------------------\n              Vuong z-statistic             H_A    p-value\nRaw                   -5.917202 model2 &gt; model1 1.6373e-09\nAIC-corrected         -5.324799 model2 &gt; model1 5.0532e-08\nBIC-corrected         -3.431859 model2 &gt; model1 0.00029973\n\n\n\ns1 &lt;- summary(mod.nb0)\n# s1\ns1$coefficients[[1]][,1]\n\n    (Intercept)            hosp      healthpoor healthexcellent        numchron \n     1.19346578      0.20121399      0.28719018     -0.31354004      0.12895450 \n     gendermale          school      privinsyes      Log(theta) \n    -0.08009312      0.02133836      0.12681467      0.39473077 \n\n\n\n1-exp(-0.31354004)\n\n[1] 0.2691449\n\n\nTheta is larger than 1 in both models, indicating that there is some over dispersion. The AICs are similar but the Voung test shows the zero inflated negative binomial is preferable. The most appropraite model seems to be the zero-inflated negative binomial. A person in excellent health is expected to be 27% less likely to visit a Doctor than someone of less than excellent health in this population among those who are not otherwise disinclined to visit, all other vaariable being equal."
  },
  {
    "objectID": "aHW_6.html#zero-inflated-model-or-a-hurdle",
    "href": "aHW_6.html#zero-inflated-model-or-a-hurdle",
    "title": "ST-518 HW 6",
    "section": "2. zero-inflated model or a hurdle",
    "text": "2. zero-inflated model or a hurdle\n(5 points) For each of the following response variables, indicate whether a zero-inflated model or a hurdle model would be more appropriate. Justify your answer by providing possible processes responsible for generating the excess zeros and the counts that correspond to the model. There may not be a clear answer for you, so simply pick one and try to justify it.\n\na.\nSchool administrators study the attendance behavior of high school juniors and take the number of days absent as the response variable.\nWith school absenses, I expect there to be excess zeroes. The hurdle model assumes all zeroes to be true zeroes. So, the zero-inlated model would be preferable.\n\n\nb.\nWildlife biologists want to model how many fish are being caught by fishermen at a state park. All park visitors are asked how many fish they caught.\nAgain the assumption of all zeroes being true dictates my decision. All park visitors are not fishermen. So, there would be excess zeroes and the zero-inflated model is better.\n\n\nc. \nResearchers are interested in creating a stock trading model for investors. The response is trades per week made by each investor.\nFor active traders, if they are not trading that’s a true zero. Here the hurdle model is appropriate.\n\n\nd. \nResearchers want to create a model for loan defaults. They take the number of outstanding payments that exist for each of a random sample of loans.\nI assume that there are cases in which there could be excess zeroes, but that the banks have already accounted for them. For example, I am assuming they are not including non-payment because of death. In the assumed situation the hurdle model would be appropriate."
  },
  {
    "objectID": "aHW_4.html",
    "href": "aHW_4.html",
    "title": "ST-518 HW 4",
    "section": "",
    "text": "Question\n\n\n\n\n\n(5 points) In 1968, Dr. Benjamin Spock was tried in Boston on charges of conspiring to violate the Selective Service Act by encouraging young men to resist the draft for military service in Vietnam. The defense in the case challenged the method of jury selection claiming that women were underrepresented on jury panels by the process. The defense argued specifically that the judge in the Spock trial had a history of venires (panels of potential jurors) in which women were systematically underrepresented compared to the venires of six other Boston area district judges. These data can be found in case0502 in the Sleuth3 package.\nAnalyze the data by treating the number of women out of 30 people on a venire as a binomial response (that is, you’ll change the percent women in the datasheet to a count by multiplying by 30 and rounding) and judge as an explanatory variable.\n\n\n\nRe-write- Defense claims women are underrepresented on jury. case0502\n\n\n\nIs there evidence of over dispersion in these data? Please explain (i.e., don’t just answer “yes” or “no”).\n\n\nrm(list = ls())\n\nlogistic &lt;- function(x) {(exp(x))/(1 + exp(x))}\ndata(\"case0502\")\ndf &lt;- case0502\n\ndf &lt;- df |&gt; group_by(Judge) |&gt; mutate(\n    venire_id = row_number(),\n    prop = Percent/100, \n    n = 30, \n    female = round(prop*n),\n    male = n - female) |&gt; ungroup()\n\ndf1 &lt;- df |&gt; dplyr::select(Judge, female, n)\n\ndf |&gt; head(n = 10)\n\n\n\n\n\nPercent\nJudge\nvenire_id\nprop\nn\nfemale\nmale\n\n\n\n\n6.4\nSpock’s\n1\n0.064\n30\n2\n28\n\n\n8.7\nSpock’s\n2\n0.087\n30\n3\n27\n\n\n13.3\nSpock’s\n3\n0.133\n30\n4\n26\n\n\n13.6\nSpock’s\n4\n0.136\n30\n4\n26\n\n\n15.0\nSpock’s\n5\n0.150\n30\n4\n26\n\n\n15.2\nSpock’s\n6\n0.152\n30\n5\n25\n\n\n17.7\nSpock’s\n7\n0.177\n30\n5\n25\n\n\n18.6\nSpock’s\n8\n0.186\n30\n6\n24\n\n\n23.1\nSpock’s\n9\n0.231\n30\n7\n23\n\n\n16.8\nA\n1\n0.168\n30\n5\n25\n\n\n\n\n\nemplog &lt;- with(df, qlogis((female/n)))\n\n\nm1 &lt;- glm((female/n)~Judge, \n          weights = n,\n    data = df1, \n    family = \"binomial\") \n\nm1 |&gt; summary()\n\n\nCall:\nglm(formula = (female/n) ~ Judge, family = \"binomial\", data = df1, \n    weights = n)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.66329    0.17236  -3.848 0.000119 ***\nJudgeB        0.01974    0.23305   0.085 0.932484    \nJudgeC       -0.23749    0.21849  -1.087 0.277049    \nJudgeD       -0.34831    0.33902  -1.027 0.304239    \nJudgeE       -0.37691    0.24188  -1.558 0.119171    \nJudgeF       -0.32945    0.22019  -1.496 0.134599    \nJudgeSpock's -1.08591    0.24302  -4.468 7.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.919  on 45  degrees of freedom\nResidual deviance: 31.119  on 39  degrees of freedom\nAIC: 208.53\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n31.119/39\n\n[1] 0.7979231\n\n\nPsi is estimated to be less than 1, therefore there is no evidence of over-dispersion.\nI am confused on these models, the examples always have a continuous explanatory variables, but here we don’t\n\n\n\nHint: In parts (b) through (d), think about what models you could compare using drop-in-deviance tests.\n\nDo the odds of a female on a venire differ for the different judges? Please explain.\n\n\nm1 &lt;- glm((female/n)~Judge, \n          weights = n,\n          data = df1, \n          family = \"binomial\") \n\ns1 &lt;- summary(m1)\ns1$coefficients\n\n                Estimate Std. Error    z value     Pr(&gt;|z|)\n(Intercept)  -0.66329422  0.1723626 -3.8482499 1.189647e-04\nJudgeB        0.01974398  0.2330503  0.0847198 9.324842e-01\nJudgeC       -0.23749233  0.2184896 -1.0869732 2.770486e-01\nJudgeD       -0.34830669  0.3390223 -1.0273858 3.042389e-01\nJudgeE       -0.37690731  0.2418765 -1.5582634 1.191708e-01\nJudgeF       -0.32945007  0.2201900 -1.4962083 1.345994e-01\nJudgeSpock's -1.08590564  0.2430158 -4.4684570 7.878583e-06\n\n\n\\[\nlog(odds) = -0.66329422A + 0.01974398B -0.23749233C -0.34830669D -0.37690731E -0.32945007F -1.08590564S\n\\] All the variables are dummy variables. Meaning each coefficient is also the log odds for that judge.\n\nlog_odds &lt;- function(A,B,C,D,E,f,S) {\n   log_o = -0.66329422*A + 0.01974398*B -0.23749233*C -0.34830669*D -0.37690731*E -0.32945007*f -1.08590564*S\n   odds = exp(log_o)\n   odds\n  }\n\nodds_a &lt;- log_odds(1,0,0,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.941176\n\nodds_a &lt;- log_odds(1,1,0,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.903226\n\nodds_a &lt;- log_odds(1,0,1,0,0,0,0)\nodds_a^(-1)\n\n[1] 2.461538\n\nodds_a &lt;- log_odds(1,0,0,1,0,0,0)\nodds_a^(-1)\n\n[1] 2.75\n\nodds_a &lt;- log_odds(1,0,0,0,1,0,0)\nodds_a^(-1)\n\n[1] 2.829787\n\nodds_a &lt;- log_odds(1,0,0,0,0,1,0)\nodds_a^(-1)\n\n[1] 2.69863\n\nodds_s &lt;- log_odds(1,0,0,0,0,0,1)\nodds_s^(-1)\n\n[1] 5.75\n\n\nThe odds of being on each judges venire are : All in favor of choosing a male and against 1\n\nA: 1.941176\nB: 1.903226\nC: 2.461538\nD: 2.75\nE: 2.829787\nf: 2.69863\nSpock: 5.75\n\nSpock is estimated to be more likely to favor males.\n\nci1 &lt;- confint.default(m1)\nci1 |&gt; exp()\n\n                 2.5 %    97.5 %\n(Intercept)  0.3674681 0.7221880\nJudgeB       0.6459544 1.6104510\nJudgeC       0.5139013 1.2101440\nJudgeD       0.3632085 1.3718563\nJudgeE       0.4269977 1.1020388\nJudgeF       0.4671922 1.1075101\nJudgeSpock's 0.2096726 0.5435664\n\n\nThe multiplicative confidence intervals seem to tell the same story. Judges B through F potentially have the same odds of picking females as Judge A. However, Spock’s odds are between 21% and 54% the odds of A.\n\ndf4 &lt;- df1 |&gt; mutate(\n  prop_f = female/n, \n  odds_f = ((prop_f)/(1 - prop_f)\n))\n\n\nggplot(df4) +\n  aes(x = Judge, y = odds_f, fill = Judge) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nGraphically, it is more obvious that there is a difference between the judges. Spock is the most obvious difference.\n\n\n\n\ndfanova &lt;- df1 |&gt; mutate(\n  tot = n,\n  male = tot - female,\n  j = 1\n) \n\n\nt &lt;- dfanova |&gt; \n  mutate(\n    id = row_number()) |&gt; \n  pivot_wider(names_from = Judge, \n                   values_from = j, \n                   id_cols = c(id, female, male, tot),\n                   values_fill = 0) |&gt; rename(S = `Spock's`, f = 'F') |&gt; \n  relocate(S, .after = \"f\")\n\nmf &lt;- glm((female/tot)~B+C+D+E+f+S, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \n\n\nms &lt;-  glm((female/tot)~B+C+D+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmF &lt;-  glm((female/tot)~B+C+D+E+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\n\nme &lt;-  glm((female/tot)~B+C+D+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmd &lt;-  glm((female/tot)~B+C+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmc &lt;-  glm((female/tot)~B+D+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmb &lt;-  glm((female/tot)~C+D+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmods &lt;- c('ms', 'mF', 'me', 'md', 'mc', 'mb')\nfor (i in 1:6) {\n  print(mods[i])\n  name &lt;- get(mods[i])\n  print(pchisq((anova(name, mf)$Deviance[2]), 1, lower.tail = F))\n}\n\n[1] \"ms\"\n[1] 6.975788e-06\n[1] \"mF\"\n[1] 0.136041\n[1] \"me\"\n[1] 0.1188039\n[1] \"md\"\n[1] 0.2981783\n[1] \"mc\"\n[1] 0.2784756\n[1] \"mb\"\n[1] 0.9324773\n\n\nThe model without Spock is the only one that rejects the null hypothesis that the coefficients are equal. The full model, with Spock, is a better fit. The factor “Spock’s” is not equal to zero, Spock is different than the others.\n\n\n\nthink about what models you could compare using drop-in-deviance tests.\n\nDo judges A-F differ in their probabilities of selecting females to the venire? Please explain.\n\n\ndfc &lt;- df |&gt; filter(Judge != \"Spock's\")\nm2 &lt;- glm((female/n)~Judge, \n          weights = n,\n    data = dfc, \n    family = \"binomial\") \n\ns2 &lt;- summary(m2)\ns2\n\n\nCall:\nglm(formula = (female/n) ~ Judge, family = \"binomial\", data = dfc, \n    weights = n)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.66329    0.17236  -3.848 0.000119 ***\nJudgeB       0.01974    0.23305   0.085 0.932484    \nJudgeC      -0.23749    0.21849  -1.087 0.277049    \nJudgeD      -0.34831    0.33902  -1.027 0.304239    \nJudgeE      -0.37691    0.24188  -1.558 0.119171    \nJudgeF      -0.32945    0.22019  -1.496 0.134599    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 31.747  on 36  degrees of freedom\nResidual deviance: 26.168  on 31  degrees of freedom\nAIC: 173.19\n\nNumber of Fisher Scoring iterations: 4\n\n\n\ns2$coefficients |&gt; exp()\n\n             Estimate Std. Error    z value Pr(&gt;|z|)\n(Intercept) 0.5151515   1.188109 0.02131701 1.000119\nJudgeB      1.0199402   1.262445 1.08841205 2.540813\nJudgeC      0.7886029   1.244196 0.33723569 1.319231\nJudgeD      0.7058824   1.403575 0.35794148 1.355593\nJudgeE      0.6859797   1.273637 0.21050131 1.126562\nJudgeF      0.7193192   1.246313 0.22397781 1.144078\n\n\n\nc2 &lt;- confint.default(m2) \nc2\n\n                 2.5 %      97.5 %\n(Intercept) -1.0011186 -0.32546980\nJudgeB      -0.4370263  0.47651425\nJudgeC      -0.6657240  0.19073939\nJudgeD      -1.0127782  0.31616482\nJudgeE      -0.8509766  0.09716194\nJudgeF      -0.7610145  0.10211435\n\nc2 |&gt; exp()\n\n                2.5 %   97.5 %\n(Intercept) 0.3674681 0.722188\nJudgeB      0.6459544 1.610451\nJudgeC      0.5139013 1.210144\nJudgeD      0.3632085 1.371856\nJudgeE      0.4269977 1.102039\nJudgeF      0.4671922 1.107510\n\n\nThere may be differences between judges A through F, but the 95% confidence intervals seem to indicate that it is plausible that these judges all have roughly to same odds of choosing females. The confidence intervals contain 1 and they are multiplicative off of A. Meaning judges B through F are all choosing at roughly the same rate.\n\n# -0.66329422  0.01974398 -0.23749233 -0.34830669 -0.37690731 -0.32945007\nlog_odds &lt;- function(A,B,C,D,E,f) {\n   log_o = (-0.66329422*A) + (0.01974398*B) + (-0.23749233*C) + (-0.34830669*D) + (-0.37690731*E) + (-0.32945007*f)\n   odds = exp(log_o)\n   odds\n  }\n\nodds_a &lt;- log_odds(1,0,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.941176\n\nodds_a &lt;- log_odds(1,1,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.903226\n\nodds_a &lt;- log_odds(1,0,1,0,0,0)\nodds_a^(-1)\n\n[1] 2.461538\n\nodds_a &lt;- log_odds(1,0,0,1,0,0)\nodds_a^(-1)\n\n[1] 2.75\n\nodds_a &lt;- log_odds(1,0,0,0,1,0)\nodds_a^(-1)\n\n[1] 2.829787\n\nodds_a &lt;- log_odds(1,0,0,0,0,1)\nodds_a^(-1)\n\n[1] 2.69863\n\n\nThe odds for these judges range from about 1.9 to 2.8 in favor of males.\n\n\n\n\ndfanova &lt;- df1 |&gt; mutate(\n  tot = n,\n  male = tot - female,\n  j = 1\n) |&gt; filter(Judge != \"Spock's\")\n\n\nt &lt;- dfanova |&gt; \n  mutate(\n    id = row_number()) |&gt; \n  pivot_wider(names_from = Judge, \n              values_from = j, \n              id_cols = c(id, female, male, tot),\n              values_fill = 0) |&gt; rename(f = 'F') \n\nmf &lt;- glm((female/tot)~B+C+D+E+f, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \n\n\n# ms &lt;-  glm((female/tot)~B+C+D+E+f, \n#             weights = tot,\n#             data = t, \n#             family = \"binomial\") \n\nmF &lt;-  glm((female/tot)~B+C+D+E, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\n\nme &lt;-  glm((female/tot)~B+C+D+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmd &lt;-  glm((female/tot)~B+C+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmc &lt;-  glm((female/tot)~B+D+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmb &lt;-  glm((female/tot)~C+D+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmods &lt;- c('mF', 'me', 'md', 'mc', 'mb')\nfor (i in 1:length(mods)) {\n  print(mods[i])\n  name &lt;- get(mods[i])\n  print(pchisq((anova(name, mf)$Deviance[2]), 1, lower.tail = F))\n}\n\n[1] \"mF\"\n[1] 0.136041\n[1] \"me\"\n[1] 0.1188039\n[1] \"md\"\n[1] 0.2981783\n[1] \"mc\"\n[1] 0.2784756\n[1] \"mb\"\n[1] 0.9324773\n\n\nTesting the remaining judges, the all fail to reject the null hypothesis. Judges A though F are equally likely to choose females.\n\n\n\n\nHow different are the odds of having a woman on the Spock judge’s venires from the odds of having a woman on the venires of other judges? Please explain.\n\nthink about what models you could compare using drop-in-deviance tests.\nAs stated in part B, the odds of being on each judges venire are : All in favor of choosing a male and against 1\n\nA: 1.941176\nB: 1.903226\nC: 2.461538\nD: 2.75\nE: 2.829787\nf: 2.69863\nSpock: 5.75\n\nComparing the ratios of the odds of Spock choosing a female vs the other judges,\n\n5.75/ 1.941176\n\n[1] 2.962122\n\n5.75/ 1.903226\n\n[1] 3.021186\n\n5.75/ 2.461538\n\n[1] 2.335938\n\n5.75/ 2.75\n\n[1] 2.090909\n\n5.75/ 2.829787\n\n[1] 2.031955\n\n5.75/ 2.69863\n\n[1] 2.130711\n\n5.75/ 5.75\n\n[1] 1\n\n\nSpock is about:\n\n3 times more likely to choose male than A,\n3 times more likely than B,\n2.33 times more likely than C,\n2.1 times more likely than D,\n2.0 times more likely than E, and\n2.1 times more likely than F.\n\nThe ANOVA in parts b and c showed that Spock is the only judge that is significantly different among this group. (Drop in Deviance test, P-value = 6.975788e-06 on 1 df)."
  },
  {
    "objectID": "aHW_4.html#spock-trial",
    "href": "aHW_4.html#spock-trial",
    "title": "ST-518 HW 4",
    "section": "",
    "text": "Question\n\n\n\n\n\n(5 points) In 1968, Dr. Benjamin Spock was tried in Boston on charges of conspiring to violate the Selective Service Act by encouraging young men to resist the draft for military service in Vietnam. The defense in the case challenged the method of jury selection claiming that women were underrepresented on jury panels by the process. The defense argued specifically that the judge in the Spock trial had a history of venires (panels of potential jurors) in which women were systematically underrepresented compared to the venires of six other Boston area district judges. These data can be found in case0502 in the Sleuth3 package.\nAnalyze the data by treating the number of women out of 30 people on a venire as a binomial response (that is, you’ll change the percent women in the datasheet to a count by multiplying by 30 and rounding) and judge as an explanatory variable.\n\n\n\nRe-write- Defense claims women are underrepresented on jury. case0502\n\n\n\nIs there evidence of over dispersion in these data? Please explain (i.e., don’t just answer “yes” or “no”).\n\n\nrm(list = ls())\n\nlogistic &lt;- function(x) {(exp(x))/(1 + exp(x))}\ndata(\"case0502\")\ndf &lt;- case0502\n\ndf &lt;- df |&gt; group_by(Judge) |&gt; mutate(\n    venire_id = row_number(),\n    prop = Percent/100, \n    n = 30, \n    female = round(prop*n),\n    male = n - female) |&gt; ungroup()\n\ndf1 &lt;- df |&gt; dplyr::select(Judge, female, n)\n\ndf |&gt; head(n = 10)\n\n\n\n\n\nPercent\nJudge\nvenire_id\nprop\nn\nfemale\nmale\n\n\n\n\n6.4\nSpock’s\n1\n0.064\n30\n2\n28\n\n\n8.7\nSpock’s\n2\n0.087\n30\n3\n27\n\n\n13.3\nSpock’s\n3\n0.133\n30\n4\n26\n\n\n13.6\nSpock’s\n4\n0.136\n30\n4\n26\n\n\n15.0\nSpock’s\n5\n0.150\n30\n4\n26\n\n\n15.2\nSpock’s\n6\n0.152\n30\n5\n25\n\n\n17.7\nSpock’s\n7\n0.177\n30\n5\n25\n\n\n18.6\nSpock’s\n8\n0.186\n30\n6\n24\n\n\n23.1\nSpock’s\n9\n0.231\n30\n7\n23\n\n\n16.8\nA\n1\n0.168\n30\n5\n25\n\n\n\n\n\nemplog &lt;- with(df, qlogis((female/n)))\n\n\nm1 &lt;- glm((female/n)~Judge, \n          weights = n,\n    data = df1, \n    family = \"binomial\") \n\nm1 |&gt; summary()\n\n\nCall:\nglm(formula = (female/n) ~ Judge, family = \"binomial\", data = df1, \n    weights = n)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.66329    0.17236  -3.848 0.000119 ***\nJudgeB        0.01974    0.23305   0.085 0.932484    \nJudgeC       -0.23749    0.21849  -1.087 0.277049    \nJudgeD       -0.34831    0.33902  -1.027 0.304239    \nJudgeE       -0.37691    0.24188  -1.558 0.119171    \nJudgeF       -0.32945    0.22019  -1.496 0.134599    \nJudgeSpock's -1.08591    0.24302  -4.468 7.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.919  on 45  degrees of freedom\nResidual deviance: 31.119  on 39  degrees of freedom\nAIC: 208.53\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n31.119/39\n\n[1] 0.7979231\n\n\nPsi is estimated to be less than 1, therefore there is no evidence of over-dispersion.\nI am confused on these models, the examples always have a continuous explanatory variables, but here we don’t\n\n\n\nHint: In parts (b) through (d), think about what models you could compare using drop-in-deviance tests.\n\nDo the odds of a female on a venire differ for the different judges? Please explain.\n\n\nm1 &lt;- glm((female/n)~Judge, \n          weights = n,\n          data = df1, \n          family = \"binomial\") \n\ns1 &lt;- summary(m1)\ns1$coefficients\n\n                Estimate Std. Error    z value     Pr(&gt;|z|)\n(Intercept)  -0.66329422  0.1723626 -3.8482499 1.189647e-04\nJudgeB        0.01974398  0.2330503  0.0847198 9.324842e-01\nJudgeC       -0.23749233  0.2184896 -1.0869732 2.770486e-01\nJudgeD       -0.34830669  0.3390223 -1.0273858 3.042389e-01\nJudgeE       -0.37690731  0.2418765 -1.5582634 1.191708e-01\nJudgeF       -0.32945007  0.2201900 -1.4962083 1.345994e-01\nJudgeSpock's -1.08590564  0.2430158 -4.4684570 7.878583e-06\n\n\n\\[\nlog(odds) = -0.66329422A + 0.01974398B -0.23749233C -0.34830669D -0.37690731E -0.32945007F -1.08590564S\n\\] All the variables are dummy variables. Meaning each coefficient is also the log odds for that judge.\n\nlog_odds &lt;- function(A,B,C,D,E,f,S) {\n   log_o = -0.66329422*A + 0.01974398*B -0.23749233*C -0.34830669*D -0.37690731*E -0.32945007*f -1.08590564*S\n   odds = exp(log_o)\n   odds\n  }\n\nodds_a &lt;- log_odds(1,0,0,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.941176\n\nodds_a &lt;- log_odds(1,1,0,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.903226\n\nodds_a &lt;- log_odds(1,0,1,0,0,0,0)\nodds_a^(-1)\n\n[1] 2.461538\n\nodds_a &lt;- log_odds(1,0,0,1,0,0,0)\nodds_a^(-1)\n\n[1] 2.75\n\nodds_a &lt;- log_odds(1,0,0,0,1,0,0)\nodds_a^(-1)\n\n[1] 2.829787\n\nodds_a &lt;- log_odds(1,0,0,0,0,1,0)\nodds_a^(-1)\n\n[1] 2.69863\n\nodds_s &lt;- log_odds(1,0,0,0,0,0,1)\nodds_s^(-1)\n\n[1] 5.75\n\n\nThe odds of being on each judges venire are : All in favor of choosing a male and against 1\n\nA: 1.941176\nB: 1.903226\nC: 2.461538\nD: 2.75\nE: 2.829787\nf: 2.69863\nSpock: 5.75\n\nSpock is estimated to be more likely to favor males.\n\nci1 &lt;- confint.default(m1)\nci1 |&gt; exp()\n\n                 2.5 %    97.5 %\n(Intercept)  0.3674681 0.7221880\nJudgeB       0.6459544 1.6104510\nJudgeC       0.5139013 1.2101440\nJudgeD       0.3632085 1.3718563\nJudgeE       0.4269977 1.1020388\nJudgeF       0.4671922 1.1075101\nJudgeSpock's 0.2096726 0.5435664\n\n\nThe multiplicative confidence intervals seem to tell the same story. Judges B through F potentially have the same odds of picking females as Judge A. However, Spock’s odds are between 21% and 54% the odds of A.\n\ndf4 &lt;- df1 |&gt; mutate(\n  prop_f = female/n, \n  odds_f = ((prop_f)/(1 - prop_f)\n))\n\n\nggplot(df4) +\n  aes(x = Judge, y = odds_f, fill = Judge) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nGraphically, it is more obvious that there is a difference between the judges. Spock is the most obvious difference.\n\n\n\n\ndfanova &lt;- df1 |&gt; mutate(\n  tot = n,\n  male = tot - female,\n  j = 1\n) \n\n\nt &lt;- dfanova |&gt; \n  mutate(\n    id = row_number()) |&gt; \n  pivot_wider(names_from = Judge, \n                   values_from = j, \n                   id_cols = c(id, female, male, tot),\n                   values_fill = 0) |&gt; rename(S = `Spock's`, f = 'F') |&gt; \n  relocate(S, .after = \"f\")\n\nmf &lt;- glm((female/tot)~B+C+D+E+f+S, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \n\n\nms &lt;-  glm((female/tot)~B+C+D+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmF &lt;-  glm((female/tot)~B+C+D+E+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\n\nme &lt;-  glm((female/tot)~B+C+D+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmd &lt;-  glm((female/tot)~B+C+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmc &lt;-  glm((female/tot)~B+D+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmb &lt;-  glm((female/tot)~C+D+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmods &lt;- c('ms', 'mF', 'me', 'md', 'mc', 'mb')\nfor (i in 1:6) {\n  print(mods[i])\n  name &lt;- get(mods[i])\n  print(pchisq((anova(name, mf)$Deviance[2]), 1, lower.tail = F))\n}\n\n[1] \"ms\"\n[1] 6.975788e-06\n[1] \"mF\"\n[1] 0.136041\n[1] \"me\"\n[1] 0.1188039\n[1] \"md\"\n[1] 0.2981783\n[1] \"mc\"\n[1] 0.2784756\n[1] \"mb\"\n[1] 0.9324773\n\n\nThe model without Spock is the only one that rejects the null hypothesis that the coefficients are equal. The full model, with Spock, is a better fit. The factor “Spock’s” is not equal to zero, Spock is different than the others.\n\n\n\nthink about what models you could compare using drop-in-deviance tests.\n\nDo judges A-F differ in their probabilities of selecting females to the venire? Please explain.\n\n\ndfc &lt;- df |&gt; filter(Judge != \"Spock's\")\nm2 &lt;- glm((female/n)~Judge, \n          weights = n,\n    data = dfc, \n    family = \"binomial\") \n\ns2 &lt;- summary(m2)\ns2\n\n\nCall:\nglm(formula = (female/n) ~ Judge, family = \"binomial\", data = dfc, \n    weights = n)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.66329    0.17236  -3.848 0.000119 ***\nJudgeB       0.01974    0.23305   0.085 0.932484    \nJudgeC      -0.23749    0.21849  -1.087 0.277049    \nJudgeD      -0.34831    0.33902  -1.027 0.304239    \nJudgeE      -0.37691    0.24188  -1.558 0.119171    \nJudgeF      -0.32945    0.22019  -1.496 0.134599    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 31.747  on 36  degrees of freedom\nResidual deviance: 26.168  on 31  degrees of freedom\nAIC: 173.19\n\nNumber of Fisher Scoring iterations: 4\n\n\n\ns2$coefficients |&gt; exp()\n\n             Estimate Std. Error    z value Pr(&gt;|z|)\n(Intercept) 0.5151515   1.188109 0.02131701 1.000119\nJudgeB      1.0199402   1.262445 1.08841205 2.540813\nJudgeC      0.7886029   1.244196 0.33723569 1.319231\nJudgeD      0.7058824   1.403575 0.35794148 1.355593\nJudgeE      0.6859797   1.273637 0.21050131 1.126562\nJudgeF      0.7193192   1.246313 0.22397781 1.144078\n\n\n\nc2 &lt;- confint.default(m2) \nc2\n\n                 2.5 %      97.5 %\n(Intercept) -1.0011186 -0.32546980\nJudgeB      -0.4370263  0.47651425\nJudgeC      -0.6657240  0.19073939\nJudgeD      -1.0127782  0.31616482\nJudgeE      -0.8509766  0.09716194\nJudgeF      -0.7610145  0.10211435\n\nc2 |&gt; exp()\n\n                2.5 %   97.5 %\n(Intercept) 0.3674681 0.722188\nJudgeB      0.6459544 1.610451\nJudgeC      0.5139013 1.210144\nJudgeD      0.3632085 1.371856\nJudgeE      0.4269977 1.102039\nJudgeF      0.4671922 1.107510\n\n\nThere may be differences between judges A through F, but the 95% confidence intervals seem to indicate that it is plausible that these judges all have roughly to same odds of choosing females. The confidence intervals contain 1 and they are multiplicative off of A. Meaning judges B through F are all choosing at roughly the same rate.\n\n# -0.66329422  0.01974398 -0.23749233 -0.34830669 -0.37690731 -0.32945007\nlog_odds &lt;- function(A,B,C,D,E,f) {\n   log_o = (-0.66329422*A) + (0.01974398*B) + (-0.23749233*C) + (-0.34830669*D) + (-0.37690731*E) + (-0.32945007*f)\n   odds = exp(log_o)\n   odds\n  }\n\nodds_a &lt;- log_odds(1,0,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.941176\n\nodds_a &lt;- log_odds(1,1,0,0,0,0)\nodds_a^(-1)\n\n[1] 1.903226\n\nodds_a &lt;- log_odds(1,0,1,0,0,0)\nodds_a^(-1)\n\n[1] 2.461538\n\nodds_a &lt;- log_odds(1,0,0,1,0,0)\nodds_a^(-1)\n\n[1] 2.75\n\nodds_a &lt;- log_odds(1,0,0,0,1,0)\nodds_a^(-1)\n\n[1] 2.829787\n\nodds_a &lt;- log_odds(1,0,0,0,0,1)\nodds_a^(-1)\n\n[1] 2.69863\n\n\nThe odds for these judges range from about 1.9 to 2.8 in favor of males.\n\n\n\n\ndfanova &lt;- df1 |&gt; mutate(\n  tot = n,\n  male = tot - female,\n  j = 1\n) |&gt; filter(Judge != \"Spock's\")\n\n\nt &lt;- dfanova |&gt; \n  mutate(\n    id = row_number()) |&gt; \n  pivot_wider(names_from = Judge, \n              values_from = j, \n              id_cols = c(id, female, male, tot),\n              values_fill = 0) |&gt; rename(f = 'F') \n\nmf &lt;- glm((female/tot)~B+C+D+E+f, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \n\n\n# ms &lt;-  glm((female/tot)~B+C+D+E+f, \n#             weights = tot,\n#             data = t, \n#             family = \"binomial\") \n\nmF &lt;-  glm((female/tot)~B+C+D+E, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\n\nme &lt;-  glm((female/tot)~B+C+D+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmd &lt;-  glm((female/tot)~B+C+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmc &lt;-  glm((female/tot)~B+D+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmb &lt;-  glm((female/tot)~C+D+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmods &lt;- c('mF', 'me', 'md', 'mc', 'mb')\nfor (i in 1:length(mods)) {\n  print(mods[i])\n  name &lt;- get(mods[i])\n  print(pchisq((anova(name, mf)$Deviance[2]), 1, lower.tail = F))\n}\n\n[1] \"mF\"\n[1] 0.136041\n[1] \"me\"\n[1] 0.1188039\n[1] \"md\"\n[1] 0.2981783\n[1] \"mc\"\n[1] 0.2784756\n[1] \"mb\"\n[1] 0.9324773\n\n\nTesting the remaining judges, the all fail to reject the null hypothesis. Judges A though F are equally likely to choose females.\n\n\n\n\nHow different are the odds of having a woman on the Spock judge’s venires from the odds of having a woman on the venires of other judges? Please explain.\n\nthink about what models you could compare using drop-in-deviance tests.\nAs stated in part B, the odds of being on each judges venire are : All in favor of choosing a male and against 1\n\nA: 1.941176\nB: 1.903226\nC: 2.461538\nD: 2.75\nE: 2.829787\nf: 2.69863\nSpock: 5.75\n\nComparing the ratios of the odds of Spock choosing a female vs the other judges,\n\n5.75/ 1.941176\n\n[1] 2.962122\n\n5.75/ 1.903226\n\n[1] 3.021186\n\n5.75/ 2.461538\n\n[1] 2.335938\n\n5.75/ 2.75\n\n[1] 2.090909\n\n5.75/ 2.829787\n\n[1] 2.031955\n\n5.75/ 2.69863\n\n[1] 2.130711\n\n5.75/ 5.75\n\n[1] 1\n\n\nSpock is about:\n\n3 times more likely to choose male than A,\n3 times more likely than B,\n2.33 times more likely than C,\n2.1 times more likely than D,\n2.0 times more likely than E, and\n2.1 times more likely than F.\n\nThe ANOVA in parts b and c showed that Spock is the only judge that is significantly different among this group. (Drop in Deviance test, P-value = 6.975788e-06 on 1 df)."
  },
  {
    "objectID": "aHW_4.html#extra-binomial-variation",
    "href": "aHW_4.html#extra-binomial-variation",
    "title": "ST-518 HW 4",
    "section": "2. Extra-binomial variation",
    "text": "2. Extra-binomial variation\n(2 points) Give three explanations for why you may see evidence of extra-binomial variation in a logistic regression.\nExtra-binomial variation could come from variables not represented in the model, outliers, or lack of independence. Unrepresented variables add noise because we are not predicting for their effect. Outliers are noise and come from a variety of sources, sometimes they are just mistakes, but they could be natural. Lack of independence causes observations to be more alike, that makes variation estimates low."
  },
  {
    "objectID": "aHW_4.html#misleading-results",
    "href": "aHW_4.html#misleading-results",
    "title": "ST-518 HW 4",
    "section": "3. Misleading results",
    "text": "3. Misleading results\n(2 points) In lecture, we saw that when we fit a logistic model when extra binomial variation is present, we get standard errors that are ’too small’. Explain why this gives misleading results.\nIf the data have more variation than is estimated in the model, the standard errors will be too small and confidence intervals too narrow. Variation in a binomial is p(1-p). If the data are not truly from a binomial distribution and there is a larger spread, then that equation is wrong."
  },
  {
    "objectID": "aHW_4.html#distribution-of-insects-surviving",
    "href": "aHW_4.html#distribution-of-insects-surviving",
    "title": "ST-518 HW 4",
    "section": "4. Distribution of insects surviving",
    "text": "4. Distribution of insects surviving\n(1 point) Consider an experiment that studies the number of insects that survive a certain dose of an insecticide, using several batches of insects of size n each. The insects may be sensitive to factors that vary among batches during the experiment but these factors (such as temperature) were unmeasured. Explain why the distribution of the number of insects per batch surviving the experiment might show over dispersion relative to a binomial(n, p) distribution.\nThe insects in each batch are not independent of one another, they live together. Furthermore, each batch of insects is subject to unmeasured variables that are not in the model."
  },
  {
    "objectID": "aHW_2.html",
    "href": "aHW_2.html",
    "title": "ST-518 HW 2",
    "section": "",
    "text": "Question\n(4 points) It is often argued that victims of violence exhibit more violent behavior toward others. To study this hypothesis, a researcher searched court records to find 908 individuals who had been victims of abuse as children. She then found 667 individuals, with similar demographic characteristics, who had not been abused as children. Based on a search through subsequent years of court records, she was able to determine how many in each of these groups became involved in violent crimes, as shown in the following table.\nIt’s retrospective, so this should be an odds ratio.\n\n\n         inCrime\nvict      Yes  No\n  victim  102 806\n  control  53 614\n\n\nThe researcher concluded: ”Early childhood victimization has demonstrable long-term consequences for violent criminal behavior.”\nConduct your own analysis of the data and comment on this conclusion. Is there evidence of a difference between the two groups? Is the strength of the causal implication of this statement justified by the data from this study?\n\nAnswer\n\n\n\n\nmosaic(violent)\n\n\n\n\n\n\n\n\nThe mosaic plot shows that the proportions of folks both victims and not are roughly equal, but there are more victims convicted.\n\nchisq.test(violent)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  violent\nX-squared = 4.3205, df = 1, p-value = 0.03765\n\n\nA p-value of 0.03765 indicates that the proportion of victims who are charged with violent crimes is not the same as the proportion of non-victims that are charged with violent crimes.\n\n\n         inCrime\nvict      Yes  No\n  victim  102 806\n  control  53 614\n\n\n\n# p_1 = pop proportion, unknown\n# n = sample size\nn_1 &lt;-  violent[1] + violent[3]\nn_2 &lt;-  violent[2] + violent[4]\n# x = number of successes\nx_1 &lt;-  violent[1]\nx_2 &lt;-  violent[2]\n\n# phat_1 = sample proportions\nphat_1 &lt;-  x_1/n_1\nphat_2 &lt;-  x_2/n_2\n\nodds_v &lt;- phat_1/(1-phat_1)\n\nodds_c &lt;- phat_2/(1-phat_2)\n\nodds_v/odds_c\n\n[1] 1.46608\n\n\nThe odds of being convicted of a violent crime, if the person had previously been a victim of abuse, is estimated to be about a 1.5 times greater.\n\n\n\nIs the strength of the causal implication of this statement justified by the data from this study?\n\nbinom.test(x_1, n_1, p = phat_2)\n\n\n    Exact binomial test\n\ndata:  x_1 and n_1\nnumber of successes = 102, number of trials = 908, p-value = 0.0004571\nalternative hypothesis: true probability of success is not equal to 0.07946027\n95 percent confidence interval:\n 0.09252877 0.13469469\nsample estimates:\nprobability of success \n             0.1123348 \n\n\nThere is a very low probability that those who were victimized and and those who were not are convicted at the same rate (Exact binomial test) p-value = 0.0004571)\nI think the strength of the statement is justified."
  },
  {
    "objectID": "aHW_2.html#victims-of-violence",
    "href": "aHW_2.html#victims-of-violence",
    "title": "ST-518 HW 2",
    "section": "",
    "text": "Question\n(4 points) It is often argued that victims of violence exhibit more violent behavior toward others. To study this hypothesis, a researcher searched court records to find 908 individuals who had been victims of abuse as children. She then found 667 individuals, with similar demographic characteristics, who had not been abused as children. Based on a search through subsequent years of court records, she was able to determine how many in each of these groups became involved in violent crimes, as shown in the following table.\nIt’s retrospective, so this should be an odds ratio.\n\n\n         inCrime\nvict      Yes  No\n  victim  102 806\n  control  53 614\n\n\nThe researcher concluded: ”Early childhood victimization has demonstrable long-term consequences for violent criminal behavior.”\nConduct your own analysis of the data and comment on this conclusion. Is there evidence of a difference between the two groups? Is the strength of the causal implication of this statement justified by the data from this study?\n\nAnswer"
  },
  {
    "objectID": "aHW_2.html#analysis",
    "href": "aHW_2.html#analysis",
    "title": "ST-518 HW 2",
    "section": "",
    "text": "mosaic(violent)\n\n\n\n\n\n\n\n\nThe mosaic plot shows that the proportions of folks both victims and not are roughly equal, but there are more victims convicted.\n\nchisq.test(violent)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  violent\nX-squared = 4.3205, df = 1, p-value = 0.03765\n\n\nA p-value of 0.03765 indicates that the proportion of victims who are charged with violent crimes is not the same as the proportion of non-victims that are charged with violent crimes.\n\n\n         inCrime\nvict      Yes  No\n  victim  102 806\n  control  53 614\n\n\n\n# p_1 = pop proportion, unknown\n# n = sample size\nn_1 &lt;-  violent[1] + violent[3]\nn_2 &lt;-  violent[2] + violent[4]\n# x = number of successes\nx_1 &lt;-  violent[1]\nx_2 &lt;-  violent[2]\n\n# phat_1 = sample proportions\nphat_1 &lt;-  x_1/n_1\nphat_2 &lt;-  x_2/n_2\n\nodds_v &lt;- phat_1/(1-phat_1)\n\nodds_c &lt;- phat_2/(1-phat_2)\n\nodds_v/odds_c\n\n[1] 1.46608\n\n\nThe odds of being convicted of a violent crime, if the person had previously been a victim of abuse, is estimated to be about a 1.5 times greater."
  },
  {
    "objectID": "aHW_2.html#causal",
    "href": "aHW_2.html#causal",
    "title": "ST-518 HW 2",
    "section": "",
    "text": "Is the strength of the causal implication of this statement justified by the data from this study?\n\nbinom.test(x_1, n_1, p = phat_2)\n\n\n    Exact binomial test\n\ndata:  x_1 and n_1\nnumber of successes = 102, number of trials = 908, p-value = 0.0004571\nalternative hypothesis: true probability of success is not equal to 0.07946027\n95 percent confidence interval:\n 0.09252877 0.13469469\nsample estimates:\nprobability of success \n             0.1123348 \n\n\nThere is a very low probability that those who were victimized and and those who were not are convicted at the same rate (Exact binomial test) p-value = 0.0004571)\nI think the strength of the statement is justified."
  },
  {
    "objectID": "aHW_2.html#challenger",
    "href": "aHW_2.html#challenger",
    "title": "ST-518 HW 2",
    "section": "2. Challenger",
    "text": "2. Challenger\n(1 point) During an investigation of the U.S. space shuttle Challenger disaster, it was learned that project managers had judged the probability of mission failure to be 0.00001, whereas engineers working on the project had estimated failure probability at 0.005. The difference between these two probabilities, 0.00499, was discounted as being too small to worry about. Is a different picture provided by considering odds? How is that interpreted?\n\nphat_m &lt;- 0.00001\nphat_e &lt;- 0.005\n\nodds_m &lt;- phat_m/(1-phat_m)\n\nodds_e &lt;- phat_e/(1-phat_e)\n\nodds_ratio &lt;- odds_e/odds_m\n\nodds_ratio\n\n[1] 502.5075\n\n\nThe engineers thought it was about 500 x more likely the mission would fail."
  },
  {
    "objectID": "aHW_2.html#orange-tabby-cats",
    "href": "aHW_2.html#orange-tabby-cats",
    "title": "ST-518 HW 2",
    "section": "3 Orange tabby cats",
    "text": "3 Orange tabby cats\n(2 points) Suppose that 90% of orange tabby cats are male. Determine if the following statements are true or false, and explain your reasoning.\n\na distribution of sample proportions\n\nThe distribution of sample proportions of random samples of size 30 is left skewed.\n\nThere is no information regarding what is considered success. I suppose I’ll say that we are talking about male cats and if they are orange.\nThe sample proportion can be modeled as normal if np &gt; 10 and n(1-p) &gt;= 10.\n\n\n[1] \"np = 27n*(1-p) = 3\"\n\n\nThe success-failure condition isn’t met, I cannot say it’s normal. There are more orange male cats (successes), than not (failures).\nbinom &lt;- rbinom(100000, size = 30, prob = .9)\ndist &lt;- binom/30\n\nhist(dist)\nplot(density(dist))\n\n\n\n\n\n\n\n\n\n\nIt appears to be True, the distribution is skewed left.\n\n\n\nb sample size 4n\n\nUsing a sample size that is 4 times as large will reduce the standard error of the sample proportion by one-half.\n\n\\(SE = \\sqrt{\\frac{p(1-p)}{n}}\\)\n\\[\n\\sqrt{\\frac{p(1-p)}{n}} \\ = \\ x\\sqrt{\\frac{p(1-p)}{4n}}\n\\]\n\\[\n\\frac{\\sqrt{\\frac{p(1-p)}{n}}}{\\sqrt{\\frac{p(1-p)}{4n}}} \\ = \\ x\n\\]\n\\[\nx^2 \\ = \\ \\frac{p(1-p)}{n} \\times \\frac{4n}{p(1-p)}\n\\]\n\\[\nx^2 \\ = \\ 4\n\\]\n\\(\\frac{SE_{n}}{2} \\ = \\  SE_{4n}\\)\nTrue\n\n\n\nc size 140\n\nThe distribution of sample proportions of random samples of size 140 is approximately normal.\n\ns &lt;- 140\nbinom &lt;- rbinom(1000, size = s, prob = .9)\ndist &lt;- binom/s\n\nhist(dist)\nplot(density(dist))\n\n\n\n\n\n\n\n\n\n\nMostly True, It still has a little bit of a skew.\n\n\nd size 280\n\nThe distribution of sample proportions of random samples of size 280 is approximately normal.\n\ns &lt;- 280\nbinom &lt;- rbinom(1000, size = s, prob = .9)\ndist &lt;- binom/s\n\nhist(dist)\nplot(density(dist))\n\n\n\n\n\n\n\n\n\n\nTrue At least it appears to be mostly normal."
  },
  {
    "objectID": "aHW_2.html#voters-in-california",
    "href": "aHW_2.html#voters-in-california",
    "title": "ST-518 HW 2",
    "section": "4. Voters in California",
    "text": "4. Voters in California\n(2 points) A 2010 survey asked 827 randomly sampled registered voters in California, ”Do you support or do you oppose drilling for oil and natural gas off the coast of California? Or do you not know enough to say?” Below is the distribution of responses, separated based on whether or not the respondent graduated from college.\n\n\n            C_Grad\nsupport      yes  no\n  support    154 132\n  oppose     180 126\n  Don't know 104 131\n  total      438 389\n\n\n\nTotal &lt;- 438 + 389\n\n\na percents\n\nWhat percents of college graduates and non-college graduates in this sample do not know enough to have an opinion on drilling for oil and natural gas off the coast of California (i.e., report two percent values)?\n\n\nnc &lt;- 438\nnn &lt;- 389 \nigc &lt;- 104\nign &lt;- 131\n\npc &lt;- igc / nc  \npn &lt;- ign / nn\n\n(pc*100) |&gt; round()\n\n[1] 24\n\n(pn*100) |&gt; round()\n\n[1] 34\n\n\n24% of college grads and 34% of those who did not declared ignorance.\n\n\nb hypothesis test\n\nConduct a hypothesis test to determine whether there is evidence that the proportion of college graduates who do not have an opinion on this issue is different from that of non-college graduates among registered voters in CA.\n\nI hypothesize that there is no difference in the proportions of folks who declare ignorance between those with and without a college degree.\nsuccess-failure criteria:\n\n# pc*nc\n# nc*(1-pc)\n# \n# pn*nn\n# nn*(1-pn)\n\npool &lt;- (pc*nc + pn*nn)/(nc + nn)\nnt &lt;- nc+nn\npool*nt\n\n[1] 235\n\nnt*(1-pool)\n\n[1] 592\n\n\nAll greater than 10, and I believe this survey was random. I can proceed with the test for equality of proportions.\n\nprop.test(c(igc, ign), c(nc,nn))\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  c(igc, ign) out of c(nc, nn)\nX-squared = 9.5084, df = 1, p-value = 0.002045\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.16333768 -0.03529832\nsample estimates:\n   prop 1    prop 2 \n0.2374429 0.3367609 \n\n\nI must reject that hypothesis, there is evidence that there is a difference in the proportion of CA voters who proclaim ignorance about off shore drilling, (p-value = 0.002045).\nIt appears that the true difference lies between 3.5% & 16.3%. The proportion of CA voters who proclaimed ignorance in matters of offshore drilling was 3 to 16% higher among voters who did not graduate from college."
  },
  {
    "objectID": "aHW_2.html#british-male-physicians",
    "href": "aHW_2.html#british-male-physicians",
    "title": "ST-518 HW 2",
    "section": "5. British male physicians",
    "text": "5. British male physicians\n(1 point) A study of British male physicians noted that the proportion who died from lung cancer was 0.0140 per year for cigarette smokers and 0.00010 per year for nonsmokers. Additionally, the proportion who died from heart disease was 0.00669 for smokers and 0.00413 for nonsmokers.\nWhich response (lung cancer or heart disease) is more strongly related to cigarette smoking, in terms of the reduction in deaths that could occur with the absence of smoking?\n\npls &lt;- 0.0140\npln &lt;- 0.00010\n\nphs &lt;- 0.00669\nphn &lt;- 0.00413\n\nols &lt;- pls/(1-pls)\noln &lt;- pln/(1-pln)\n\nodds.lung &lt;- ols/oln\n\n\nohs &lt;- phs/(1-phs)\nohn &lt;- phn/(1-phn)\n\nodds.heart &lt;- ohs/ohn\n\nodds.lung / odds.heart\n\n[1] 87.4206\n\nodds.lung\n\n[1] 141.9736\n\nodds.heart\n\n[1] 1.624029\n\n\nThe odds of dying from lung cancer as a smoker are 87 times that of from heart disease. Lung cancer is more strongly related to smoking than heart disease."
  },
  {
    "objectID": "9_Imp_Pred_Validate.html",
    "href": "9_Imp_Pred_Validate.html",
    "title": "9 Imp, Pred, Validate",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAfter successful completion of this module, you will be able to:\n\nPerform a complete analysis of a dataset involving categorical or count responses.\nSpecifically articulate the question(s) of interest that you will explore using the data you chose for your final project.\n\nTask list\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview/work through Birdkeeping.Rmd\nReview/work through Badgers.Rmd with accompanying data Badgers.csv\nReview/work through Respiratory.Rmd with accompanying data respiratory.csv\nRead through the Final Project.pdf assignment and complete the tasks for Week 9.\n\n\n\n\n\nlibrary(tidyverse)\n\nbadgers &lt;- read.csv(\"../../Data/Badgers.csv\")\nrespiration &lt;- read.csv(\"../../Data/respiratory.csv\")"
  },
  {
    "objectID": "7_Random_Effects.html",
    "href": "7_Random_Effects.html",
    "title": "7 Random_Effects",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAfter successful completion of this module, you will be able to:\n\nWrite out the expression of a generalized linear mixed model.\nDescribe the situation in which adding a random effect is important\nDescribe the correct method for interpreting fixed effect coefficient estimates from GLMM and be able to give an example.\n\nIn R:\n\nFit GLMM in R, and perform model selection for both the random and fixed parts.\nUse some examples to understand the issue involved with interpreting fixed effect estimates from GLMM.\nPrepare and submit an R markdown script.\n\nTask list\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 7 Readings and Lectures\nParticipate in the Module 7 Discussion\nSubmit Module 7 Lab\nSubmit Module 7 Homework\nTake the Module 7 R Quiz\nTake the Module 7 Content Quiz\nlibrary(tidyverse)\nlibrary(Sleuth3)\nlibrary(vcdExtra)\nlibrary(magrittr)\nlibrary(lme4)     # access the mixed functions"
  },
  {
    "objectID": "7_Random_Effects.html#clustered-data",
    "href": "7_Random_Effects.html#clustered-data",
    "title": "7 Random_Effects",
    "section": "Clustered Data",
    "text": "Clustered Data\n\nFish in tanks example\nObservation of tumors in the same tank are dependent\nClustering leads to correlated Bernoulli observations, which manifests as over dispersion in log-regs.\nObservations that are clustered in space or time are more similar and therefore dependent.\nDo we want to infer about the clusters or do we want to control for them.\nGroup id as fixed effect if we want to infer about the cluster.\nGroup id as random effect if we want to control for clusters.\nGenerally, if we want CI or estimates, they should be fixed effects."
  },
  {
    "objectID": "7_Random_Effects.html#mixed-effects",
    "href": "7_Random_Effects.html#mixed-effects",
    "title": "7 Random_Effects",
    "section": "Mixed Effects",
    "text": "Mixed Effects\n\nX2 &lt;- tank\n\n# Fixed model \nlog(odds) = B0 + B1*X + B2*X2\n\netaij &lt;- tank\nXij &lt;- dose ith fish in jth tank\n\n# Mixed effects model \nlog(odds) = B0 + B1*Xij + B2*etaj\n\netaj sim ind N(0, var) for i = 1 to T\n\nThe quasibinomial is an alternative to mixed effects for handling Over dispersion."
  },
  {
    "objectID": "7_Random_Effects.html#mixed-example",
    "href": "7_Random_Effects.html#mixed-example",
    "title": "7 Random_Effects",
    "section": "Mixed Example",
    "text": "Mixed Example\nlog(odds) = beta_0 + beta_1log(dose)_ij + beta_2 log(dose)_ij + eta_j\n\nglmer in lme4\ndoesn’t converge\ncompare quasibinomial\n\n\ndata(ex2116)\ntumors &lt;- ex2116\n\n# Add no  tumor and tank id. \ntumors %&lt;&gt;% mutate(Dose = Dose, Tumor = Tumor, NoTumor = Total - Tumor, TankID = factor(1:nrow(tumors)),logDose = log(Dose), logDose2 = log(Dose)^2)\n\n# fit fixed effects logisitic regression\nglm1 &lt;- glm(cbind(Tumor,NoTumor) ~ logDose + logDose2, data = tumors, family=binomial)\nsummary(glm1)\n\n\nCall:\nglm(formula = cbind(Tumor, NoTumor) ~ logDose + logDose2, family = binomial, \n    data = tumors)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49343   2.086  0.03699 *  \nlogDose     -1.03048    0.35743  -2.883  0.00394 ** \nlogDose2    -0.39195    0.06136  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: 119.45\n\nNumber of Fisher Scoring iterations: 4\n\n\npsi is greater than 1.\n\n# fit fixed effects logistic regression with quasi-binomial likelihood\nglm2 &lt;- glm(cbind(Tumor,NoTumor) ~ logDose + logDose2, data = tumors, family=quasibinomial)\nsummary(glm2)\n\n\nCall:\nglm(formula = cbind(Tumor, NoTumor) ~ logDose + logDose2, family = quasibinomial, \n    data = tumors)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.02921    0.59942   1.717   0.1041    \nlogDose     -1.03048    0.43421  -2.373   0.0297 *  \nlogDose2    -0.39195    0.07454  -5.258 6.41e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasibinomial family taken to be 1.475778)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 4\n\n\nThere is evidene of overdisperion in the model. This is the better model because it accounts for the dispersion.\n\n# fit mixed effects logistic regression, using Tank as random effect\nglm3 &lt;- glmer(cbind(Tumor,NoTumor) ~ logDose + logDose2 + (1|TankID), data = tumors,family=binomial)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00506263 (tol = 0.002, component 1)\n\n\n\nUse columns Tumor and NoTumor\n+(1|TankID) adds intercept term for each tank.\nis a pipe.\nconvergence warning is about the variance being small. Trouble optimizing the surface to estimate.\nNeed to start the algorithm somewhere or it picks.\ngetME get mixed effects from lme4, go to glm3 and pull off theta, the random effects variance, and the estimates of the fixed effects.\n\n\n# oops, it looks like theres' a convergence problems. Let's re-run the glmer algorithm\n# using the values from the model we just fit as starting points:\n(init &lt;- getME(glm3, name =c (\"theta\",\"fixef\")))\n\n$theta\nTankID.(Intercept) \n        0.09980808 \n\n$fixef\n(Intercept)     logDose    logDose2 \n  1.0346691  -1.0309744  -0.3925934 \n\n\n\nestimate for RE std dev is .099\nfixed effects are similar to the regular model\nstart at these values.\n\n\nglm3 &lt;- glmer(cbind(Tumor,NoTumor) ~ logDose + logDose2 + (1|TankID), data=tumors, start=init, family=binomial)\nsummary(glm3)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: cbind(Tumor, NoTumor) ~ logDose + logDose2 + (1 | TankID)\n   Data: tumors\n\n     AIC      BIC   logLik deviance df.resid \n   121.3    125.3    -56.6    113.3       16 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.79604 -0.62245 -0.08873  0.97928  1.58266 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n TankID (Intercept) 0.009959 0.0998  \nNumber of obs: 20, groups:  TankID, 20\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.0349     0.5219   1.983  0.04736 *  \nlogDose      -1.0308     0.3780  -2.727  0.00639 ** \nlogDose2     -0.3926     0.0647  -6.067  1.3e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) logDos\nlogDose  0.969        \nlogDose2 0.915  0.983 \n\n\n\nNo trouble with convergence this time.\nFixed effects table is the same as glm, not the numbers, but the table is there.\nRandom effects variance and std dev is new.\nVariance is .0099 and variance cannot be zero or negative.\nThese being non zero means there is evidence of over dispersion.\n\n\nsummary(glm1)$coefficients\n\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept)  1.0292126  0.4934250  2.085854 3.699184e-02\nlogDose     -1.0304804  0.3574260 -2.883060 3.938329e-03\nlogDose2    -0.3919491  0.0613608 -6.387614 1.684940e-10\n\nsummary(glm2)$coefficients\n\n              Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept)  1.0292126 0.59942066  1.717012 1.041388e-01\nlogDose     -1.0304804 0.43420681 -2.373248 2.968769e-02\nlogDose2    -0.3919491 0.07454208 -5.258091 6.408881e-05\n\nsummary(glm3)$coefficients\n\n              Estimate Std. Error   z value     Pr(&gt;|z|)\n(Intercept)  1.0348488  0.5218465  1.983052 4.736161e-02\nlogDose     -1.0308418  0.3780293 -2.726883 6.393563e-03\nlogDose2    -0.3925717  0.0647011 -6.067465 1.299448e-09\n\n\n\n1 is binomial, 2 is quasi, estimates are the same std errs is not.\n3 is mixed, but the estimates are similar and the std errs are intermediate.\nThe mixed effects model is likelihood based and can be compared via AIC.\n\n\n# compare using AIC\nAIC(glm1,glm3)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nglm1\n3\n119.4461\n\n\nglm3\n4\n121.2700\n\n\n\n\n\n\n\nThe fixed effects model wins, but it’s close.\nThere is overdispersion, so the mixed effect can/should be used."
  },
  {
    "objectID": "7_Random_Effects.html#modeling-strategies",
    "href": "7_Random_Effects.html#modeling-strategies",
    "title": "7 Random_Effects",
    "section": "Modeling Strategies",
    "text": "Modeling Strategies\n\nSettle on a model for the fixed effects\nsettle on a model for the Random effects.\nWhen you don’t know what should be fixed, fit a rich model for fixed effects. Then look at Random effects.\nIterate between steps one and two.\nmake inference on the fixed estimates\nReport on random effects.\nIf there were different labs for each tank, but tanks in a diff lab, then you only need a REffect for tank.\nConsider this sort of info\nThings that are clustered tend to be more similar.\nIf there are many types of clustering or nesting, you need many RE for each type of cluster.\nLook at estimated RE variances, If small maybe they’re not needed, unless there is some reason to include them.\nLike they correspond to nesting or generate over dispersion\nEvaluate normality of REs.\n\nLooking at normality.\n\nRE &lt;- as.numeric(unlist(ranef(glm3)$TankID))\nqqnorm(RE)\nqqline(RE)\n\n\n\n\n\n\n\n\nLooks good.\n\nUse AIC or BIC to compare two mixed effects models.\nfixed effects should be fixed.\nYou can also compare mixed models and fixed models.\n\nLastly summarize the inference.\nEx:\nWe fit a generalized linear mixed model to the fish tumor counts, using TankID as a random effect and log(Dose) and its square as fixed effects. The random effect variance is estimated to be 0.01, which, though small, seems necessary to include given the structure of the experiment and the evidence of over dispersion in the tumor counts. Both log(Dose) and its square were important to the model, with p-values of p = 0.006 and p &lt; 0.0001, respectively.\n\nInterpreting the fixed effects is conditional on the mixed effects."
  },
  {
    "objectID": "7_Random_Effects.html#model-interpretation",
    "href": "7_Random_Effects.html#model-interpretation",
    "title": "7 Random_Effects",
    "section": "Model Interpretation",
    "text": "Model Interpretation\n\nBack transformations and complications.\nUsing the same mixed effects model for the fish tumors.\nSolving for the p_js in\n\n\\(pj = \\frac{exp{β0 +β1logDosej +β2logDose2j +ηj}}{1+exp{β0 +β1logDosej +β2logDose2j +ηj}}\\)$\n\nResults in each tank having it’s own dose-response.\nWe don’t want tank level inference. We want to say something about each dose.\nCan’t average of the random effects because of non-linearity of back transformation of logit link.\nIn a linear mixed model they are linear and we can average.\nWe have to make conditional inference.\nThey are conditioned on two observations being in the same cluster.\neta_js need to be the same.\nWe could go back and use the quasi-binomial model to handle the over dispersion.\nThat would be correct here\nInference here is academic. We are assuming the REs don’t change the log(odds) of a tumor by much.\nThe dose probability CI slide shows that with the caveat that the RE are meaningless.\n\nAlternative approaches to eliminate conditional inference.\n\ngeneralized estimating equations\nconditional maximum likelihood.\n\nThey encourage us to study more on this if we end up actually using these models.\nClustered categorical and count responses is the search term."
  },
  {
    "objectID": "7_Random_Effects.html#r",
    "href": "7_Random_Effects.html#r",
    "title": "7 Random_Effects",
    "section": "R",
    "text": "R"
  },
  {
    "objectID": "7_Random_Effects.html#c",
    "href": "7_Random_Effects.html#c",
    "title": "7 Random_Effects",
    "section": "C",
    "text": "C"
  },
  {
    "objectID": "5_Log_linear_Regression.html",
    "href": "5_Log_linear_Regression.html",
    "title": "5 Log-lin-Reg",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAfter successful completion of this module, you will be able to:\n\nWrite out the expression of a Poisson regression model, including the response distribution and the model equation.\nInterpret the results of a Poisson regression.\nIdentify potential problems with the fit of a Poisson regression model.\nDescribe models for over dispersion of Poisson counts in the regression setting.\nEvaluate and compare models in the Poisson regression setting.\nDescribe how log linear models can be used for general contingency table data.\n\nIn R:\n\nFit Poisson, quasi-Poisson and negative binomial regression models, and make comparisons among them.\nFit log linear models to general contingency table data.\nUse simulations to understand problems that can arise when the sample size is small and/or the counts are small.\nPrepare and submit an R markdown script.\n\nTask list\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 5 Readings and Lectures\nSubmit Module 5 Lab\nSubmit Module 5 Homework\nParticipate in the Module 5 Discussion\nR Quiz\nContent Quiz\nlibrary(arm)\nlibrary(Sleuth3)\nlibrary(tidyverse)\nlibrary(vcdExtra)\nlibrary(magrittr)"
  },
  {
    "objectID": "5_Log_linear_Regression.html#w5-lectures",
    "href": "5_Log_linear_Regression.html#w5-lectures",
    "title": "5 Log-lin-Reg",
    "section": "w5 Lectures",
    "text": "w5 Lectures\nBook is better than lectures!\n\n\nCode\n#\n# Example using Agresti's crab data\n#\n\nlibrary(ggplot2)\n#install.packages(\"glm2\")\nlibrary(glm2)\nhelp(crabs, package = \"glm2\")\ndata(crabs, package = \"glm2\")\n\n#\n# Take a look at the number of satellites (males) vs Width\n#\n\nwork = crabs\nggplot(work,aes(Width,Satellites)) + geom_point()\n\n#\n# There are some zeroes, let's adjust for log transformation\n# and re-plot\n#\n\nwork$lSat = log(ifelse(work$Satellites==0,0.1,work$Satellites))\nggplot(work,aes(Width,lSat)) + geom_point() + ylab(\"log(Satellites)\")\n\nggplot(work,aes(Dark,lSat)) + geom_point() + ylab(\"log(Satellites)\")\nggplot(work,aes(GoodSpine,lSat)) + geom_point() + ylab(\"log(Satellites)\")\nggplot(work,aes(Width,lSat)) + geom_point()  + facet_wrap(~Dark+GoodSpine)+ ylab(\"log(Satellites)\")\n\n\n#\n# Fit a rich model with all interactions\n#\n\nmod1 = glm(Satellites~Width*Dark*GoodSpine,data=work,family=poisson)\nsummary(mod1)\n\n#\n# Look at residuals and fitted values\n#\n\nwork$res = residuals(mod1)\nwork$fits = predict.glm(mod1,type=\"response\")\n\nggplot(work,aes(Width,res)) + geom_point()\nggplot(work,aes(Satellites,fits)) + geom_point()\n\n\n\n\nCode\n#\n# Fit and compare quasi-Poisson and negative binomial models to the Crab\n# data\n# \n\nlibrary(ggplot2)\nlibrary(MASS)     # access the glm.nb function\nlibrary(glm2)     # access the crab data\n\ndata(crabs, package = \"glm2\")\n\nwork = crabs\n\n# fit the Poisson, quasi-Poisson and negative binomial models\n\nmod1 = glm(Satellites~Width*Dark*GoodSpine,data=work,family=poisson)\nmod2 = glm(Satellites~Width*Dark*GoodSpine,data=work,family=quasipoisson)\nmod3 = glm.nb(Satellites~Width*Dark*GoodSpine,data=work)\n\n# compare coefficient estimates\n\ncbind(coef(mod1),coef(mod2),coef(mod3))\n\n# compare output from the two models that account for over dispersion\n\nsummary(mod2)\nsummary(mod3)\n\n# look at some residual plots\n\nwork$res2 = resid(mod2)\nwork$res3 = resid(mod3)\n\nggplot(work,aes(Width,res2)) + geom_point()\nggplot(work,aes(Width,res3)) + geom_point()\n\n# conclusion: favor the negative binomial approach over the quasi-poisson\n# approach (likelihood-based, we get AIC)\n\n# more to come: almost 36% of the satellite counts are zero...another\n# modeling approach is to use a zero-inflated model...module 6\n\n\n\n\nCode\n#\n# Example using Sleuth exercise 22.26\n#\n\nlibrary(Sleuth3)\nlibrary(MASS)\nlibrary(ggplot2)\n\nhelp(ex2226)\nwork = ex2226\nnames(work)\n\n# exploratory analysis\n\n# are there zeroes?\n\nsummary(work$Moons)\nwork$Moons1 = ifelse(work$Moons==0,0.1,work$Moons)\n\n# log moons versus distance\n\nggplot(work,aes(Distance,log(Moons1))) + geom_point()\n\n# log moons versus diameter\n\nggplot(work,aes(Diameter,log(Moons1))) + geom_point()\nggplot(work,aes(log(Diameter),log(Moons1))) + geom_point()\n\n# log moons versus mass\n\nggplot(work,aes(Mass,log(Moons1))) + geom_point()\nggplot(work,aes(log(Mass),log(Moons1))) + geom_point()\n\n# log diameter versus log mass\n\nggplot(work,aes(log(Diameter),log(Mass))) + geom_point()\n\ncor(log(work$Diameter),log(work$Mass))      \n\n# fit a rich model--with n = 13, I won't include interaction\n# terms \n\nmod1 = glm(Moons~Distance+log(Diameter)+log(Mass),data=work,family=poisson)\nsummary(mod1)\n\n# look at residuals, dispersion, goodness of fit\n\nwork$res1 = residuals(mod1)\nggplot(work,aes(Distance,res1)) + geom_point()\nggplot(work,aes(Diameter,res1)) + geom_point()\nggplot(work,aes(Mass,res1)) + geom_point()\n41.897/9\n1-pchisq(41.897,9)\n\n# there is evidence of over dispersion, fit a NB model:\n \nmod2 = glm.nb(Moons~Distance+log(Diameter)+log(Mass),data=work)\nsummary(mod2)\n\n\n# look at residuals again\n\nwork$res2 = residuals(mod2)\nggplot(work,aes(Distance,res2)) + geom_point()\n\n# It appears that the diameter of the planet and its mass are associated\n# with the number of moons the planet has.\n\n\n\nLog Linear Regression\nCrabs by width and color.\nAll examples use poisson.\n\\[\nY-I = log(\\lambda_i) = \\beta_0 + ... + \\beta_kX_{k-1i}\n\\]\nLink is log.\npdf = Lye-L / y!\nnon constant variance.\nlambda may not be wnough to represent variation.\nMultiplicative vs add error terms mean GLm is better than mlr. even if variance is constant. MLR assumes additivity.\nCoef fit by ML.\nEverything is similar to binomial counts.\nPoisson counts look at y and exp vars.\nIf one is zero, DNE, add a num to create a plot.\n\n\nCrab Example\nAgresti ex.\n173 crabs, data in glm2 library\nwidth, dark and and good spawn are exp.\nfitting a rich model.\nScript above.\nplotting sats by width shows lots of zeroes but no pattern. Lots of ladies with no men. Maybe a hint of inc relationship.\nAdjusting for zero by adding .01 to zero only. then take log.\nplotting sats by width again shows the zeroes by -2 and everything else pretty much the same.\nSats by dark and light shows maybe more by dark, and for better spine condition.\nfacet wrap by yes no for spine and dark doesn’t show much, but dark and spine bad is not populated much.\nGLM for sats~width*dark*spine in poisson family with automatic log link.\ndispersion is assumed one by default.\nthree way interacition is significant. but we can’t make inference without looking at disperison.\nResids and fits with predict by type response for fits. and residuals().\nwidth by resids shows the line near zero and others for the fact that the data are discrete.\nResids are spread out and theres a lot above 2 and 3.\nPlotting fitted by observed counts, we expect y = x. That is not the case. Lots near zero and spread near 1 - 5.\nWe want to fit for extra poisson variation. The plots make her think dispersion is at fault.\n\n\nModel Fit\nTalk about fit with poisson regression\ndeviance GOF and extra poisson variation via the crabs.\nthere are dev, pearson, and std-resids. dev are default in R.\nIf the model is correct and sample is large dev resids look normal.\ndev GOF test is informal test of adequecy, not good.\ncompares reg model to sat model\na large p may mean good fit or inadequate data\nsmall p, model is correst poisson is wrong, outliers.\nAs in log reg, dev gof stat is sum os squared resids. resid deviance.\nIn the poisson case chi 2 requires means to be large (most greater than 5). Counts give idea of means.\nFor crabs Resid dev is 550 on 165 df. 75% are less than or eq to 5. We shouldn’t use dev GOf.\nextra poisson variation. like binom variation from more var in obseveed counts. Var in poisson via lambda.\nIf E-poisson var exists var too small and SE too small.\nChecking, is it likely, is there clustering, missing exp variation.\nWe could compare to sample var and mean to groups to counts with identical exp vars . not often possible.\nDev GOF gives an idea., calc disp param, examine dev resids plots.\n= resid/ df. here = 3.33. suggestind extra var.\nLooking at dev resids by width shows lots above 2 and below -2 means there could be extra dispersion.\n\n\nOver Dispersion in R\nWe can use quisi poisson lM like we did with binom by adding an extra param.\nNeg binom regression maight work.\nmass and glm2 libs.\nmass for glm.nb for neg binom. mass before glm to get correct crab data.\nfit poisson , quasi and neg.\nglm family is poisson, and quisipoisson then nb is glm.nb w/o family.\ncoef for estimates. poisson and quasi are the same as before. SE does. nb does slightly change the ests.\nSummary for quasi and nb. quasi shows 1 sig variable. disp is 3.25.\nRemove the three way interaction for further analysis.\nglm.nb shows shows different everything but the same significance. We do get and AIC for this for model comparison.\nPlotting resid plots for these shows via resid(mod) to data$col. \nquasi is the same as the first bc coefs are the same and resids are based on those, but the glm.nb shows a different scale and less above and below 2 or -2.\nnb model does a good job for extra dispersion in this case. plus its likelihood based.\nWe see zero inflation and that is mod 6.\n\n\nData Analysis Strategy\ndealing with poisson regression and looking at a large example.\nbe clear about objectives,\nwhat element can answer\nwhat is response and exp var. How do they relate(hyp)\nif poisson count perform exp analysis. Look for zeroes in response. Plot log of responses agaisnst exp vars.\nrelative to the q of interest and samle size fit a rich model.\nexaming the resids, check dev GOF and look at psi.\nrefit with nb\nperfrom reduction and anova or aic. but don’t use model selection bias.\nlook at resid plots again.\nEx vai slueth for planets,\nwhat char of planets makes moons.\nsleuth mass ggplot.\nname dist dia mass moons are variables.\nexplore for zeroes, and add.01 for plotting log.\nsummary shows min and first q are zero, at least 25% are zero.\nlog moons by dist is zero inflated but maybe negatively related.\ndist by dia is also zero inflated but maybe curved and increasing. dist by log dia is linear.\nmad via log moons is curved, log mass is inc. both dia and mass are inc. mog mass and log dia is near y = x. Both may not be good in the model, but a rich model is what we are going for at first.\nglm moons by .og dia log mass and dist.\npsi is 21/9 is greater than 2 and maybe there’s dispersion.\nplotting resids by exp variables:\n\nmass is zero and one large one, spread is good.\ndia is the same\ndist is more spread out but no pattern.\nall show zero inflation.\ndispersion is 2.4\n\nX squared GOF is low.\nFitting a nb mod:\nmass and dia are again sig.\nresids:\n\ndist is normal, no pattern\n\nit appears dia and mass are important to a planet having moons, but dia and mass are cov. check diff models with aic and anova.\n\n\nLog Linear Models for cont tables.\nexample and notation.\nAgresti table for weed and booze. alc yes, cigs, yes/no, weed yes/no.\nquestion isn’t about variation in use from one to another but looking for association of booze, cigs, and weed.\nDo smokers smoke it all and such.\nsub-notation, I 1-2 for booze yes and no, j, 1-2 for cigs and k for weed. n_111 for weed booze and cig yes.\npi_ijk for prob by cat.\nN = 2276 for total participants, mu_ijk = N x pi_ijk.\nlog(mu_ijk) = beta_0 + … + b_7X_iY_jZ_k in the parlance of the course.\nexpamine reg coef of interaction terms for associations.\nif b_7 is zero and three ways have no chance then they are ind.\nfor the two ways its the same thought, we’ll consider three ways and two ways in lab."
  },
  {
    "objectID": "5_Log_linear_Regression.html#lab",
    "href": "5_Log_linear_Regression.html#lab",
    "title": "5 Log-lin-Reg",
    "section": "Lab",
    "text": "Lab"
  },
  {
    "objectID": "5_Log_linear_Regression.html#hw",
    "href": "5_Log_linear_Regression.html#hw",
    "title": "5 Log-lin-Reg",
    "section": "HW",
    "text": "HW\n\n(2 points) Recall the obesity problem from Homework 1. The data are as follows:\n\n        CVD Death\n\n            Yes         No\nObese       16        2045\nNot obese   7         1044\nUsing Poisson log linear regression, test for independence between obesity and CVD death outcome. (Hint: this is equivalent to testing that the interaction term in the model is zero.) How does your answer compare to a chi-square test on the same data?\n\no &lt;- expand.grid(\n  ob = factor(c(\"Obese\", \"NotObese\"), levels = c(\"Obese\", \"NotObese\")),\n  death = factor(c(\"Yes\", \"No\"), levels = c(\"Yes\", \"No\"))\n)\no$Freq &lt;- c(16, 7, 2045,  1044)\n\no_tab &lt;- xtabs(data = o, Freq~ob + death)\no_tab\n\n          death\nob          Yes   No\n  Obese      16 2045\n  NotObese    7 1044\n\n\n\nm1 &lt;- glm(data = o, \n    family = poisson, \n    Freq~ob+death)\ns1 &lt;- summary(m1)\ns1\n\n\nCall:\nglm(formula = Freq ~ ob + death, family = poisson, data = o)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.7234     0.2089   13.04   &lt;2e-16 ***\nobNotObese   -0.6734     0.0379  -17.77   &lt;2e-16 ***\ndeathNo       4.9001     0.2093   23.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4376.49698  on 3  degrees of freedom\nResidual deviance:    0.11741  on 1  degrees of freedom\nAIC: 32.796\n\nNumber of Fisher Scoring iterations: 3\n\n\n\nm1 &lt;- glm(data = o, \n    family = poisson, \n    Freq~ob+death)\ns1 &lt;- summary(m1)\ns1\n\n\nCall:\nglm(formula = Freq ~ ob + death, family = poisson, data = o)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.7234     0.2089   13.04   &lt;2e-16 ***\nobNotObese   -0.6734     0.0379  -17.77   &lt;2e-16 ***\ndeathNo       4.9001     0.2093   23.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4376.49698  on 3  degrees of freedom\nResidual deviance:    0.11741  on 1  degrees of freedom\nAIC: 32.796\n\nNumber of Fisher Scoring iterations: 3\n\n\nThe statsistical independence model for log lin reg:\n\\(\\mu_{ij} = \\mu \\alpha \\beta_j\\)\nObese , not obese are one variable. Death yes or no are another.\n\\[\n\\mu_{ij} = n \\pi_i + \\pi_{+j}, \\  i = 1  \\ to \\  I,  \\ j = 1  \\ to \\ J\n\\]\nSubscript +j means column j total.\n\nChi squared\n\nn &lt;- sum(o$Freq)\n\nn11 &lt;- 16\nn12 &lt;- 2045\nn21 &lt;- 7\nn22 &lt;- 1044\n\nj1 &lt;- n11 + n21\nj2 &lt;- n12 + n22\ni1 &lt;- n11 + n12\ni2 &lt;- n21 + n22\n\nmu_11 &lt;- i1*j1/n\nmu_12 &lt;- i1*j2/n\nmu_21 &lt;- i2*j1/n\nmu_22 &lt;- i2*j2/n\n\nXsquared &lt;- (((n11 - mu_11)^2)/mu_11) + (((n12 - mu_12)^2)/mu_12) + (((n21 - mu_21)^2)/mu_21) + (((n22 - mu_22)^2)/mu_22)\n\npchisq(Xsquared, df = 1, lower.tail = F)\n\n[1] 0.7340665\n\n\n\nans &lt;- log(mu_11) + log(mu_22) - log(mu_12) - log(mu_21)\nexp(ans)\n\n[1] 1\n\n\n\ni1*j1/n\n\n[1] 15.23233"
  },
  {
    "objectID": "5_Log_linear_Regression.html#quizzes",
    "href": "5_Log_linear_Regression.html#quizzes",
    "title": "5 Log-lin-Reg",
    "section": "Quizzes",
    "text": "Quizzes\n\nR\nAll questions rely on the data in the quine dataset in the MASS library. The dataset contains information about children from Walgett, New South Wales, Australia. They were classified by Ethnicity (Eth), Age, Sex and Learner (Lrn) status and the number of days (Days) absent from school in a particular school year was recorded.\n\nlibrary(MASS)\ndata(\"quine\")\ndf &lt;- quine\n\nQuestion 1\nAll of the explanatory variables, Eth, Age, Sex, and Lrn are categorical. What does this mean for the analysis we should perform? (Select one) Group of answer choices\nWe can use log linear regression using combinations of these explanatory variables.\nQuestion 2\nFit a model that contains all of the two-way interactions between the explanatory variables. You should notice that the effect corresponding to AgeF3:LrnSL cannot be estimated. Why is this? (Select one) Group of answer choices\n\nglm(data = df, \n    family = poisson, \n    Days~(Eth + Age + Sex + Lrn)^2) |&gt; summary()\n\n\nCall:\nglm(formula = Days ~ (Eth + Age + Sex + Lrn)^2, family = poisson, \n    data = df)\n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.93246    0.09826  29.843  &lt; 2e-16 ***\nEthN        -0.17399    0.12134  -1.434   0.1516    \nAgeF1       -0.04270    0.12691  -0.336   0.7365    \nAgeF2       -0.08632    0.16164  -0.534   0.5933    \nAgeF3       -0.15290    0.11898  -1.285   0.1987    \nSexM        -0.71452    0.12229  -5.843 5.14e-09 ***\nLrnSL        0.21608    0.14558   1.484   0.1377    \nEthN:AgeF1  -0.92889    0.14657  -6.337 2.34e-10 ***\nEthN:AgeF2  -1.33398    0.13504  -9.879  &lt; 2e-16 ***\nEthN:AgeF3  -0.11242    0.13478  -0.834   0.4042    \nEthN:SexM    0.43902    0.09208   4.768 1.86e-06 ***\nEthN:LrnSL   0.26415    0.11378   2.322   0.0203 *  \nAgeF1:SexM  -0.05565    0.16303  -0.341   0.7328    \nAgeF2:SexM   1.09942    0.15281   7.195 6.26e-13 ***\nAgeF3:SexM   1.15949    0.13859   8.366  &lt; 2e-16 ***\nAgeF1:LrnSL -0.13019    0.15688  -0.830   0.4066    \nAgeF2:LrnSL  0.37340    0.14563   2.564   0.0103 *  \nAgeF3:LrnSL       NA         NA      NA       NA    \nSexM:LrnSL   0.04143    0.13718   0.302   0.7627    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2073.5  on 145  degrees of freedom\nResidual deviance: 1368.7  on 128  degrees of freedom\nAIC: 1993.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\ndf |&gt; filter(Age == \"F3\" & Lrn == \"SL\")\n\n\n\n\n\nEth\nSex\nAge\nLrn\nDays\n\n\n\n\n\n\n\n\nNo students.\nQuestion 3\nFrom the summary information you obtained in question 2, there is evidence of over dispersion. What is this evidence? (Select one) Group of answer choices\n\n1368.7/128  \n\n[1] 10.69297\n\n\nThe residual deviance is a lot bigger than the residual degrees of freedom.\nQuestion 4\nFit the same model you fit in question 2, except use the glm.nb function. Using this model fit, what is the expected number of days absent for a male of Aboriginal ethnicity in the F2 age group who is an average learner? (Select one) Group of answer choices\n\nglm.nb(data = df, \n       Days~(Eth + Age + Sex + Lrn)^2) |&gt; summary()\n\n\nCall:\nglm.nb(formula = Days ~ (Eth + Age + Sex + Lrn)^2, data = df, \n    init.theta = 1.60364105, link = log)\n\nCoefficients: (1 not defined because of singularities)\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.00155    0.33709   8.904  &lt; 2e-16 ***\nEthN        -0.24591    0.39135  -0.628  0.52977    \nAgeF1       -0.02546    0.41615  -0.061  0.95121    \nAgeF2       -0.54884    0.54393  -1.009  0.31296    \nAgeF3       -0.25735    0.40558  -0.635  0.52574    \nSexM        -0.77181    0.38021  -2.030  0.04236 *  \nLrnSL        0.38919    0.48421   0.804  0.42153    \nEthN:AgeF1  -0.70000    0.43646  -1.604  0.10876    \nEthN:AgeF2  -1.23283    0.42962  -2.870  0.00411 ** \nEthN:AgeF3   0.04721    0.44883   0.105  0.91622    \nEthN:SexM    0.36240    0.29430   1.231  0.21818    \nEthN:LrnSL   0.06847    0.34040   0.201  0.84059    \nAgeF1:SexM   0.02257    0.47360   0.048  0.96198    \nAgeF2:SexM   1.55330    0.51325   3.026  0.00247 ** \nAgeF3:SexM   1.25227    0.45539   2.750  0.00596 ** \nAgeF1:LrnSL -0.43101    0.47948  -0.899  0.36870    \nAgeF2:LrnSL  0.52074    0.48567   1.072  0.28363    \nAgeF3:LrnSL       NA         NA      NA       NA    \nSexM:LrnSL   0.07187    0.40805   0.176  0.86019    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.6036) family taken to be 1)\n\n    Null deviance: 235.23  on 145  degrees of freedom\nResidual deviance: 167.53  on 128  degrees of freedom\nAIC: 1100.5\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.604 \n          Std. Err.:  0.214 \n\n 2 x log-likelihood:  -1062.546 \n\n\n\na &lt;- 3.00155\n# a is Aborig, female, F0, AL\n# a + Aborig + male + F2 + AL + interactions. \n# d is a     + F2   +  Male    + F2:Male  \nd &lt;- 3.00155 - 0.5488 - 0.77181 + 1.55330 \na*d\n\n[1] 9.707733\n\nexp(d)\n\n[1] 25.38707\n\n\n\n\nC\nQuestion 1\nConsider the deviance goodness-of-fit test. Under what conditions is it valid for Poisson regression? (i.e., when is the Poisson distribution well-approximated by a Normal distribution?)\nWhen all of the Poisson counts are large (at least 5)\nQuestion 2\nConsider the deviance goodness-of-fit test. When it is valid, what possibility is suggested by a small p-value? Group of answer choices\nWe are using the wrong model for λ\nQuestion 3\nConsider the deviance goodness-of-fit test. When it is valid, what possibility is suggested by a large p-value? Group of answer choices\nWe have chosen the correct model for the data.\nQuestion 4\nWhich of the following is the best approach to assess the fit of a Poisson Regression Model? Group of answer choices\nLook at the residuals and examine the deviance goodness of fit test."
  },
  {
    "objectID": "3_Logistic_Regression_I.html",
    "href": "3_Logistic_Regression_I.html",
    "title": "3 Log Reg I",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAfter successful completion of this module, you will be able to:\n\nDescribe the logistic regression model, which includes a probability model for the responses and the model equation.\nWrite a few sentences in non-technical language that explain the results of a logistic regression model fit.\nDescribe how to compare two logistic regression models.\nExplain the need for the link function in logistic regression.\n\nIn R:\n\nFit logistic regression models and interpret the output.\nCreate exploratory plots for logistic regression, and be able to explain any limitations of these plots.\nPrepare and submit an R markdown script.\n\n\n\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 3 Readings and\nLectures\nSubmit Module 3 Homework\nSubmit Module 3 Lab\nTake the Module 3 Content Quiz\nR Quiz\nParticipate in the Module 3 Discussion\n95% Confidence Interval for a standard normal distribution.\n\\[\nCONF.INT = EST \\pm SE*1.96\n\\]\nOtherwise\n\\[\nCONF.INT = EST \\pm t_{\\alpha = .05}\\times SE\n\\]\n\\[\nCritcal \\ Value = t_{\\alpha = .05}\n\\] \\[\nSE = \\frac{sd}{sqrt(n)}\n\\]\nlibrary(tidyverse)"
  },
  {
    "objectID": "3_Logistic_Regression_I.html#task-list",
    "href": "3_Logistic_Regression_I.html#task-list",
    "title": "3 Log Reg I",
    "section": "",
    "text": "In order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 3 Readings and\nLectures\nSubmit Module 3 Homework\nSubmit Module 3 Lab\nTake the Module 3 Content Quiz\nR Quiz\nParticipate in the Module 3 Discussion"
  },
  {
    "objectID": "3_Logistic_Regression_I.html#w-3-lectures",
    "href": "3_Logistic_Regression_I.html#w-3-lectures",
    "title": "3 Log Reg I",
    "section": "W-3 Lectures",
    "text": "W-3 Lectures\n\nIntroduction to Logistic Regression\nDonner party survival by sex and age, interested in sex.\nMLR won’t work, Binary responses are not Normally Distributed.\nMLR was y = B + B1X1 + …\nIn Log-Reg:\ng(u) = B + B1X1 + …\ng(u) is the link function. Some function of the mean of y given the explanatory variables. For normally distributed responses, the link fct is the identity function.\nFor binary responses we use the logit link, g(p) = log(p/(1-p)). The log(odds) of success.\nWe’ll be able to interpret regression coefficient estimates from a logistic regression as changes in the odds of success corresponding to unit increases in an explanatory variable, with other variables held fixed. Or we can transform it back with:\n\\(p = f(\\eta) = \\frac{e^{\\eta}}{1 + e^{\\eta}}\\)\neta is the greek letter\nThe Logistic regression model is:\n\\(logit(p) = \\beta_0 + \\beta_1X_1 + ...\\)\nIt is classed as a general linear model with MLR.\n\n\nModel Interpretation\nLogit is log odd, if we exp(logit) we get odds.\n\\(\\frac{p}{1-p} = exp(\\beta_0 + \\beta_1X_1 + ...)\\)\n\\(\\hat{logit (p)} = 1.63−0.078Age +1.60Female\\)\n\nLRM = glm(Status~Age+Female,data=work,family=binomial(link=\"logit\"))\nsummary(LRM)\n\n\nCall:\nglm(formula = Status ~ Age + Female, family = binomial(link = \"logit\"), \n    data = work)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  1.63312    1.11018   1.471   0.1413  \nAge         -0.07820    0.03728  -2.097   0.0359 *\nFemale       1.59729    0.75547   2.114   0.0345 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 61.827  on 44  degrees of freedom\nResidual deviance: 51.256  on 42  degrees of freedom\nAIC: 57.256\n\nNumber of Fisher Scoring iterations: 4\n\n\nFrom the equation above we can get odds by specifying values for age and sex.\n\nThe estimated odds of survival for a 50 year old female were: \\(exp(1.63−0.078×50+1.60) = 0.52\\)\nthe odds of survival for a 50 year old male were: \\(exp(1.63−0.078×50) = 0.10\\)\n\nThe odds for a women were 5 times that of men.\nThe coefficient for age of men and women is the same in the equation/model, so odds are the same for all ages.\n\n\nEstimation in Logistic Regression\n\nMaximum Likelihood Estimation\nThe Bernoulli Likelihood\nMLE in Logistic Regression\nInference\nFor MLR we use least squares for estimating coefficients.\nFor LogIts we use Maximum Likelihood Estimation\n\nAfter specifying a statistical model for the response, we can write a Liklihood fct.\nSome probability models for response variables—the Normal distribution, the Bernoulli distribution, the Binomial distribution, etc.\n\nFor each of these distributions, and given a sample of data, we can then construct a Likelihood function.\nThe maximum likelihood estimate (MLE), is the estimated value of our parameter(s) that maximize(s) the Likelihood function.\n\n\\prod_{i=1}^{\\infty} a_{i}\n\\(\\prod_{i=1}^{\\infty} a_{i}\\)\nFor n independent Bernoulli (binary) random variables, each with it’s own prob of success p_i:\n\\(P(Y_i = y_i) = p_i^{y_i}(1-p_i)^{1-y_i}\\)\nThe joint probability distribution of Y 1 to n is called the Likelihood Fucntion. It is the product of these n Bernoulli prob dists:\n\\(L(Y) = (Y_1 = y_1, Y_2 = y_2 + ...) = \\prod_{i=1}^{n} p_i^{y_i}(1-p_i)^{1-y_i}\\)\n\\(p_1^{y_1}(1-p_1)^{1-y_1} \\times p_2^{y_2}(1-p_2)^{1-y_2} \\times ...\\)\nfor each pi, we’ll use its connection to the explanatory information using the logistic regression model.\n\nThe Bernoulli Likelihood Funtion.\n\\(L(Y) = \\prod_{i=1}^{n} p_i^{y_i}(1-p_i)^{1-y_i}\\)\nwhere p_i is:\n\\(pi = \\frac{exp(\\beta_0 +\\beta_1Age_i +\\beta_2Female_i)}{1+exp(\\beta_0 +\\beta_1Age_i +\\beta_2Female_i)}\\)\nSo we sub in the expression for p_i into g(u):\n\\[\nL(Y) =  \n\\prod_{i=1}^{n} (\n\\frac{exp(\\beta_0 +\\beta_1Age_i +\\beta_2Female_i)}{1+exp(\\beta_0 +\\beta_1Age_i +\\beta_2Female_i)}\n)^{y_i}(\n\\frac{1}{1+exp(\\beta_0 +\\beta_1Age_i +\\beta_2Female_i)}\n)^{1-y_i}\n\\] This is the expression for the Bernoulli likelihood of the betas.\nThe Maximum Likelihood Estimates (MLE) can, in general, be found by using calculus in this example, the function we’re trying to maximize has three unknowns (the three Betas)\nIn the case of the Logistic Regression Model, expressions for the MLE cannot be written down, but rather the estimates are obtained using an iterative numerical algorithm (an optimization).\nIf our logistic regression model is correct and the sample size is large enough, then:\n\nThe MLE are essentially unbiased.\nThere are known formulae for estimating the standard deviations of the sampling distributions of MLE (these will be different under different models, but they exist).\nThe MLE’s are about as precise (i.e., have roughly the smallest variance) as nearly any other unbiased estimates.\nThe shapes of the sampling distributions of the MLE are approximately Normal.\n\nWe can build approximate confidence intervals and perform approximate hypothesis tests for the logistic regression coefficients.\n\nsummary(LRM)\n\n\nCall:\nglm(formula = Status ~ Age + Female, family = binomial(link = \"logit\"), \n    data = work)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  1.63312    1.11018   1.471   0.1413  \nAge         -0.07820    0.03728  -2.097   0.0359 *\nFemale       1.59729    0.75547   2.114   0.0345 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 61.827  on 44  degrees of freedom\nResidual deviance: 51.256  on 42  degrees of freedom\nAIC: 57.256\n\nNumber of Fisher Scoring iterations: 4\n\n\nStd.Error comes from the MLE procedure, z values can be evaluated against an standard normal dist. P is against standard normal.\n\n\n\nFitting Models\nUse glm and set the family and link appropriately.\nResids are called deviance resids. More later.\nDispersion Parameter: later\nNumber of Fischer scoring iterations: 4 is from the iteration of the Fischer scoring algorithm. Makes sure you reach convergence to the MLE.\nconfint.default gets conf ints for glm object. In this case, the response is log odds, so exp is there to report odds.\n\n# I like to create a \"work\" file for the current data file that\n# I'm using; then I take a quick look at the data and create the \n# Female indicator variable:\n\nwork = case2001   \nhead(work)\n\n\n\n\n\nAge\nSex\nStatus\n\n\n\n\n23\nMale\nDied\n\n\n40\nFemale\nSurvived\n\n\n40\nMale\nSurvived\n\n\n30\nMale\nDied\n\n\n28\nMale\nDied\n\n\n40\nMale\nDied\n\n\n\n\n\nwork$Female = ifelse(work$Sex==\"Female\",1,0)\n\n\n# Now, just a quick plot to look at the data (you'll do this\n# in this module's lab too)\n\nggplot(work,aes(Age,Status,color=Sex)) + geom_point()\n\n\n\n\n\n\n\n# Here's the code to fit a logistic regression model:\n\n# Response ~ explanatory, data = data, family is new. \nLRM = glm(Status~Age+Female,data=work,family=binomial(link=\"logit\"))\nsummary(LRM)\n\n\nCall:\nglm(formula = Status ~ Age + Female, family = binomial(link = \"logit\"), \n    data = work)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  1.63312    1.11018   1.471   0.1413  \nAge         -0.07820    0.03728  -2.097   0.0359 *\nFemale       1.59729    0.75547   2.114   0.0345 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 61.827  on 44  degrees of freedom\nResidual deviance: 51.256  on 42  degrees of freedom\nAIC: 57.256\n\nNumber of Fisher Scoring iterations: 4\n\n# And approximate confidence intervals for the Beta's:\n\ncis = confint.default(LRM)\ncis\n\n                 2.5 %       97.5 %\n(Intercept) -0.5428002  3.809040837\nAge         -0.1512803 -0.005127799\nFemale       0.1166015  3.077985503\n\nexp(cis)\n\n                2.5 %     97.5 %\n(Intercept) 0.5811187 45.1071530\nAge         0.8596067  0.9948853\nFemale      1.1236716 21.7146143\n\n\n\n\nDrop in Deviance\nThe Drop in Deviance Test, analogous to extra sum of squares test in MLR. Drop in Deviance Using R\nUse the drop in dev test to make inference about multiple regression coefficients.\nThis one includes a term for the interaction between Age and Female\nCoefficients:\n                Estimate    Std. Error    z value Pr(&gt;|z|)\n(Intercept)     0.31834     1.13103     0.281     0.7784\nAge             -0.03248    0.03527     -0.921    0.3571\nFemale          6.92805     3.39887     2.038     0.0415\nAge:Female      -0.16160    0.09426     -1.714    0.0865\nThe interaction term has no evidence, it’s different from zero. If we dropped age and interactions?\nwhen you fit multiple linear regression models, you used the Extra sum of squares F test to compare models that differed by more than one explanatory variable. In logistic regression (and generalized linear modeling) we use the drop in deviance test\nThe drop in deviance test aka the likelihood ratio test:\nCompare the max value of the likelihood fct in one model to another.\n\\(LRT = 2log(LMAX_{full} - 2log(LMAX_{reduced}))\\)\nWhen the reduced model is correct (i.e., under the null hypothesis), the LRT follows (approximately) a Chi-squared distribution with degrees of freedom equal to the difference in the number of parameters between the full and reduced models.\nMost computer packages (including R) don’t report the\nLMAX, but instead report a quantity called the deviance:\ndeviance = constant−2log(LMAX).\n\nFortunately, the constant is the same for both the full and reduced models, so that:\n\n\\(LRT = deviance_{reduced} −deviance_{full}\\)\nPass anove two models to do the test.\nFor the models:\n\nlogit(pi) = β0 +β1Agei +β2Femalei +β3Agei : Femalei\nlogit(pi) = β0 +β2Femalei\n\nWhen using the anova function to compare models, the reduced (smaller) model goes first.\n\nmod.full = glm(Status ~ Age*Female, data = work, family = binomial(link = \"logit\"))\nmod.red = glm(Status ~ Female, data = work, family = binomial(link = \"logit\"))\n\nanova(mod.red,mod.full)\n\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n43\n57.28628\nNA\nNA\nNA\n\n\n41\n47.34637\n2\n9.939909\n0.0069435\n\n\n\n\n\n\nCompare that drop in deviance statistic to a Chi-squrare distribution with 2 degrees of freedom\n\n1-pchisq(9.93399,2)\n\n[1] 0.006964044\n\n\np-value = 0.006964044, suggests there’s evidence to reject the reduced model in favor of the full model in this case.\nComparing this output to:\nCoefficients:\n                Estimate    Std. Error    z value Pr(&gt;|z|)\n(Intercept)     0.31834     1.13103     0.281     0.7784\nAge             -0.03248    0.03527     -0.921    0.3571\nFemale          6.92805     3.39887     2.038     0.0415\nAge:Female      -0.16160    0.09426     -1.714    0.0865\nShows that the interaction and age terms\nLooking at the p-value for the int term, there isn’t evidence it’s different from zero, but the anova let’s us see that it is important."
  },
  {
    "objectID": "3_Logistic_Regression_I.html#quizzes",
    "href": "3_Logistic_Regression_I.html#quizzes",
    "title": "3 Log Reg I",
    "section": "Quizzes",
    "text": "Quizzes\n\nR\nAll questions rely on the data in case1902 in the Sleuth3 library—you saw these data in Lab 1. The dataset contains sentencing outcomes (Death/NoDeath) from 362 murder trials in Georgia, as well as the race (Black/White) of the victim and aggravation level of the crime (1,2,…,6; where 6 is the most egregious). Use gather() or pivot_longer() and then expand.dft() to get the case1902 data into tidy (case) format. Feel free to refer to Lab 1\n\nlibrary(Sleuth3)\nlibrary(vcdExtra)\n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\ndata(case1902)\n\n\ndf &lt;- case1902\ndf &lt;- df |&gt; pivot_longer(cols = c(Death, NoDeath), names_to = \"sent\", values_to = \"Freq\")\ndf &lt;- expand.dft(df)\ndf &lt;- df |&gt; mutate(\n  sent = ifelse(sent == \"Death\", 1, 0)\n)\ndf\n\n\n\n\n\nAggravation\nVictim\nsent\n\n\n\n\n1\nWhite\n1\n\n\n1\nWhite\n1\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nBlack\n1\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n2\nWhite\n1\n\n\n2\nWhite\n1\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nBlack\n1\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nBlack\n1\n\n\n3\nBlack\n1\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n0\n\n\n4\nWhite\n0\n\n\n4\nWhite\n0\n\n\n4\nBlack\n1\n\n\n4\nBlack\n1\n\n\n4\nBlack\n0\n\n\n4\nBlack\n0\n\n\n4\nBlack\n0\n\n\n4\nBlack\n0\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n0\n\n\n5\nBlack\n0\n\n\n5\nBlack\n0\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nBlack\n1\n\n\n6\nBlack\n1\n\n\n6\nBlack\n1\n\n\n6\nBlack\n1\n\n\n\n\n\n\nUse the glm() function to fit a logistic regression model that includes additive terms for Aggravation and Victim (e.g., Sentence ~ Aggravation + Victim ). What is the p-value corresponding to the coefficient on Victim?\n0.000732\n\nglm(sent ~ Aggravation + Victim, \n    data = df, \n    family = binomial(link = \"logit\")) |&gt; summary()\n\n\nCall:\nglm(formula = sent ~ Aggravation + Victim, family = binomial(link = \"logit\"), \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -6.6760     0.7574  -8.814  &lt; 2e-16 ***\nAggravation   1.5397     0.1867   8.246  &lt; 2e-16 ***\nVictimWhite   1.8106     0.5361   3.377 0.000732 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 321.88  on 361  degrees of freedom\nResidual deviance: 113.48  on 359  degrees of freedom\nAIC: 119.48\n\nNumber of Fisher Scoring iterations: 7\n\n\nDid the numeric algorithm used to obtain the maximum likelihood estimates of the logistic regression coefficients converge, and if so what evidence do you have for that.\nIt converged, the number of Fisher Scoring iterations is 7.\nWhich of the following statements best describes the odds of a Death sentence when the Victim was white relative to when the victim was black, for two murders at the same aggravation level?\n\nAgg &lt;- 0 \nWhite &lt;- 1\n\n# log(odds) = -6.6760 + 1.5397*Agg + 1.8106*White\nodds1 = exp(-6.6760) + exp(1.8106*White)\nodds1\n\n[1] 6.115376\n\nWhite &lt;- 0\nodds2 = exp(-6.6760) + exp(1.8106*White)\nodds2\n\n[1] 1.001261\n\nodds1/odds2\n\n[1] 6.107675\n\n\nThe odds of a death sentence when the victim was white are estimated to be 6.11 times of the odds of a death sentence when the victim was black.\nIf you first make sure that the response variable, Sentence, is coded as 0 or 1, and then you use the glm() function on the death penalty data, but neglect to pass in the argument, “family=binomial” what happens?\n\ndf\n\n\n\n\n\nAggravation\nVictim\nsent\n\n\n\n\n1\nWhite\n1\n\n\n1\nWhite\n1\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nWhite\n0\n\n\n1\nBlack\n1\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n1\nBlack\n0\n\n\n2\nWhite\n1\n\n\n2\nWhite\n1\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nWhite\n0\n\n\n2\nBlack\n1\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n2\nBlack\n0\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n1\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nWhite\n0\n\n\n3\nBlack\n1\n\n\n3\nBlack\n1\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n3\nBlack\n0\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n1\n\n\n4\nWhite\n0\n\n\n4\nWhite\n0\n\n\n4\nWhite\n0\n\n\n4\nBlack\n1\n\n\n4\nBlack\n1\n\n\n4\nBlack\n0\n\n\n4\nBlack\n0\n\n\n4\nBlack\n0\n\n\n4\nBlack\n0\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nWhite\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n1\n\n\n5\nBlack\n0\n\n\n5\nBlack\n0\n\n\n5\nBlack\n0\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nWhite\n1\n\n\n6\nBlack\n1\n\n\n6\nBlack\n1\n\n\n6\nBlack\n1\n\n\n6\nBlack\n1\n\n\n\n\n\nglm(sent ~ Aggravation + Victim, \n    data = df) |&gt; summary()\n\n\nCall:\nglm(formula = sent ~ Aggravation + Victim, data = df)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.212931   0.019125 -11.134  &lt; 2e-16 ***\nAggravation  0.185380   0.008332  22.249  &lt; 2e-16 ***\nVictimWhite  0.088504   0.026020   3.401 0.000746 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.04985609)\n\n    Null deviance: 49.384  on 361  degrees of freedom\nResidual deviance: 17.898  on 359  degrees of freedom\nAIC: -53.2\n\nNumber of Fisher Scoring iterations: 2\n\n\nA logistic regression model is fit, but it uses Normal (Gaussian) errors.\n\nA multiple linear regression model is fit by default.\n\n\n\nC\nAll four questions on this quiz are related to the situation and output provided here:\nOn January 28, 1986, a routine launch was anticipated for the Challenger space shuttle. Seventy-three seconds into the flight, disaster happened: the shuttle broke apart, killing all seven crew members on board. An investigation into the cause of the disaster focused on a critical seal called an O-ring, and it is believed that damage to O-rings during shuttle launches may have been related to the ambient temperature at the time of the launch. Using data from 24 shuttle missions, we fit a simple logistic regression model. Here, Temperature is the temperature in Fahrenheit at launch time and the response variable, Failure, is an indicator of O-rings failures (Failure = 1 if there was at least O-ring that failed.)\nHere is a summary of the logistic regression model t to these data:\nEstimate    Std. Error  z value Pr(&gt;|z|\n(Intercept) 10.88   5.70    1.91    0.06\nTemperature -0.17   0.08    -2.05   0.04\n\n1.\nGive a 95% confidence interval for the coefficient on Temperature.\nAns c(-17 - 1.96(.08), -17 + 1.96(.08))\n\nc((-.17 - 1.96*(.08)), (-.17 + 1.96*(.08)))\n\n[1] -0.3268 -0.0132\n\n\n\nt &lt;- -.17\nse &lt;- .08 \nz &lt;- 2.05\n\nc(t - se*z, t+se*z)\n\n[1] -0.334 -0.006\n\n\n(-0.33, -0.01)\n\n\n2.\nIn the context of the problem, is this the correct interpretation of the confidence interval you found in question 1, on the log-odds scale. (True or False)\nA one degree increase in temperature is associated with an estimated decrease in the log odds of O-ring failure between 0.0132 and 0.3268 (95% confidence interval for the log-odds of failure).\nANS, TRUE\n\n 0.0132 - 0.3268\n\n[1] -0.3136\n\n\n\n\n3.\nGive a 95% confidence interval for the effect of a one-degree increase in temperature on the odds of O-ring failure.\nANS c(exp(-17 - 1.96(.08)), exp(-17 + 1.96(.08))\n\nc((exp(-.17 - 1.96*(.08))), exp(-.17 + 1.96*(.08)))\n\n[1] 0.7212280 0.9868867\n\n\n\n(10.88 + (5.7*1.91))\n\n[1] 21.767\n\n(10.88 -.17 + (5.7*1.91) + (.08 * -2.05))\n\n[1] 21.433\n\n(10.88 + (5.7*1.91))- (10.88 -.17 + (5.7*1.91) + (.08 * -2.05))\n\n[1] 0.334\n\n\n\n(10.88)\n\n[1] 10.88\n\n(10.88 - .17)\n\n[1] 10.71\n\n(10.88) - (10.88 - .17)\n\n[1] 0.17\n\n\n\nexp(0.0132) \n\n[1] 1.013288\n\nexp(0.3268)\n\n[1] 1.386524\n\n\n\n\n4.\nIn the context of the problem, is this the correct interpretation of the confidence interval you found in question 3. (True or False)\nWe estimate that the odds of O-ring failure decrease between roughly 72% and 99% for each one degree increase in temperature (95% confidence interval for the odds of O-ring failure).\nTRUE\nWe estimate that the odds of O-ring failure decrease between roughly 72% and 99% for each one degree increase in temperature (95% confidence interval for the odds of O-ring failure)."
  },
  {
    "objectID": "1_Types_of_Categoricals.html",
    "href": "1_Types_of_Categoricals.html",
    "title": "1 Types of Categoricals",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "1_Types_of_Categoricals.html#lectures",
    "href": "1_Types_of_Categoricals.html#lectures",
    "title": "1 Types of Categoricals",
    "section": "Lectures",
    "text": "Lectures\n\nAnalyzing categorical and count data.\nCourse priorities:\n\nContingency tables, proportions, risk, odds\nLogistic regression\nLog-linear regression\nOver dispersion in binomial and poisson variables\nMixed effects in the generalized linear model setting\nData imputation—methods for handling missing data.\nPrediction—using generalized linear models to predict new observations.\nScaling up—methods for/issues with performing all of the above on large datasets.\n\nPoisson \\(\\lambda\\) probability of an event happening a certain number of times (k) within a given interval of time or space.\nBinomial (n,p). Prob 0 or 1.\nBernoulli is a Binomial, \\(Pr(Z = z) = p^z(1-p)^{1-z)}\\) for \\(z = 0,1\\) and \\(p \\in [0,1]\\)\nWith a categorical or count random variable, it’s fairly typical that changes in the mean correspond to changes in the variance. MLR and ANOVA are not robust to heteroscedasticity.\nWith categorical data (and some count data), we typically address questions about proportions (or probabilities), risk and odds. With count data, changes in the mean correspond to changes in the variance.\n\n\nTypes of Categorical Data\nBinary Data & More than Two Categories\nExamples\n\nPolls on President’s characteristics\nClinical trial, survival odds\nPotential Credit Fraud\n\nCategorical data takes on discrete values.\nBernoulli = \\(Pr(Z = z) = p^z(1-p)^{1-z)}\\) for \\(z = 0,1\\) and \\(p \\in [0,1]\\)\nFor situations with more than two category, these can be represented by dummy variables in a matrix of zeroes and ones. For each vector in the matrix, where onle one value is 1 and the rest are zero, the probability of p_i (i = 1, 2, 3) = 1 The prob mass fct is \\(Pr(W1 ...) = p_1^{w_1}...\\)\nA binomial random variable is defined as the sum of n independent Bernoulli random variables, all with probability p.  A multinomial random variable is defined as the sum of N independent categorical random variables, all with identical category probabilities, p1,p2,…,pk\n\n\nContingency Tables\nAggregation & Simpson’s Paradox\n\n\nCode\nx &lt;- tribble(\n  ~gender, ~admition, \n  \"male\", \"Accepted\", \n  \"male\", \"Denied\", \n  \"female\", \"Accepted\",\n  \"female\", \"Denied\", \n  \"female\", \"Denied\", \n  \"female\", \"Denied\")\n\ntable(x$gender, x$admition)\n\n\n        \n         Accepted Denied\n  female        1      3\n  male          1      1\n\n\nContingency tables can suggest different things depending on how the data is aggregated."
  },
  {
    "objectID": "1_Types_of_Categoricals.html#lab",
    "href": "1_Types_of_Categoricals.html#lab",
    "title": "1 Types of Categoricals",
    "section": "Lab",
    "text": "Lab\n\nSummary\n\nCase Format == Tidy\nFrequency Format is Case format with an extra col for counts. Every combo gets a count.\nTabular is a table for each variable. In an array.\n\nHere is how to convert between them:\n\n\n\n\n\n\n\n\n\nConvert: Row to column\nCase form\nFrequency form\nTabular form\n\n\n\n\nCase form\nN/A\nas.data.frame(table(X))\ntable(X) or xtabs( ~ V1 + V2 +…+ Vp, X)\n\n\nFrequency form\nexpand.dft(X)\nN/A\nxtabs(Freq ~ V1 + V2 +…+ Vp, X)\n\n\nTabular form\nexpand.dft(X)\nas.data.frame(X)\nN/A\n\n\n\nBasic Functions for One Categorical Variable\n\nfactor creates a factor from a vector.\nlevels** accesses the possible values of a factor.\n\nFunctions for Creating/Transforming Tables\n\ntable creates a table of counts from a factor (or collection of factors).\nxtabs creates a contingency table out of factors in a data frame, using a formula interface.\nftable creates a flat table by adjoining separate slices of a high-dimensional tabular array.\naperm “rotates” a tabular array by permuting its dimensions\nstructable is like ftable() but with more more control of the orientation of the table displayed.\nprop.table turns a table of counts into a table of proportions (with respect to rows, columns, tables, etc.).\nmargin.table collapses a table by aggregating over every level of one (or more) of the factors.\ncollapse.table lumps together some levels of one (or more) factors in a table, reducing “resolution” of that factor.\nco_table makes slices of a table conditional on one or more factors.\nexpand.dft makes a frequency table tidy.\n\nFunctions for Plotting Tabular Data\n\nbarplot creates a (stacked) bar chart from a 1- or 2-dimensional table.\nmosaic creates an area-plot from a table or flat table.\nprod returns the product of all the values present in its arguments.\nexpand.dft: Converts a frequency table, given either as a table object or a data frame in frequency form to a data frame representing individual observations in the table.\nmodel.matrix: creates a design (or model) matrix, e.g., by expanding factors to a set of dummy variables (depending on the contrasts) and expanding interactions similarly.\n\n\nTo tabulate frequency-format data, write the name of the frequency column on the left-hand side of the formula, and the other variables on the right-hand side. For case-format data, leave the left-hand side of the formula empty.\n\n\n# The following are equivalent:\npenalty_tab &lt;- xtabs(~ Sentence + Victim + Aggravation, penalty_case)\npenalty_tab &lt;- xtabs(Freq ~ Sentence + Victim + Aggravation, penalty_freq)\n\n# You can get regular or stacked barcharts for 1 or 2 variables respectively using `barplot()` on a table object: \nbarplot(xtabs(~Sentence + Aggravation, penalty_case))\n\n## Another very useful graphic is the `mosaic` plot, which can take as input either a table, or the `xtabs()` \n# formula that would produce a table.\nmosaic(~ Victim + Sentence, penalty_case)\n\n\n\nLab code\n\n\nCode\nlibrary(gnm)\nlibrary(vcdExtra)\nlibrary(Sleuth3)\nlibrary(tidyverse)\n\n\n\n# Formats ----------------------------------------\n\nX &lt;- data.frame(\n V1 = c('Up', 'Up', 'Down', 'Down', 'Up', 'Up'), \n V2 = c('Left', 'Left', 'Right', 'Right', 'Left', 'Right'),\n V3 = c('B','B','A','B', 'A', 'B'))\nX\n\n# line 150\n\nlibrary(kableExtra)\nX %&gt;% table %&gt;% as.data.frame |&gt;kbl() |&gt; \n kable_styling(bootstrap_options = \"striped\", full_width = F, position = \"left\") \n\nX_tab &lt;- table(X)\n\n\n## Dimensions of the 3-dimensional array that contains the frequencies of the factor-level combinations of the 3 \n# variables in `X`.\n(dims &lt;- dim(X_tab))\n\n# This is why there are 8 rows in the frequency table \nprod(dims)\n\n# 2-D slices of 3-D table\nX_tab\n\n\n# Dataset: Race and the Death Penalty -------------------\n# Line 254\npenalty &lt;- case1902\npenalty\nstr(penalty)\n\n\npenalty_freq &lt;- pivot_longer(\n  data = penalty, \n  cols = c(\"Death\", \"NoDeath\"), \n  names_to = \"Sentence\", \n  values_to = \"Freq\", \n  cols_vary = \"slowest\")\n\npenalty[1,]\n\n\npenalty_freq[c(1,13),]\n\n\npenalty_case &lt;- expand.dft(penalty_freq)\nhead(penalty_case)\n\n\n\npenalty_indicators&lt;- mutate(penalty_case, .keep = \"none\",\n        Aggravation = Aggravation,\n        White = ifelse(Victim == \"White\", 1, 0), \n        Death = ifelse(Sentence == \"Death\", 1, 0))\n# another binary encoding: model.matrix( ~ Sentence + Victim + Aggravation, data = penalty_case)\nhead(penalty_indicators)\n\npenalty_tab &lt;- xtabs(~ Sentence + Victim + Aggravation, penalty_case)\n\n\n\n# Working with Tabular Data ---------------\n# Line 378\n\nxtabs(~ Sentence + Victim + Aggravation, penalty_case) %&gt;% dim\n\nxtabs(~ Sentence + Aggravation + Victim, penalty_case) %&gt;% dim\n\naperm(penalty_tab, perm = c(1, 2, 3)) %&gt;% dim\n# the 2nd and 3rd dimensions switched places -- we've turned the array on its end\naperm(penalty_tab, perm = c(1, 3, 2)) %&gt;% dim \n\n(penalty_given_sentence &lt;- co_table(penalty_tab,'Sentence'))\n\npenalty_given_sentence$Death\n\n# Line 438 ---------------------------------------------------\n\npenalty_tab %&gt;% aperm(c(3, 1, 2)) %&gt;% ftable\n\nftable(Aggravation + Victim ~ Sentence, penalty_case)\n\nstructable(Sentence + Aggravation ~ Victim, penalty_case)\n\npenalty_tab %&gt;% aperm(c(2, 1, 3)) %&gt;% structable(direction = c(\"v\", \"v\", \"h\"))\n\nxtabs(~ Victim + Sentence, penalty_case) # collapse along Aggravation axis\n\nxtabs(~ Sentence, penalty_case) # collapse along Aggravation and Victim axes\n\n## penalty_tab was defined with the formula ~ Sentence + Victim + Aggravation. \n# Sentence and Victim, as the first two variables in the formula, will be retained, while Aggravation will get squashed. \nmargin.table(penalty_tab, margin = c(1,2)) \n\n# Aggravation is the 3rd variable in the formula, so here it will be retained while `Victim` and `Sentence` get squashed.\nmargin.table(penalty_tab, margin = c(3))\n\npenalty_tab %&gt;% collapse.table('Aggravation' = c(rep(\"Low\", 3), c(rep(\"High\", 3))))\n\n# Table of counts\n(sentence_victim_tab &lt;- margin.table(penalty_tab, margin = c(1,2)))\n# Table of proportions\nprop.table(sentence_victim_tab) %&gt;% round(2) # rounding all proportions to 2 decimal points to avoid visual clutter\n\n# Table of column proportions\ncol_prop_tab &lt;- prop.table(sentence_victim_tab, margin = 2)\ncol_prop_tab %&gt;% round(2)\n# Table of column percents\n100 * col_prop_tab %&gt;% round(3)\n\n# Visualizing Categorical Data -------------------------\n# Line 545 \nbarplot(xtabs(~Sentence + Aggravation, penalty_case))\n\nqplot(data = penalty_case, x = Aggravation, fill = Sentence, geom = \"bar\")\n\nmosaic(~ Victim + Sentence, penalty_case)\n\nflat_table &lt;- xtabs(~ Sentence + Victim + Aggravation, penalty_case) %&gt;%\n  prop.table(margin = c(2, 3)) %&gt;% \n  aperm(c(3,2,1)) %&gt;% \n  structable(direction = c(\"v\",\"v\",\"h\"))\n\nflat_table %&gt;% round(2)\n\nmosaic(flat_table)"
  },
  {
    "objectID": "1_Types_of_Categoricals.html#quizzes",
    "href": "1_Types_of_Categoricals.html#quizzes",
    "title": "1 Types of Categoricals",
    "section": "Quizzes",
    "text": "Quizzes\n\nR Quiz\nPackage too old.\nThese data are available in R in the dataset called UCBAdmissions, which contains the data in tabular format as a 2 x 2 x 6 array (Admit x Gender x Dept). From the choices below, select the R command that displays the data in the format given above.\nStill considering the UCBAdmissions dataset, which one of the following R commands will produce two 6 x 2 contingency tables—one for females and one for males?\nConsider the mosaic plot created by the R command mosaic(UCBAdmissions,condvars=“Admit”). Which one of the following best describes the width of the gray bars.\nGood\nftable(UCBAdmissions,row.vars=“Dept”,col.vars=c(“Gender”,“Admit”))\naperm(UCBAdmissions,perm=c(3,1,2))\nThe relative proportions of males and females in the Admitted group (top) and the Rejected group (bottom).\nUCBAmissions\n\nUCBAdmssions &lt;- read_csv(\"../../Data/UCBAdmssions.csv\")\n\nftable(UCBAdmissions,row.vars=\"Dept\",col.vars=c(\"Gender\",\"Admit\"))\n\naperm(UCBAdmissions,perm=c(3,1,2))\nmosaic(UCBAdmissions,condvars=\"Admit\")\n\n\n\nC Quiz\nIn a survey, a sample of college students were asked which political philosophy best describes them - liberal, moderate, or conservative. Given the nature of the responses, what distribution would be the most appropriate to model the data?\nmultinomial.\nIn a survey, college students are asked what percentage of their total weekly spending is on alcoholic beverages. Is the parameter of interest a mean or a proportion? Will the responses be categorical or numerical?\nProportion; categorical.\nProportion; numerical. Changed my answer because of question 4.\nStudents of a statistics course were asked, “Have you ever taken a statistics course before?” Given the nature of the responses, what distribution would be the most appropriate to model the data?\nBinomial\nWhich one of the following questions would elicit a response that is considered to be categorical data?\nDo you believe the expression, “an apple a day keeps the doctor away?”\nIn a sample of recent college graduates, it is found that 85 percent expect to get a job within one year of their graduation date. Is the parameter of interest a mean or a proportion? Will the responses be categorical or numerical?\nProportion; categorical."
  },
  {
    "objectID": "10_Final_Project.html",
    "href": "10_Final_Project.html",
    "title": "10 Final Project",
    "section": "",
    "text": "Ruberic\nThere is no ruberic up yet.\nData Analysis Writing\nFinal Project.pdf\n\n\nInstructions\nChoose a dataset, even a personal one with instructor approval.\n\nCensus income\nForest Cover Type\nCrash Data, 3 from crashi in VGAM\nor one with instructor approval\n\nProgress Report is two questions and a description of the data:\n\n2 Substantive questions\n\nAt least 1 explanatory, to understand variation in a response on the basis of several explanatory variables.\nDescribe the data in your own words\nClear indications of the response variables you will use and the methods you will use to address your questions.\nAt least one and no more than three exploratory data plot relevant to your analysis.\n\n\nFinal Project is a cohesive report that explains:\n\nthe data,\nyour questions,\nyour approach,\nany problems you encounter\nadditional assumptions you have to make\na summary of your findings.\n\nMore info on reports in the week 10 reading, Data Analysis Writing.\n\n\n\n\n\n\nFull Instructions\n\n\n\n\n\nOverview\nFor this project, you must work on your own. You may interact by email with the course TA and/or the course instructor, and you may ask questions on the Project Canvas Discussion, but you may not interact with any of your fellow students outside of the Project Canvas Discussion. You may choose one of the following datasets for your project. You may also use a dataset of your own choosing, but if that’s what you want to do, you must get the instructor’s approval first. Datasets\n\nCensus income: https://archive.ics.uci.edu/ml/datasets/Adult Potential responses: whether or not making more than 50k; whether or not completed college; etc.\nForest cover type: https://archive.ics.uci.edu/ml/datasets/Covertype Potential responses: cover type (combine categories somehow); whether or not it is a wilderness area; etc.\nCrash data: there are eight different data files in the VGAM package in R (after loading the VGAM package, type crashi to learn about them). We looked at the crashi data in Lab 8, but you take any combination of 3 or more of these data files to construct a new dataset and address some interesting questions about crashes. Potential responses: number of crashes involving motorcycles; number of crashes involving alcohol; etc. Deadlines and Deliverables There are two deadlines:\n\n\nDeadline 1: due end of week 9. This is a progress report. This progress report should be in the form of a pdf report that you generated using an R markdown file. The progress report should include the following:\n\n\nA brief description of the data you are using for your project and the questions that you will address—you must address at least two substantive questions about the data you choose. We expect that at least one of the questions you address will be explanatory in nature—that is, you’ll use the data to understand variation in a response on the basis of several explanatory variables. Also, your description of the data should go beyond saying which of the three options above that you chose—you should describe the data in your own words.\nClear indications of (a) the response variable(s) you will use and (b) the methods (e.g., logistic regression) you will use to address your questions of interest.\nAt least one and no more than three exploratory data plot relevant to your analysis.\n\n\nDeadline 2: due end of week 10. This is the completed project report. The deliverable is a pdf report that you created from an R markdown file. It is your responsibility to verify that your code is well-documented and completely self-contained.\n\nPlease note that your report should not be a sequential list of what you did. Rather, it should be a cohesive report that explains the data, your questions, your approach, any problems you encounter or additional assumptions you have to make, and a summary of your findings.\nWe have uploaded a document titled DataAnalysisReports.pdf that provides some guidance about the anatomy of your report.\n\n\n\n\n\n\n\n\n\nData Analysis Writing Summary\n\n\n\n\n\n\nAudience is my supervisor\n\n\nOutline\n\n\nExec. Summary\n\nSummary of study\nAnswer to questions\n\nBody\n\nData\nAnalysis\nResults\n\nDiscussion\n\nReprise the questions and results of the Executive Summary\nNew Questions, Going forward\n\nAppendices\n\nIt’s not a report, it’s a convo between you and your supervisor.\nStatistical Summary Example:\nThere is convincing evidence of a difference in the mean response between two treatment groups, A and B (p &lt; 0.0001 from a Welch’s t-test on 32.4 df). The 95% confidence interval for this difference runs from 1.34 to 3.51 units, with the mean for treatment A being higher than the mean for treatment B.\nStatistically significant as a term in writing:\nUse the p-value to convey strength of evidence, in the sense that a p-value in the range of p &lt; 0.0001 provides convincing evidence against the null hypothesis, where as a p-value around p = 0.05 only provides marginal evidence against the null hypothesis.\nDon’t use “I am 95% confident that…”\n\n\n\n\n\n_____END_______"
  },
  {
    "objectID": "2_Props_Risks_Odds.html",
    "href": "2_Props_Risks_Odds.html",
    "title": "2 Props, Risk & Odds",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAt the end of this week you should be able to:\n\nIdentify potential issues with small sample sizes in tables of counts.\nDescribe the situations in which a comparison of odds ratios is more appropriate than a comparison of proportions.\nIndicate the one-to-one relationship between proportions and odds.\nDescribe the multinomial and Poisson distributions and the connection between them.\n\nIn R:\n\nPerform tests for a difference in proportions and an odds ratio.\nUse simulations to understand the performance of statistical tests for count data when the sample sizes are small.\nPrepare and submit an R markdown script.\n\n\n\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 2 Readings and\nLectures\nSubmit Module 2 Homework\nSubmit Module 2 Lab\nTake the Module 2 Content Quiz and\nR Quiz\nParticipate in the Module 2 Discussion\nlibrary(tidyverse)\nlibrary(Sleuth3)\ndata(case1802)\ndf &lt;- case1802"
  },
  {
    "objectID": "2_Props_Risks_Odds.html#task-list",
    "href": "2_Props_Risks_Odds.html#task-list",
    "title": "2 Props, Risk & Odds",
    "section": "",
    "text": "In order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 2 Readings and\nLectures\nSubmit Module 2 Homework\nSubmit Module 2 Lab\nTake the Module 2 Content Quiz and\nR Quiz\nParticipate in the Module 2 Discussion"
  },
  {
    "objectID": "2_Props_Risks_Odds.html#lab",
    "href": "2_Props_Risks_Odds.html#lab",
    "title": "2 Props, Risk & Odds",
    "section": "Lab",
    "text": "Lab\n\nNotes\nMethods for making inference about the association between two categorical variables in a larger population of interest.\nX and Y, are independent if they are uninformative about one another in terms of the probability of occurrence of specific outcomes.\nIn a cont table, The cell probability for the i,j cell is equal to the marginal probability of the ith row times the marginal probability of the jth column.\nWe say that a contingency table is the most consistent with statistical independence if P_ij = p_i p_j, for all i, j. The extent to which the observed counts in a table deviate from P_ij = p_i p_j for all i, j provides us with evidence against the statistical independence hypothesis.\nUse the mosaic or sieve plot as a tool for evaluating statistical independence visually.\nChi-Squared Statistic\nComparing the observed table to an expected table where we expect them to be independent.\nyou should NOT do this smoothing in practice.\nChi squared test of independence, test of association, or a test of homogeneity.\n“large” means that all cell counts are 5 or larger and the table total is at least 30.\ncontinuity correction is less important with large N.\nFor small sample sizes, re-sample. Our re-sampling technique is closer to the true reference distribution of the Chi-sq statistic than is the distribution when the sample size is small.\nOnce the re-sampling script computes a lot of chi-squared statistics (stored in resamp$stats) for tables drawn under the hypothesis of independence, we see where we stand by plotting the distribution of those re-sampled chi-squared statistics, and comparing it to the theoretical Chi-squared distribution on a plot.\nFisher’s exact test was designed for precisely the situation of the Lady Tasting Tea (statistically, both margins are fixed).\nchisq.test() and fisher.test() only test for independece.\nI am not certain I understand fixed margins.\n\n\nFunctions\n\nsieve draws the outline of the mosaic plot that we would expect to see under the assumption of independence\nmargin.table\nchisq.test\n\n\n\nProp vs \\(\\chi^2\\)\nprop.test can be used for testing the null that the proportions (prob of success) in several groups are the same, or that they equal certain given values.\nTest of equal proportions:\n\n# p_1 = pop proportion\n# n_1 = sample size\n# x_1 = number of successes\n# phat_1 = sample proportions\n# qhat_1 = (1 -  phat_1) the compliment of phat_1\n\n# pooled sample prop, pbar = (x_1 + x_2) / (n_1 + n_2)\n# qbar = compliment of pbar\n\n# z = ( (phat_1 - phat_2) - (p_1 - P_2) ) / sqrt( (pbar*qbar/n_1) + (pbar*qbar/n_2) )\n\n\nviolent &lt;- as.table(\n matrix(c(102, 53, 806, 614),\n     nrow = 2,\n     dimnames = \n      list(vict = c(\"victim\", \"control\"),\n        inCrime= c(\"Yes\", \"No\")\n        )))\nviolent\n\n         inCrime\nvict      Yes  No\n  victim  102 806\n  control  53 614\n\n\n\n# p_1 = pop proportion, unknown\n# n_1 = sample size\nn_1 &lt;-  102 + 806\nn_2 &lt;-  53 + 614\n# x_1 = number of successes\nx_1 &lt;-  102\nx_2 &lt;-  53\n# phat_1 = sample proportions\nphat_1 &lt;-  x_1/n_1\nphat_2 &lt;-  x_2/n_2\n\n# qhat_1 = (1 -  phat_1) the compliment of phat_1\nqh1 &lt;- (1 - phat_1)\nqh2 &lt;- (1 - phat_2)\n# pooled sample prop, pbar = (x_1 + x_2) / (n_1 + n_2)\npbar &lt;- (x_1 + x_2) / (n_1 + n_2)\n# qbar = compliment of pbar\nqbar &lt;- (1-pbar)\n\n# z = ( (phat_1 - phat_2) - (p_1 - P_2) ) / sqrt( (pbar*qbar/n_1) + (pbar*qbar/n_2) ), where (p_1 - P_2 = 0)\nz &lt;- ( (phat_1 - phat_2) - (0) ) / sqrt( ((pbar*qbar)/n_1) + ((pbar*qbar)/n_2) )\nz\n\n[1] 2.164191\n\nnormdist &lt;- rnorm(10000)\n\nggplot() + \n  aes(normdist) + \n  geom_histogram() + \n  geom_vline(xintercept = -qnorm(.975), color = \"red\") + \n  geom_vline(xintercept = qnorm(.975), color = \"red\") + \n  geom_vline(xintercept = -z, color = \"blue\") + \n  geom_vline(xintercept = z, color = \"blue\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\ndnorm(z)\n\n[1] 0.03835767\n\n\n\npnorm(z, lower.tail = F)\n\n[1] 0.01522483\n\n\n\nprop.test(violent)\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  violent\nX-squared = 4.3205, df = 1, p-value = 0.03765\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.002537413 0.063211651\nsample estimates:\n    prop 1     prop 2 \n0.11233480 0.07946027 \n\n\n\nchisq.test(violent)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  violent\nX-squared = 4.3205, df = 1, p-value = 0.03765\n\n\n\nprop.test(violent, correct = F)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  violent\nX-squared = 4.6837, df = 1, p-value = 0.03045\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.003837699 0.061911365\nsample estimates:\n    prop 1     prop 2 \n0.11233480 0.07946027 \n\n\n\nz\n\n[1] 2.164191\n\nsqrt(4.6837)\n\n[1] 2.164186\n\n\nThe the z-test for equal proportions is equivelent to prop.test with the yates correction set to false. From there, prop.test is equal to the chi square test and the z stat is the square root of the chi2 stat.\nchisq.test performs chi-squared contingency table tests and goodness-of-fit tests.\nUse the chi-square test of independence when you have two nominal variables and you want to see whether the proportions of one variable are different for different values of the other variable. Use it when the sample size is large.\nThe null hypothesis is that the relative proportions of one variable are independent of the second variable; in other words, the proportions at one variable are the same for different values of the second variable.\nFisher’s exact test is more accurate than the chi-square test of independence when the expected numbers are small,"
  },
  {
    "objectID": "2_Props_Risks_Odds.html#r",
    "href": "2_Props_Risks_Odds.html#r",
    "title": "2 Props, Risk & Odds",
    "section": "R",
    "text": "R\nWhich of the following returns the 99th percentile (0.99 quantile) of the standard normal distribution?\n\nsqrt(qchisq(0.98, 1))\n\n[1] 2.326348\n\nqnorm(.99)\n\n[1] 2.326348\n\n\nThe p-value that you get from a chi-square test without a continuity correction is:\nThe same as you get from a proportions test without continuity correction.\nThe R command mosaic(matrix(c(30,30,30,30),2,2,byrow=T)) produces a mosaic plot that suggests independence between two variables. Which of the following produces a mosaic plot that suggests the two variables are farthest from independence?\n\nlibrary(vcdExtra)\n\nLoading required package: vcd\n\n\nLoading required package: grid\n\n\nLoading required package: gnm\n\n\n\nAttaching package: 'vcdExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    summarise\n\nmosaic(matrix(c(30,30,30,30),2,2,byrow=T))\n\n\n\n\n\n\n\n# mosaic(matrix(c(40,50,20,10),2,2,byrow=T))\nmosaic(matrix(c(50,30,10,30),2,2,byrow=T))\n\n\n\n\n\n\n\n# mosaic(matrix(c(45,25,25,45),2,2,byrow=T))\n# mosaic(matrix(c(45,25,25,45),2,2,byrow=T))"
  },
  {
    "objectID": "2_Props_Risks_Odds.html#c",
    "href": "2_Props_Risks_Odds.html#c",
    "title": "2 Props, Risk & Odds",
    "section": "C",
    "text": "C\nFor the following questions, refer to the following study:\nIn a 1962 social experiment, 123 3-and 4-year old children from poverty-level families in Ypsilant, Michigan were randomly assigned either to a treatment group receiving 2 years of preschool instruction or to a control group receiving no preschool. The participants were followed into their adult years. The following table shows how many in each group were arrested for some crime by the time they were 19 years old.\nArrested for some crime?\nYes No Preschool 19 42 Control 32 30\nIs it possible to use these data to see whether preschool instruction can cause a lower rate of criminal arrest for some populations? Explain your reasoning.\n\nn1 &lt;- 19+42\n19/n1\n\n[1] 0.3114754\n\n\nArrested for some crime?\nYes No Preschool 19 42 Control 32 30\n\n\n\nWhat is the estimated odds ratio of being arrested for a crime by the age of 19 for the group that didn’t go to preschool versus the group that did go to preschool?\n\npy &lt;- 19\npn &lt;- 42\nn1 &lt;- pn + py\n\ncy &lt;- 32\ncn &lt;- 30\nn2 &lt;- cy + cn\n\nppy &lt;- py/n1\npcy &lt;- cy/n2\n\nopy &lt;- ppy/(1-ppy)\nocy &lt;- pcy/(1-pcy)\n\nopy/ocy\n\n[1] 0.4241071\n\nocy/opy\n\n[1] 2.357895\n\n\n\n\n\nGive a one-sentence interpretation of the estimated odds ratio from the previous question in the context of the problem.\nThe odds of going to jail before 19 were about 2.4 times higher in the control group compared to the preschool group."
  },
  {
    "objectID": "4_Logistic_Regression_II.html",
    "href": "4_Logistic_Regression_II.html",
    "title": "4 Log-Reg II",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAfter successful completion of this module, you will be able to:\n\nDescribe how to examine the goodness of fit of a logistic regression model.\nExplain what an empirical logit is, why it’s useful and how to calculate it.\nDescribe how to compare two logistic regression models.\nDefine over dispersion (or extra-binomial variation), and indicate why it can cause problems for inference in logistic regression.\nList some reasons that counts may exhibit extra-binomial variation.\n\nIn R:\n\nEstimate and interpret the dispersion parameter.\nCreate exploratory plots for logistic regression using the empirical logit.\nUse the deviance residuals to examine goodness of fit of the logistic regression model.\nPrepare and submit an R markdown script.\n\nTask list\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 4 Readings and Lectures\nSubmit Module 4 Homework\nSubmit Module 4 Lab\nTake the Module 4 Content Quiz and\nR Quiz\nParticipate in the Module 4 Discussion\nlibrary(tidyverse)\nlibrary(arm)\nlibrary(Sleuth3)\n# library(tidyverse)\nlibrary(vcdExtra)\nlibrary(magrittr)\n\n\n# library(arm)\nlibrary(datasets)"
  },
  {
    "objectID": "4_Logistic_Regression_II.html#practical-stats",
    "href": "4_Logistic_Regression_II.html#practical-stats",
    "title": "4 Log-Reg II",
    "section": "Practical Stats",
    "text": "Practical Stats\nFor logistic regression, first think of the outcome not as a binary label, but as the probability p that the label is a one.\np is not a linear function of predictors because p will end up outside of zero and one. Instead model p by applying a logistic response or inverse logit fct to ensure the response stays between zero and one.\n\\[\np = \\frac{1}{a + e^{1(\\beta_0 ...)}}\n\\]\nTo get the exponential expression out of the denominator, we consider odds instead of probability. \\[\nOdds = \\frac{prob}{1 - prob}\n\\] \\[\nProb = \\frac{Odds}{1+Odds}\n\\] Combine this with the logistic response fct to get: \\[\nodds(Y=1) = e^{\\beta_0 ...}\n\\]\nThe linear function is:\n\\[\nlog(odds(Y=1)) = \\beta_0 ...\n\\]\nThe log-odds fct, aka the logit fct, maps p from 0 to 1 to and value. Using a cutoff rule, where any value greater than the rule is classified as 1, we can set a rule for certain values always being classified as 1.\nResponse is log odds of a binary outcome of 1.\nA factor with P levels is represented with P-1 columns. In R levels are all compared to the reference level.\nGLMs are characterized by two main components. A probability dist(here binomial) and a link function that maps the response to the predictors(here logit).\nThe poisson is often used for count data like number of times a user visits a website.\nOne advantage or log-regs is that it produces a model that can be scored to new data rapidly, without re-computation. Another is the ease of interpretation via the odds ratio.\nLog-Regs use maximum likelihood estimates. MLE is a process that tries to find the model that is most likely to have made that data we see. It fins the solution such that the estimated log odds best describes the observed outcome. For a set of data [X_n] and probability model P_theta(X_n) with parameters theta. The goal of MOE is to find the set of theta estimates that maximize P, aka the probability of seeing X_n given the model P. It does this using deviance,\n\\[\ndev = -2log(P_{\\hat{\\theta}}(X_1, ... X_n))\n\\] Lower deviance means better fit.\n\nAssessing the model\nAssessment is based generalization error.\nThe p-value for glms should be viewed as a relative indicator of variable importance. There is no RMSE or R-squared. You can train and fit with different models and asses performance. You can use stepwise regression, fit interaction terms or include spline terms. Confounding and cerrelated variables are still issues."
  },
  {
    "objectID": "4_Logistic_Regression_II.html#w-4-lectures",
    "href": "4_Logistic_Regression_II.html#w-4-lectures",
    "title": "4 Log-Reg II",
    "section": "W-4 Lectures",
    "text": "W-4 Lectures\n\nAnother Example in R - More Logistic Regression\n\n\nCode\n#\n# Email dataset: logisitic regression example\n#\n\n#library(devtools)\n#install_github(\"OpenIntroOrg/openintro-r-package\", subdir = \"openintro\")\nlibrary(openintro)\nlibrary(ggplot2)\nlibrary(MASS)\n\n# ?email\nnames(email)\n\n\n [1] \"spam\"         \"to_multiple\"  \"from\"         \"cc\"           \"sent_email\"  \n [6] \"time\"         \"image\"        \"attach\"       \"dollar\"       \"winner\"      \n[11] \"inherit\"      \"viagra\"       \"password\"     \"num_char\"     \"line_breaks\" \n[16] \"format\"       \"re_subj\"      \"exclaim_subj\" \"urgent_subj\"  \"exclaim_mess\"\n[21] \"number\"      \n\n\nCode\nxtabs(~to_multiple+spam,data=email)\n\n\n           spam\nto_multiple    0    1\n          0 2946  355\n          1  608   12\n\n\nCode\nxtabs(~winner+spam,data=email)\n\n\n      spam\nwinner    0    1\n   no  3510  347\n   yes   44   20\n\n\n\n#| code-fold: true\n\nfull1 = glm(\n  spam~to_multiple + from + cc + sent_email + time + image + attach + dollar + \n    winner + inherit + viagra + password + num_char + format + re_subj + exclaim_subj + \n    urgent_subj + exclaim_mess + number,\n  data = email, \n  family=binomial(link=\"logit\"))\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary(full1)\n\n\nCall:\nglm(formula = spam ~ to_multiple + from + cc + sent_email + time + \n    image + attach + dollar + winner + inherit + viagra + password + \n    num_char + format + re_subj + exclaim_subj + urgent_subj + \n    exclaim_mess + number, family = binomial(link = \"logit\"), \n    data = email)\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -8.912e+01  9.709e+03  -0.009  0.99268    \nto_multiple1 -2.614e+00  3.278e-01  -7.975 1.52e-15 ***\nfrom1        -2.215e+01  9.709e+03  -0.002  0.99818    \ncc            1.768e-02  2.244e-02   0.788  0.43070    \nsent_email1  -2.028e+01  4.008e+02  -0.051  0.95965    \ntime          8.365e-08  2.865e-08   2.919  0.00351 ** \nimage        -1.811e+00  5.985e-01  -3.027  0.00247 ** \nattach        7.061e-01  1.455e-01   4.852 1.23e-06 ***\ndollar       -5.955e-02  2.575e-02  -2.312  0.02076 *  \nwinneryes     2.027e+00  3.639e-01   5.571 2.53e-08 ***\ninherit       3.125e-01  1.549e-01   2.017  0.04366 *  \nviagra        2.846e+00  2.216e+03   0.001  0.99898    \npassword     -8.475e-01  2.970e-01  -2.854  0.00432 ** \nnum_char     -4.840e-02  9.540e-03  -5.074 3.90e-07 ***\nformat1      -6.952e-01  1.496e-01  -4.648 3.35e-06 ***\nre_subj1     -1.691e+00  3.859e-01  -4.383 1.17e-05 ***\nexclaim_subj  2.305e-01  2.411e-01   0.956  0.33891    \nurgent_subj1  3.960e+00  1.321e+00   2.999  0.00271 ** \nexclaim_mess  7.754e-03  1.525e-03   5.084 3.69e-07 ***\nnumbersmall  -1.253e+00  1.543e-01  -8.117 4.76e-16 ***\nnumberbig    -3.448e-01  2.185e-01  -1.578  0.11466    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2437.2  on 3920  degrees of freedom\nResidual deviance: 1653.1  on 3900  degrees of freedom\nAIC: 1695.1\n\nNumber of Fisher Scoring iterations: 19\n\n\nThe warning about zero or one is ok, we know probabilities can be zero or one, but check the convergence.\nHere it is 19 which is finite and ok.\nThe variables that are not significant shouldn’t be removed all at the same time.\nMASS has a function to remove variables one at a time with -.\n\n#| code-fold: true\n\nfull2 = update(full1,~.-from-cc-sent_email-viagra-exclaim_subj)\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nsummary(full2)\n\n\nCall:\nglm(formula = spam ~ to_multiple + time + image + attach + dollar + \n    winner + inherit + password + num_char + format + re_subj + \n    urgent_subj + exclaim_mess + number, family = binomial(link = \"logit\"), \n    data = email)\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -9.438e+01  3.650e+01  -2.585 0.009726 ** \nto_multiple1 -2.563e+00  3.138e-01  -8.168 3.13e-16 ***\ntime          7.071e-08  2.746e-08   2.575 0.010017 *  \nimage        -2.100e+00  9.013e-01  -2.330 0.019810 *  \nattach        4.678e-01  9.764e-02   4.791 1.66e-06 ***\ndollar       -5.298e-02  2.459e-02  -2.154 0.031215 *  \nwinneryes     2.144e+00  3.605e-01   5.946 2.75e-09 ***\ninherit       3.434e-01  1.523e-01   2.255 0.024143 *  \npassword     -8.109e-01  3.005e-01  -2.699 0.006956 ** \nnum_char     -3.968e-02  8.925e-03  -4.446 8.77e-06 ***\nformat1      -9.453e-01  1.398e-01  -6.763 1.36e-11 ***\nre_subj1     -3.045e+00  3.835e-01  -7.941 2.01e-15 ***\nurgent_subj1  3.801e+00  1.063e+00   3.577 0.000348 ***\nexclaim_mess  6.614e-03  1.453e-03   4.551 5.34e-06 ***\nnumbersmall  -8.639e-01  1.449e-01  -5.962 2.49e-09 ***\nnumberbig    -2.278e-02  2.087e-01  -0.109 0.913067    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2437.2  on 3920  degrees of freedom\nResidual deviance: 1815.3  on 3905  degrees of freedom\nAIC: 1847.3\n\nNumber of Fisher Scoring iterations: 8\n\n\nWarning is still ok. Convergence was better, it converged in less iterations.\nThe number of significant factors may mean it’s better, but let’s look at the drop in deviance test.\n\n#| code-fold: true\n\nanova(full2, full1)\n\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n3905\n1815.327\nNA\nNA\nNA\n\n\n3900\n1653.086\n5\n162.2409\n0\n\n\n\n\n\n1 - pchisq(162, 5)\n\n[1] 0\n\n\nSmaller first, then full. Deviane 162 and df 5. DF is difference in size between mocels.\n162 in pchisq is zero shows the full model is better.\nPulling by significance wan’t the best idea here.\n\n#| code-fold: true\n\n# fitted values\n\nfits1 = fitted(full1)\nfits2 = predict.glm(full1)\nfits3 = predict.glm(full1,type=\"response\")\n\nhead(cbind(fits1,fits2,fits3))\n\n       fits1     fits2      fits3\n1 0.12002923 -1.992153 0.12002923\n2 0.05467984 -2.850029 0.05467984\n3 0.06900556 -2.602066 0.06900556\n4 0.06797927 -2.618152 0.06797927\n5 0.10455872 -2.147568 0.10455872\n6 0.10519712 -2.140768 0.10519712\n\nfits4 = exp(fits2)/(1 + exp(fits2))\nhead(cbind(fits1,fits2,fits3,fits4))\n\n       fits1     fits2      fits3      fits4\n1 0.12002923 -1.992153 0.12002923 0.12002923\n2 0.05467984 -2.850029 0.05467984 0.05467984\n3 0.06900556 -2.602066 0.06900556 0.06900556\n4 0.06797927 -2.618152 0.06797927 0.06797927\n5 0.10455872 -2.147568 0.10455872 0.10455872\n6 0.10519712 -2.140768 0.10519712 0.10519712\n\n\nFitted values from log reg. Fitted values are the values we get if we apply the observations to the model that we fitted.\nUsing full one, fitted and predict.glm will give fitted values. predict.glm can have type set.\nFits one and fits 2 are the same, but fits 2 is different. Fits one gives the est fits of the log reg model of probabilities. fitted returns on the probability scale. By setting type to response we get the same thing.\npredict.glm will give log(odds).\nFits 4 is a back transformation of log(odds). It is now the same as the other two.\nEnsure you know the scale you are looking at.\n\ndf &lt;- ex2116\n\n\n\nDose Response Relationships\nDose responses are a particular type of log-reg.\nEx: toxic effects of mold. Fish in tanks get dosed. After a year, they count the fish with tumors. 5 doses, 4 tanks at each dose. They graph proportion with tumors by dose for the 5 tanks. It’s on a multiplicative scale, at each step the dose doubles. Log dose is more linear. Responses are binomial counts. Number with tumors out of a number at a dose. We have been talking Bernoulli. Binomial is the sum independent Bernoulli random variables with the same probability of success.\nWith binomial, we can plot emperical logits.\n\\[\nlog(\\frac{x}{n-x})\n\\] We can plot the empirical logit against explanatory info like log(dose).\nFitting the model to the data by log dose, but including a poly function for the curve.\n\n# plot(Tumor, Dose, data = df)\n\n\ndf &lt;- ex2116 |&gt;  mutate(dose = Dose,\n                        tumor = Tumor,\n                        notumor = Total - Tumor,\n                        tankid = factor(1:nrow(df)),\n                        logdose = log(Dose), \n                        emplog = log((Tumor)/(Total  - Tumor)),\n                        ld2 = log(Dose)^2)\n\ndf |&gt; ggplot() + \n  aes(x = logdose, y = emplog) + \n  geom_point()\n\n\n\n\n\n\n\n\n\nmod1 &lt;- glm(data = df, \n            cbind(tumor, notumor) ~ logdose + ld2, \n            family = \"binomial\") \nmod1 |&gt; summary()\n\n\nCall:\nglm(formula = cbind(tumor, notumor) ~ logdose + ld2, family = \"binomial\", \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49343   2.086  0.03699 *  \nlogdose     -1.03048    0.35743  -2.883  0.00394 ** \nld2         -0.39195    0.06136  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: 119.45\n\nNumber of Fisher Scoring iterations: 4\n\n\nBoth the squared term and log odds seam important.\n\n\nDeviance Goodness-of-fit\nA way to evaluate the adequacy of a model.\nBefore interpretation check resids and adequacy.\nIn logistic regression, with binary or Bernoulli, resids aren’t useful because everyting is zero or one. With binomial counts, resids are useful.\nThere is also no need to worry about over-dispersion in binary logistic regression. There is when dealing with binomial responses.\nThere are several types of resids. Two are deviance and Pearson resids. R defaults to Pearson. We use deviance more often. R reports sum of squared deviance resids.\nResids are what is left after we fit a model.\nFor the fish example: 3 models on n binomial counts, the number of counts. 20 binomial counts in the fish set.\n\nlogit(p_i) = beta_0, one param.\nlogit(p_i) = beta_0 + beta_1X_1 + … + beta_pX_k, to 20, k params.\nlogit(p_i) = alpha_i, n params.\n\nThe null deviance corresponds to 1, with one parameter.\nThe residual deviance corresponds to k = 20.\nTo compare with a drop in deviance test, null dev - resid rev in a chi squared with k-1 df, where the null and resid deviances come from fitting the logistic reg model with k - 1 explanatory variables.\nFor the model with k params vs the model with n params. Comparing 2 to 3 asks if 2, a linear structure, is adequate for explaining the variation in the data.\nThe resid deviance from the model with n params is zero. So, the resid dev - 0 = chi square on n-k df.\nThis gives us a way to compare 2 against the model with a different phat for each observation, the saturated model. This is similar to the goodness of fit test.\n\n\nCode\nmod1 |&gt; summary()\n\n\n\nCall:\nglm(formula = cbind(tumor, notumor) ~ logdose + ld2, family = \"binomial\", \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49343   2.086  0.03699 *  \nlogdose     -1.03048    0.35743  -2.883  0.00394 ** \nld2         -0.39195    0.06136  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: 119.45\n\nNumber of Fisher Scoring iterations: 4\n\n\nCompare the residual deviance of 26.048 and find the p-value on a chi-s with 20-3 df. p-value = .07 because of dispersion(extra binomial variation)\n\n\nOver Dispersion\nA binomial Rand Var is the sum of ind Bernoulli RVs each with the same probability.\nIf we summed over RVs with the same probability, but are not statistically independent,\n\nas in the number of Alzeimers cases in an extended family or counting fish with tumors that live in the same tank.\n\nRemember that if X ~ binim(n,p), then mean(X) = np and Var(X) = np(1-p).\np is in both, and a single parameter p is often inadequate to describe both mean and var. This is a problem because the extra variation cannot be modeled with binomial counts.\nWhen extra-binomial variation is present, the standard errors corresponding to logistic regression coefficient estimates are TOO SMALL.\n\nThis means that p-values based on these SE’s are TOO SMALL and confidence intervals build with these SE’s are TOO NARROW.\nThat is, the tests and confidence intervals are not just approximate, they are MISLEADING in this case.\nWhen in doubt, assume extra-binomial variation is present.\n\nIt is best to assume there is extra binomial variation.\nThe Quasi-Likelihood Model:\nWe don’t assume the responses come form a binomial dist. We specify the mean and Var. m_ip_i are the sample mean and sample variation.\nVar = psi(the dispersion parameter)*m_ip_i(1-p_i).\nExtra binimoial variation is one type of over-dispersion. We’re not typically concerned with under-dispersion\nIf psi = 1, it’s binomial.\nTo check for over dispersion:\n\nThink about whether over-dispersion might be likely for this particular response (dependence among binary random variables; unaccounted for explanatory information).\nExamine the deviance goodness-of-fit after fitting a rich model.\nExamine the residuals—over dispersion could just be due to one or two large outliers.\n\nRemember that under the quasi-likelihood parameterization, the variance of a count, Y_i, is assumed to be psi*m_i*p_i(1−p_i), where m_i is the size (denominator) associated with Y_i.\nOne estimate for ψ is: psi = residual deviance / degrees of freedom, where degrees of freedom are n−k. psi is greater than one if there is over-dispersion.\n\n\nMore on Over Dispersion\n\nsummary(mod1)\n\n\nCall:\nglm(formula = cbind(tumor, notumor) ~ logdose + ld2, family = \"binomial\", \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.02921    0.49343   2.086  0.03699 *  \nlogdose     -1.03048    0.35743  -2.883  0.00394 ** \nld2         -0.39195    0.06136  -6.388 1.68e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: 119.45\n\nNumber of Fisher Scoring iterations: 4\n\n\nNote the dispersion parameter is taken to be 1. The dispersion parameter estimate is the Residual deviance/df. So, psi is estimated to be 26.048/17 = 1.53. This suggests over-dispersion, but the dispersion parameter was set to one.\nTo fit the Quasi, pass family = quasibinomial\n\nmod2 &lt;- glm(cbind(tumor, Total-Tumor) ~ logdose + ld2, \n    family = quasibinomial, \n    data = df) \n\nsummary(mod2)\n\n\nCall:\nglm(formula = cbind(tumor, Total - Tumor) ~ logdose + ld2, family = quasibinomial, \n    data = df)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.02921    0.59942   1.717   0.1041    \nlogdose     -1.03048    0.43421  -2.373   0.0297 *  \nld2         -0.39195    0.07454  -5.258 6.41e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasibinomial family taken to be 1.475778)\n\n    Null deviance: 667.195  on 19  degrees of freedom\nResidual deviance:  26.048  on 17  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 4\n\n\nDispersion parameter for quasi.. family taken to be 1.5. The estimates table has the same beta estimates. The std. Errors have gotten larger. The z-value is now a t-value, and the p-values come from the corresponding dists. AIC is not given as before. The dispersion parameter doesn’t match our estimate because R uses the pearson. This can be set in R by passing the type = pearson to the out2 model object. The AIC is a liklihood based metric, here we don’t have a likelihood model, so we don’t get an AIC.\nStd. Errors are multiplied by sqrt(psi), so we have more variation. We can perfom test and build confidence inervals as before using these adjusted std. Errors. We can use the standard normal, but using t is more conservative."
  },
  {
    "objectID": "4_Logistic_Regression_II.html#lab",
    "href": "4_Logistic_Regression_II.html#lab",
    "title": "4 Log-Reg II",
    "section": "Lab",
    "text": "Lab\nRemember the logit transformation of a proportion/probability is given by qlogis():\n\nempirical_logits &lt;- with(tumors, qlogis(Tumor/Total))\n\nThe LR Chisq is the residual deviance, which is the sum of the squared deviance residuals. For instance, for mod5, the residual deviance value of 277 comes can be obtained as\n\nresid(mod5, type = 'deviance') %&gt;% raise_to_power(2) %&gt;% sum\n\nUCBAdmissions come in table format. Lab 1 deals with changing these into something useful."
  },
  {
    "objectID": "4_Logistic_Regression_II.html#hw",
    "href": "4_Logistic_Regression_II.html#hw",
    "title": "4 Log-Reg II",
    "section": "HW",
    "text": "HW\nConfidence intervals for log-regs are:\n\\[\nest \\pm SE*1.96\n\\]\nnot\n\\[\nestA + estB \\pm (SEA*1.96 + SEB*1.96)\n\\]\nThey are the multiplicative confidence intervals.\nDrop in Deviance:\n\nlibrary(tidyverse)\nlibrary(Sleuth3)\nlibrary(magrittr)\nlibrary(arm)\nlibrary(vcdExtra)\nlibrary(datasets)\n\n\nrm(list = ls())\n\nlogistic &lt;- function(x) {(exp(x))/(1 + exp(x))}\ndata(\"case0502\")\ndf &lt;- case0502\n\ndf &lt;- df |&gt; group_by(Judge) |&gt; mutate(\n    venire_id = row_number(),\n    prop = Percent/100, \n    tot = 30, \n    n = 30,\n    female = round(prop*n),\n    male = n - female) |&gt; ungroup()\n\ndf1 &lt;- df |&gt; dplyr::select(Judge, female, tot)\n\ndf |&gt; head(n = 10)\n\n\n\n\n\nPercent\nJudge\nvenire_id\nprop\ntot\nn\nfemale\nmale\n\n\n\n\n6.4\nSpock’s\n1\n0.064\n30\n30\n2\n28\n\n\n8.7\nSpock’s\n2\n0.087\n30\n30\n3\n27\n\n\n13.3\nSpock’s\n3\n0.133\n30\n30\n4\n26\n\n\n13.6\nSpock’s\n4\n0.136\n30\n30\n4\n26\n\n\n15.0\nSpock’s\n5\n0.150\n30\n30\n4\n26\n\n\n15.2\nSpock’s\n6\n0.152\n30\n30\n5\n25\n\n\n17.7\nSpock’s\n7\n0.177\n30\n30\n5\n25\n\n\n18.6\nSpock’s\n8\n0.186\n30\n30\n6\n24\n\n\n23.1\nSpock’s\n9\n0.231\n30\n30\n7\n23\n\n\n16.8\nA\n1\n0.168\n30\n30\n5\n25\n\n\n\n\n\nemplog &lt;- with(df, qlogis((female/n)))\n\n\nm1 &lt;- glm((female/tot)~Judge, \n          weights = tot,\n    data = df1, \n    family = \"binomial\") \n\nm1 |&gt; summary()\n\n\nCall:\nglm(formula = (female/tot) ~ Judge, family = \"binomial\", data = df1, \n    weights = tot)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.66329    0.17236  -3.848 0.000119 ***\nJudgeB        0.01974    0.23305   0.085 0.932484    \nJudgeC       -0.23749    0.21849  -1.087 0.277049    \nJudgeD       -0.34831    0.33902  -1.027 0.304239    \nJudgeE       -0.37691    0.24188  -1.558 0.119171    \nJudgeF       -0.32945    0.22019  -1.496 0.134599    \nJudgeSpock's -1.08591    0.24302  -4.468 7.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.919  on 45  degrees of freedom\nResidual deviance: 31.119  on 39  degrees of freedom\nAIC: 208.53\n\nNumber of Fisher Scoring iterations: 4\n\n\n\ndfmf &lt;- df1 |&gt; mutate(\n  male = tot - female,\n  j = 1\n) \n\ndfmf\n\n\n\n\n\nJudge\nfemale\ntot\nmale\nj\n\n\n\n\nSpock’s\n2\n30\n28\n1\n\n\nSpock’s\n3\n30\n27\n1\n\n\nSpock’s\n4\n30\n26\n1\n\n\nSpock’s\n4\n30\n26\n1\n\n\nSpock’s\n4\n30\n26\n1\n\n\nSpock’s\n5\n30\n25\n1\n\n\nSpock’s\n5\n30\n25\n1\n\n\nSpock’s\n6\n30\n24\n1\n\n\nSpock’s\n7\n30\n23\n1\n\n\nA\n5\n30\n25\n1\n\n\nA\n9\n30\n21\n1\n\n\nA\n10\n30\n20\n1\n\n\nA\n12\n30\n18\n1\n\n\nA\n15\n30\n15\n1\n\n\nB\n8\n30\n22\n1\n\n\nB\n9\n30\n21\n1\n\n\nB\n10\n30\n20\n1\n\n\nB\n10\n30\n20\n1\n\n\nB\n11\n30\n19\n1\n\n\nB\n14\n30\n16\n1\n\n\nC\n6\n30\n24\n1\n\n\nC\n7\n30\n23\n1\n\n\nC\n8\n30\n22\n1\n\n\nC\n8\n30\n22\n1\n\n\nC\n9\n30\n21\n1\n\n\nC\n10\n30\n20\n1\n\n\nC\n10\n30\n20\n1\n\n\nC\n10\n30\n20\n1\n\n\nC\n10\n30\n20\n1\n\n\nD\n7\n30\n23\n1\n\n\nD\n9\n30\n21\n1\n\n\nE\n5\n30\n25\n1\n\n\nE\n6\n30\n24\n1\n\n\nE\n6\n30\n24\n1\n\n\nE\n8\n30\n22\n1\n\n\nE\n10\n30\n20\n1\n\n\nE\n12\n30\n18\n1\n\n\nF\n5\n30\n25\n1\n\n\nF\n6\n30\n24\n1\n\n\nF\n7\n30\n23\n1\n\n\nF\n8\n30\n22\n1\n\n\nF\n8\n30\n22\n1\n\n\nF\n9\n30\n21\n1\n\n\nF\n9\n30\n21\n1\n\n\nF\n10\n30\n20\n1\n\n\nF\n11\n30\n19\n1\n\n\n\n\n\n\n\nt &lt;- dfmf |&gt; \n  mutate(\n    id = row_number()) |&gt; \n  pivot_wider(names_from = Judge, \n                   values_from = j, \n                   id_cols = c(id, female, male, tot),\n                   values_fill = 0) |&gt; rename(S = `Spock's`, f = 'F') |&gt; \n  relocate(S, .after = \"f\")\nt \n\n\n\n\n\nid\nfemale\nmale\ntot\nA\nB\nC\nD\nE\nf\nS\n\n\n\n\n1\n2\n28\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n2\n3\n27\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n3\n4\n26\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n4\n4\n26\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n5\n4\n26\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n6\n5\n25\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n7\n5\n25\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n8\n6\n24\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n9\n7\n23\n30\n0\n0\n0\n0\n0\n0\n1\n\n\n10\n5\n25\n30\n1\n0\n0\n0\n0\n0\n0\n\n\n11\n9\n21\n30\n1\n0\n0\n0\n0\n0\n0\n\n\n12\n10\n20\n30\n1\n0\n0\n0\n0\n0\n0\n\n\n13\n12\n18\n30\n1\n0\n0\n0\n0\n0\n0\n\n\n14\n15\n15\n30\n1\n0\n0\n0\n0\n0\n0\n\n\n15\n8\n22\n30\n0\n1\n0\n0\n0\n0\n0\n\n\n16\n9\n21\n30\n0\n1\n0\n0\n0\n0\n0\n\n\n17\n10\n20\n30\n0\n1\n0\n0\n0\n0\n0\n\n\n18\n10\n20\n30\n0\n1\n0\n0\n0\n0\n0\n\n\n19\n11\n19\n30\n0\n1\n0\n0\n0\n0\n0\n\n\n20\n14\n16\n30\n0\n1\n0\n0\n0\n0\n0\n\n\n21\n6\n24\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n22\n7\n23\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n23\n8\n22\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n24\n8\n22\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n25\n9\n21\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n26\n10\n20\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n27\n10\n20\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n28\n10\n20\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n29\n10\n20\n30\n0\n0\n1\n0\n0\n0\n0\n\n\n30\n7\n23\n30\n0\n0\n0\n1\n0\n0\n0\n\n\n31\n9\n21\n30\n0\n0\n0\n1\n0\n0\n0\n\n\n32\n5\n25\n30\n0\n0\n0\n0\n1\n0\n0\n\n\n33\n6\n24\n30\n0\n0\n0\n0\n1\n0\n0\n\n\n34\n6\n24\n30\n0\n0\n0\n0\n1\n0\n0\n\n\n35\n8\n22\n30\n0\n0\n0\n0\n1\n0\n0\n\n\n36\n10\n20\n30\n0\n0\n0\n0\n1\n0\n0\n\n\n37\n12\n18\n30\n0\n0\n0\n0\n1\n0\n0\n\n\n38\n5\n25\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n39\n6\n24\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n40\n7\n23\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n41\n8\n22\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n42\n8\n22\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n43\n9\n21\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n44\n9\n21\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n45\n10\n20\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n46\n11\n19\n30\n0\n0\n0\n0\n0\n1\n0\n\n\n\n\n\n\n\n# m1 &lt;- glm((female/tot)~Judge, \n#           weights = tot,\n#     data = df1, \n#     family = \"binomial\") \n\n\nm1 &lt;- glm((female/tot)~B+C+D+E+f+S, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \ns1 &lt;- m1 |&gt; summary()\ns1\n\n\nCall:\nglm(formula = (female/tot) ~ B + C + D + E + f + S, family = \"binomial\", \n    data = t, weights = tot)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.66329    0.17236  -3.848 0.000119 ***\nB            0.01974    0.23305   0.085 0.932484    \nC           -0.23749    0.21849  -1.087 0.277049    \nD           -0.34831    0.33902  -1.027 0.304239    \nE           -0.37691    0.24188  -1.558 0.119171    \nf           -0.32945    0.22019  -1.496 0.134599    \nS           -1.08591    0.24302  -4.468 7.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.919  on 45  degrees of freedom\nResidual deviance: 31.119  on 39  degrees of freedom\nAIC: 208.53\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nm2 &lt;- glm((female/tot)~B+C+D+E+f, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \ns2 &lt;- m2 |&gt; summary()\ns1\n\n\nCall:\nglm(formula = (female/tot) ~ B + C + D + E + f + S, family = \"binomial\", \n    data = t, weights = tot)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.66329    0.17236  -3.848 0.000119 ***\nB            0.01974    0.23305   0.085 0.932484    \nC           -0.23749    0.21849  -1.087 0.277049    \nD           -0.34831    0.33902  -1.027 0.304239    \nE           -0.37691    0.24188  -1.558 0.119171    \nf           -0.32945    0.22019  -1.496 0.134599    \nS           -1.08591    0.24302  -4.468 7.88e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.919  on 45  degrees of freedom\nResidual deviance: 31.119  on 39  degrees of freedom\nAIC: 208.53\n\nNumber of Fisher Scoring iterations: 4\n\ns2\n\n\nCall:\nglm(formula = (female/tot) ~ B + C + D + E + f, family = \"binomial\", \n    data = t, weights = tot)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.2852     0.1184 -10.851   &lt;2e-16 ***\nB             0.6416     0.1966   3.265   0.0011 ** \nC             0.3844     0.1790   2.147   0.0318 *  \nD             0.2736     0.3150   0.868   0.3852    \nE             0.2450     0.2069   1.184   0.2365    \nf             0.2925     0.1811   1.615   0.1064    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 62.919  on 45  degrees of freedom\nResidual deviance: 51.319  on 40  degrees of freedom\nAIC: 226.73\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nanova(m2, m1)\n\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n40\n51.31931\nNA\nNA\nNA\n\n\n39\n31.11944\n1\n20.19986\n7e-06\n\n\n\n\n\n\n\npchisq(20.2,1, lower.tail = F)\n\n[1] 6.975294e-06\n\n\n\nDEF\n\nmf &lt;- glm((female/tot)~B+C+D+E+f+S, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \n\nme &lt;- glm((female/tot)~B+C+D+f+S, \n          weights = tot,\n    data = t, \n    family = \"binomial\") \n\nae &lt;- anova(me, mf)\nae$Deviance[2]\n\n[1] 2.433019\n\n\n\npchisq(2.433, 1, lower.tail = F)\n\n[1] 0.1188053\n\n\nFor the drop in deviance test on D, I accept the null hypothesis that the betas a,b,c,d,e,f,s are not equal to betas, a,b,c,e,f,s.\n\nms &lt;-  glm((female/tot)~B+C+D+E+f, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmF &lt;-  glm((female/tot)~B+C+D+E+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\n\nme &lt;-  glm((female/tot)~B+C+D+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\nmd &lt;-  glm((female/tot)~B+C+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmc &lt;-  glm((female/tot)~B+D+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \n\n\nmb &lt;-  glm((female/tot)~C+D+E+f+S, \n            weights = tot,\n            data = t, \n            family = \"binomial\") \nan &lt;- anova(ms,mF, me, md, mc, mb, mf)\nan$\nan$Deviance\n\nNULL\n\n\n\nfor (i in 2:7) {\n  print(paste0(\"*\",an$Deviance[i]))\n  print(pchisq(an$Deviance[i], 1, lower.tail = F))\n}\n\n[1] \"*17.9776859435636\"\n[1] 2.235097e-05\n[1] \"*-0.210840104158429\"\n[1] 1\n[1] \"*1.35069494016167\"\n[1] 0.2451567\n[1] \"*-0.0921905385879072\"\n[1] 1\n[1] \"*1.16733533961862\"\n[1] 0.2799494\n[1] \"*0.00717891306437934\"\n[1] 0.9324773\n\n\n\nmods &lt;- c('ms', 'mF', 'me', 'md', 'mc', 'mb')\nfor (i in 1:6) {\n  print(mods[i])\n  name &lt;- get(mods[i])\n  print(pchisq((anova(name, mf)$Deviance[2]), 1, lower.tail = F))\n}\n\n[1] \"ms\"\n[1] 6.975788e-06\n[1] \"mF\"\n[1] 0.136041\n[1] \"me\"\n[1] 0.1188039\n[1] \"md\"\n[1] 0.2981783\n[1] \"mc\"\n[1] 0.2784756\n[1] \"mb\"\n[1] 0.9324773\n\n# pchisq((anova(ms, mf)$Deviance[2]), 1, lower.tail = F)"
  },
  {
    "objectID": "4_Logistic_Regression_II.html#quizzes",
    "href": "4_Logistic_Regression_II.html#quizzes",
    "title": "4 Log-Reg II",
    "section": "Quizzes",
    "text": "Quizzes\n\nR\nAll questions rely on the data in ex2119 in the Sleuth3 library. The dataset contains information from ten different studies in which investigators examined the relationship between breast feeding and breast cancer in women.\n\nlibrary(Sleuth3)\ndata(ex2119)\ndf &lt;- ex2119\ndf\n\n\n\n\n\nStudy\nLactate\nCancer\nNoCancer\n\n\n\n\n1\nno\n107\n226\n\n\n1\nyes\n352\n865\n\n\n2\nno\n244\n489\n\n\n2\nyes\n574\n1059\n\n\n3\nno\n158\n147\n\n\n3\nyes\n95\n119\n\n\n4\nno\n433\n371\n\n\n4\nyes\n682\n676\n\n\n5\nno\n565\n32693\n\n\n5\nyes\n894\n55735\n\n\n6\nno\n190\n180\n\n\n6\nyes\n262\n272\n\n\n7\nno\n179\n337\n\n\n7\nyes\n612\n1325\n\n\n8\nno\n504\n433\n\n\n8\nyes\n470\n540\n\n\n9\nno\n1957\n1824\n\n\n9\nyes\n1873\n2107\n\n\n10\nno\n1925\n1988\n\n\n10\nyes\n1708\n1802\n\n\n\n\n\n# ?ex2119\n\n\n1\nTake a look at the data first. Which one of the following things can you verify ?\nStudy 5 had substantially more participants than all of the other studies.\n\ndf |&gt; group_by(Study) |&gt; dplyr::summarise(\n  n = n(), \n  sum = sum(Cancer + NoCancer)\n)\n\n\n\n\n\nStudy\nn\nsum\n\n\n\n\n1\n2\n1550\n\n\n2\n2\n2366\n\n\n3\n2\n519\n\n\n4\n2\n2162\n\n\n5\n2\n89887\n\n\n6\n2\n904\n\n\n7\n2\n2453\n\n\n8\n2\n1947\n\n\n9\n2\n7761\n\n\n10\n2\n7423\n\n\n\n\n\n\nStudy 5 had substantially more participants than all of the other studies.\n\n\n2\nRemembering that Study should be coded as a factor variable, fit a binomial logistic regression model to these data that includes Lactate, Study and their interaction. Are there any problems with this model? (choose one).\nYes, the model is overfit—there are no df left to estimate the residual deviance.\n\ndf &lt;- df |&gt; mutate(Study = as.factor(Study), \n                   total = Cancer + NoCancer)\nm1 &lt;- glm(cbind(Cancer,NoCancer)~Lactate*Study, \n          family = \"binomial\", \n          data = df)\ns1 &lt;- summary(m1)\ns1\n\n\nCall:\nglm(formula = cbind(Cancer, NoCancer) ~ Lactate * Study, family = \"binomial\", \n    data = df)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.747706   0.117348  -6.372 1.87e-10 ***\nLactateyes         -0.151392   0.133295  -1.136    0.256    \nStudy2              0.052512   0.141117   0.372    0.710    \nStudy3              0.819869   0.164020   4.999 5.77e-07 ***\nStudy4              0.902242   0.137024   6.585 4.56e-11 ***\nStudy5             -3.310384   0.124784 -26.529  &lt; 2e-16 ***\nStudy6              0.801773   0.156810   5.113 3.17e-07 ***\nStudy7              0.115009   0.149414   0.770    0.441    \nStudy8              0.899545   0.134403   6.693 2.19e-11 ***\nStudy9              0.818087   0.121778   6.718 1.84e-11 ***\nStudy10             0.715503   0.121627   5.883 4.03e-09 ***\nLactateyes:Study2   0.234135   0.163087   1.436    0.151    \nLactateyes:Study3  -0.146017   0.223224  -0.654    0.513    \nLactateyes:Study4   0.005693   0.160368   0.036    0.972    \nLactateyes:Study5   0.076825   0.143891   0.534    0.593    \nLactateyes:Study6   0.059867   0.189946   0.315    0.753    \nLactateyes:Study7   0.011654   0.169441   0.069    0.945    \nLactateyes:Study8  -0.139283   0.161371  -0.863    0.388    \nLactateyes:Study9  -0.036712   0.140838  -0.261    0.794    \nLactateyes:Study10  0.130021   0.141175   0.921    0.357    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3.3218e+04  on 19  degrees of freedom\nResidual deviance: 6.1133e-12  on  0  degrees of freedom\nAIC: 188.72\n\nNumber of Fisher Scoring iterations: 2\n\n\nYes, the model is overfit—there are no df left to estimate the residual deviance.\n\n\n3\nNow fit a model that just includes the main effects of Lactate and Study. Which one of the following do you observe?\nThere is evidence of over dispersion.\n\n1.33 of 4, before was 3.33 of 4. There appears to be something different about Study 7. There is convincing evidence that lactation is associated with breast cancer. There is evidence of over dispersion.\n\n\nm1 &lt;- glm(cbind(Cancer,NoCancer)~Lactate+Study, \n          family = \"binomial\", \n          data = df)\ns1 &lt;- summary(m1)\ns1\n\n\nCall:\nglm(formula = cbind(Cancer, NoCancer) ~ Lactate + Study, family = \"binomial\", \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.78029    0.05846 -13.348  &lt; 2e-16 ***\nLactateyes  -0.10943    0.02303  -4.751 2.02e-06 ***\nStudy2       0.21757    0.07050   3.086  0.00203 ** \nStudy3       0.77526    0.10433   7.431 1.08e-13 ***\nStudy4       0.91200    0.07044  12.947  &lt; 2e-16 ***\nStudy5      -3.25657    0.06172 -52.765  &lt; 2e-16 ***\nStudy6       0.84493    0.08685   9.729  &lt; 2e-16 ***\nStudy7       0.12387    0.07045   1.758  0.07870 .  \nStudy8       0.83808    0.07203  11.635  &lt; 2e-16 ***\nStudy9       0.81036    0.06041  13.414  &lt; 2e-16 ***\nStudy10      0.78969    0.06071  13.008  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 33218.213  on 19  degrees of freedom\nResidual deviance:    16.659  on  9  degrees of freedom\nAIC: 187.38\n\nNumber of Fisher Scoring iterations: 3\n\n\n\n(s1$coefficients) |&gt; exp()\n\n              Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept) 0.45827389   1.060202 1.596752e-06 1.000000\nLactateyes  0.89634755   1.023300 8.642843e-03 1.000002\nStudy2      1.24305103   1.073050 2.188668e+01 1.002032\nStudy3      2.17115800   1.109970 1.686931e+03 1.000000\nStudy4      2.48929063   1.072978 4.197669e+05 1.000000\nStudy5      0.03852023   1.063663 1.214572e-23 1.000000\nStudy6      2.32782062   1.090734 1.678983e+04 1.000000\nStudy7      1.13187027   1.072992 5.802364e+00 1.081882\nStudy8      2.31192890   1.074686 1.130275e+05 1.000000\nStudy9      2.24871035   1.062276 6.689864e+05 1.000000\nStudy10     2.20271574   1.062590 4.458594e+05 1.000000\n\n\n\n16.659/9 \n\n[1] 1.851\n\n\n\nconfint.default(m1) |&gt; exp()\n\n                 2.5 %    97.5 %\n(Intercept) 0.40866218 0.5139085\nLactateyes  0.85678390 0.9377381\nStudy2      1.08261804 1.4272586\nStudy3      1.76963365 2.6637870\nStudy4      2.16829488 2.8578068\nStudy5      0.03413141 0.0434734\nStudy6      1.96345884 2.7597975\nStudy7      0.98589064 1.2994649\nStudy8      2.00753673 2.6624744\nStudy9      1.99760448 2.5313811\nStudy10     1.95561187 2.4810427\n\n\n\n\n4\nFit the same model you fit in question 3, except use family = quasibinomial. Which one of the following do you observe?\nThere is no evidence of a difference between Studies 1 and 7.\n\nm2 &lt;- glm(cbind(Cancer,NoCancer)~Lactate+Study, \n          family = \"quasibinomial\", \n          data = df)\ns2 &lt;- summary(m1)\n\n\ns2\n\n\nCall:\nglm(formula = cbind(Cancer, NoCancer) ~ Lactate + Study, family = \"binomial\", \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.78029    0.05846 -13.348  &lt; 2e-16 ***\nLactateyes  -0.10943    0.02303  -4.751 2.02e-06 ***\nStudy2       0.21757    0.07050   3.086  0.00203 ** \nStudy3       0.77526    0.10433   7.431 1.08e-13 ***\nStudy4       0.91200    0.07044  12.947  &lt; 2e-16 ***\nStudy5      -3.25657    0.06172 -52.765  &lt; 2e-16 ***\nStudy6       0.84493    0.08685   9.729  &lt; 2e-16 ***\nStudy7       0.12387    0.07045   1.758  0.07870 .  \nStudy8       0.83808    0.07203  11.635  &lt; 2e-16 ***\nStudy9       0.81036    0.06041  13.414  &lt; 2e-16 ***\nStudy10      0.78969    0.06071  13.008  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 33218.213  on 19  degrees of freedom\nResidual deviance:    16.659  on  9  degrees of freedom\nAIC: 187.38\n\nNumber of Fisher Scoring iterations: 3\n\ns1\n\n\nCall:\nglm(formula = cbind(Cancer, NoCancer) ~ Lactate + Study, family = \"binomial\", \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.78029    0.05846 -13.348  &lt; 2e-16 ***\nLactateyes  -0.10943    0.02303  -4.751 2.02e-06 ***\nStudy2       0.21757    0.07050   3.086  0.00203 ** \nStudy3       0.77526    0.10433   7.431 1.08e-13 ***\nStudy4       0.91200    0.07044  12.947  &lt; 2e-16 ***\nStudy5      -3.25657    0.06172 -52.765  &lt; 2e-16 ***\nStudy6       0.84493    0.08685   9.729  &lt; 2e-16 ***\nStudy7       0.12387    0.07045   1.758  0.07870 .  \nStudy8       0.83808    0.07203  11.635  &lt; 2e-16 ***\nStudy9       0.81036    0.06041  13.414  &lt; 2e-16 ***\nStudy10      0.78969    0.06071  13.008  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 33218.213  on 19  degrees of freedom\nResidual deviance:    16.659  on  9  degrees of freedom\nAIC: 187.38\n\nNumber of Fisher Scoring iterations: 3\n\n\n\ns2$coefficients |&gt; exp()\n\n              Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept) 0.45827389   1.060202 1.596752e-06 1.000000\nLactateyes  0.89634755   1.023300 8.642843e-03 1.000002\nStudy2      1.24305103   1.073050 2.188668e+01 1.002032\nStudy3      2.17115800   1.109970 1.686931e+03 1.000000\nStudy4      2.48929063   1.072978 4.197669e+05 1.000000\nStudy5      0.03852023   1.063663 1.214572e-23 1.000000\nStudy6      2.32782062   1.090734 1.678983e+04 1.000000\nStudy7      1.13187027   1.072992 5.802364e+00 1.081882\nStudy8      2.31192890   1.074686 1.130275e+05 1.000000\nStudy9      2.24871035   1.062276 6.689864e+05 1.000000\nStudy10     2.20271574   1.062590 4.458594e+05 1.000000\n\ns1$coefficients |&gt; exp()\n\n              Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept) 0.45827389   1.060202 1.596752e-06 1.000000\nLactateyes  0.89634755   1.023300 8.642843e-03 1.000002\nStudy2      1.24305103   1.073050 2.188668e+01 1.002032\nStudy3      2.17115800   1.109970 1.686931e+03 1.000000\nStudy4      2.48929063   1.072978 4.197669e+05 1.000000\nStudy5      0.03852023   1.063663 1.214572e-23 1.000000\nStudy6      2.32782062   1.090734 1.678983e+04 1.000000\nStudy7      1.13187027   1.072992 5.802364e+00 1.081882\nStudy8      2.31192890   1.074686 1.130275e+05 1.000000\nStudy9      2.24871035   1.062276 6.689864e+05 1.000000\nStudy10     2.20271574   1.062590 4.458594e+05 1.000000\n\n\n\n(s2$coefficients) |&gt; exp()\n\n              Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept) 0.45827389   1.060202 1.596752e-06 1.000000\nLactateyes  0.89634755   1.023300 8.642843e-03 1.000002\nStudy2      1.24305103   1.073050 2.188668e+01 1.002032\nStudy3      2.17115800   1.109970 1.686931e+03 1.000000\nStudy4      2.48929063   1.072978 4.197669e+05 1.000000\nStudy5      0.03852023   1.063663 1.214572e-23 1.000000\nStudy6      2.32782062   1.090734 1.678983e+04 1.000000\nStudy7      1.13187027   1.072992 5.802364e+00 1.081882\nStudy8      2.31192890   1.074686 1.130275e+05 1.000000\nStudy9      2.24871035   1.062276 6.689864e+05 1.000000\nStudy10     2.20271574   1.062590 4.458594e+05 1.000000\n\n\n\nconfint.default(m2) |&gt; exp()\n\n                 2.5 %     97.5 %\n(Intercept) 0.39219008 0.53549279\nLactateyes  0.84300776 0.95306231\nStudy2      1.03021013 1.49986475\nStudy3      1.64435119 2.86673984\nStudy4      2.06342727 3.00304641\nStudy5      0.03268062 0.04540332\nStudy6      1.84703948 2.93374825\nStudy7      0.93820068 1.36551841\nStudy8      1.90830697 2.80092003\nStudy9      1.91445165 2.64132982\nStudy10     1.87381693 2.58934401\n\n\n\n\nRedo’s\n2.33 att. 4\nStudy 5 had substantially more participants than all of the other studies.\nYes, the model is overfit—there are no df left to estimate the residual deviance.\nThere appears to be something different about Study 7. There is evidence of over dispersion.\nThere is no evidence of a difference between Studies 1 and 7.\natt. 4, 2.33\nStudy 5 had substantially more participants than all of the other studies.\nYes, the model is overfit—there are no df left to estimate the residual deviance.\nThere is evidence of over dispersion. There is convincing evidence that lactation is associated with breast cancer.\nThere is no evidence of a difference between Studies 1 and 7.\natt. 5, 2.33\nStudy 5 had substantially more participants than all of the other studies.\nYes, the model is overfit—there are no df left to estimate the residual deviance.\nThere is evidence of over dispersion. There appears to be something different about Study 7. There is convincing evidence that lactation is associated with breast cancer.\nThere is no evidence of a difference between Studies 1 and 7.\natt. 7, 4 points.\nStudy 5 had substantially more participants than all of the other studies.\nYes, the model is overfit—there are no df left to estimate the residual deviance.\nThere is evidence of over dispersion.\nThere is no evidence of a difference between Studies 1 and 7. Because we included study in the model, there is no explanation for the over dispersion. The effect of Lactate is different across the different studies\n\n\n\nC\nThe estimates of the coefficients ( ’s) resulting from a quasi-binomial model are identical to those from the binomial likelihood model. Group of answer choices\nTrue\nQuestion 2\nFor each of the following, answer the question, “Is the response a proportion resulting from a count?”\nThe proportion of cells with chromosome aberrations, out of 100 examined. - Yes\nThe proportion of body fat lost after a special diet. - No\nThe proportion out of 10 grams of offered food eaten by a quail. - no\nThe proportion of a mouse’s four limbs that have malformations. - yes\nQuestion 3\nSuppose that Y has a binomial (n, p) distribution. Is the variance of the binomial count Y an increasing or decreasing function of n? Group of answer choices\nIncreasing\n\\[\nvar(Y)= np(1-p)\n\\]\n\nn &lt;- seq(1,10, 1)\np &lt;- .25\nn*p*(1-p)\n\n [1] 0.1875 0.3750 0.5625 0.7500 0.9375 1.1250 1.3125 1.5000 1.6875 1.8750\n\n\nIncreasing."
  },
  {
    "objectID": "6_Dispersion_Zero_Inflation.html",
    "href": "6_Dispersion_Zero_Inflation.html",
    "title": "6 Disp & 0 Inflation",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAfter successful completion of this module, you will be able to:\n\nWrite out the expression of a zero-inflated Poisson regression model, including the response distribution and the model equations.\nDescribe the distinctions between over dispersion and zero-inflation.\nDescribe the distinction between “true zeroes” and “excess zeroes” and provide some examples.\nDescribe the key difference between zero-inflated models and hurdle models.\n\nIn R:\n\nFit ZIP and ZINB regression models, and Poisson and negative binomial hurdle regression models, and make comparisons among these models.\nUse simulations to understand what zero-inflation and over dispersion look like in certain situations.\nPrepare and submit an R markdown script.\n\nTask list\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 6 Readings and Lectures\nSubmit Module 6 Homework\nSubmit Module 6 Lab\nTake the Module 6 Content Quiz and R Quiz\nParticipate in the Module 6 Discussion\nlibrary(tidyverse)"
  },
  {
    "objectID": "6_Dispersion_Zero_Inflation.html#zero-inf-lectures",
    "href": "6_Dispersion_Zero_Inflation.html#zero-inf-lectures",
    "title": "6 Disp & 0 Inflation",
    "section": "6. Zero-Inf Lectures",
    "text": "6. Zero-Inf Lectures\n\n\nCode\n#\n# Fit and compare ZIP and and ZINB models to the Crab data\n# \n\nlibrary(ggplot2)\n#install.packages(\"pscl\")\nlibrary(pscl)     # access the zeroinfl function\nlibrary(MASS)     # access the glm.nb function\nlibrary(glm2)     # access the crab data ***order of accessing these\n                  #         libraries is important for getting the \n                  #         appropriate crabs dataset\n\ndata(crabs, package = \"glm2\")\nwork = crabs\nhead(work)\nggplot(work,aes(Width,Satellites)) + geom_point()\n\n# fit the ZIP model\n\nmod1 = zeroinfl(Satellites~Width+Dark+GoodSpine,dist=\"poisson\",data=work)\nsummary(mod1)\n\n# compare to Poisson model\n\nmod0 = glm(Satellites~Width+Dark+GoodSpine,family=poisson,data=work)\nsummary(mod0)\n\nAIC(mod0,mod1)\n\n# fit the ZINB model\n\nmod2 = zeroinfl(Satellites~Width+Dark+GoodSpine,dist=\"negbin\",data=work)\nsummary(mod2)\n\n# compare to the negative binomial model\n\nmod0 = glm.nb(Satellites~Width+Dark+GoodSpine,data=work)\nsummary(mod0)\n\nAIC(mod0,mod2)\n\nmod3 = hurdle(Satellites~Width+Dark+GoodSpine,dist=\"poisson\",data=work)\nsummary(mod3)\n\nmod4 = hurdle(Satellites~Width+Dark+GoodSpine,dist=\"negbin\",data=work)\nsummary(mod4)\n\nAIC(mod0,mod1,mod2,mod3,mod4)\n\n\n\nZero Inflation\n\nWe must account for over dispersion with the correct model.\nSero inflation is more zeroes than we expect from a poisson or neg.bin. model.\nTrue zeroes are from the same dist as the non-zeroes, female crabs un-attractive, but old enough.\nexcess zeroes are not, female crabs not old enough for mating.\nProb \\(\\pi\\) is probabilty of an excess zero.\nThere can still be over-dispersion in the non-zero counts. Shoppers who buy lots vs average of 1 or 2.\nuse zero inflated nb. ZINB if there is still OD, or ZIP if not.\n\n\n\nZIP & ZINB in R\n\nCrabs example\nWhat characteristics are reltaed to the mean number of satelite males per female crab.\n\\(Y_i \\sim ZIP \\ (\\pi_i, \\lambda_i)\\)\n\\(logit(\\pi_i) = \\beta_0 + ...\\)\n\\(log(\\lambda_i) = \\gamma_0 + ...\\)\n\nIn R:\n\n# Fit and compare ZIP and and ZINB models to the Crab data\n\nlibrary(ggplot2)\n#install.packages(\"pscl\")\nlibrary(pscl)     # access the zeroinfl function\n\nClasses and Methods for R originally developed in the\nPolitical Science Computational Laboratory\nDepartment of Political Science\nStanford University (2002-2015),\nby and under the direction of Simon Jackman.\nhurdle and zeroinfl functions by Achim Zeileis.\n\nlibrary(MASS)     # access the glm.nb function\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(glm2)     # access the crab data ***order of accessing these\n\n\nAttaching package: 'glm2'\n\n\nThe following object is masked from 'package:MASS':\n\n    crabs\n\n                  #         libraries is important for getting the \n                  #         appropriate crabs dataset\n\ndata(crabs, package = \"glm2\")\nwork = crabs\nhead(work)\n\n\n\n\n\nSatellites\nWidth\nDark\nGoodSpine\nRep1\nRep2\n\n\n\n\n8\n28.3\nno\nno\n2\n2\n\n\n0\n22.5\nyes\nno\n4\n5\n\n\n9\n26.0\nno\nyes\n5\n6\n\n\n0\n24.8\nyes\nno\n6\n6\n\n\n4\n26.0\nyes\nno\n6\n8\n\n\n0\n23.8\nno\nno\n8\n8\n\n\n\n\n\nggplot(work,aes(Width,Satellites)) + geom_point()\n\n\n\n\n\n\n\n\n\n# fit the ZIP model\nmod1 = zeroinfl(Satellites~Width+Dark+GoodSpine, \n          dist=\"poisson\",\n          data=work)\n\nsummary(mod1)\n\n\nCall:\nzeroinfl(formula = Satellites ~ Width + Dark + GoodSpine, data = work, \n    dist = \"poisson\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.6800 -0.8315 -0.2883  0.6516  4.4613 \n\nCount model coefficients (poisson with log link):\n             Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   0.64169    0.59881   1.072    0.284\nWidth         0.03075    0.02190   1.404    0.160\nDarkyes      -0.02495    0.10453  -0.239    0.811\nGoodSpineyes  0.12486    0.09928   1.258    0.209\n\nZero-inflation model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   11.0579     2.7783   3.980 6.89e-05 ***\nWidth         -0.4652     0.1062  -4.381 1.18e-05 ***\nDarkyes        0.7658     0.3899   1.964   0.0495 *  \nGoodSpineyes   0.3412     0.4179   0.816   0.4142    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 17 \nLog-likelihood: -361.9 on 8 Df\n\n\n\nBig Pearson resid on Max, something might be wrong. they should look standard normal.\nTwo reports, one for the Poisson rate paramater and one for the zero inflation \\(\\pi s\\).\nWidth and dark are important to there being zeroes, but not for there being male satelites.\nWe could modify the zeroinf call to control the parts that go to each part of the model.\n\n\n# compare to Poisson model\nmod0 = glm(Satellites~Width+Dark+GoodSpine,\n        family=poisson,\n        data=work)\n\nsummary(mod0)\n\n\nCall:\nglm(formula = Satellites ~ Width + Dark + GoodSpine, family = poisson, \n    data = work)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -2.820088   0.570859  -4.940 7.81e-07 ***\nWidth         0.149196   0.020753   7.189 6.52e-13 ***\nDarkyes      -0.265665   0.104972  -2.531   0.0114 *  \nGoodSpineyes -0.002041   0.097990  -0.021   0.9834    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 632.79  on 172  degrees of freedom\nResidual deviance: 560.96  on 169  degrees of freedom\nAIC: 924.25\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nWidth and dark eyes appear important again, but above we saw that they are important for finding zeroes.\n\n\nAIC(mod0,mod1)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nmod0\n4\n924.2548\n\n\nmod1\n8\n739.8864\n\n\n\n\n\n\n\nAIC favors the zip model.\n\n\n# fit the ZINB model\nmod2 = zeroinfl(Satellites~Width+Dark+GoodSpine,dist=\"negbin\",data=work)\nsummary(mod2)\n\n\nCall:\nzeroinfl(formula = Satellites ~ Width + Dark + GoodSpine, data = work, \n    dist = \"negbin\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.3408 -0.7569 -0.2396  0.5506  3.7472 \n\nCount model coefficients (negbin with log link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.40462    0.87317   0.463    0.643    \nWidth         0.03815    0.03184   1.198    0.231    \nDarkyes      -0.01734    0.14733  -0.118    0.906    \nGoodSpineyes  0.13213    0.14197   0.931    0.352    \nLog(theta)    1.58554    0.35147   4.511 6.45e-06 ***\n\nZero-inflation model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   11.4254     3.0153   3.789 0.000151 ***\nWidth         -0.4860     0.1163  -4.180 2.91e-05 ***\nDarkyes        0.8380     0.4260   1.967 0.049130 *  \nGoodSpineyes   0.3864     0.4564   0.846 0.397311    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta = 4.8819 \nNumber of iterations in BFGS optimization: 19 \nLog-likelihood: -350.8 on 9 Df\n\n\n\nAgain, there’s two reports.\nThe log(theta) term accounts for OD in counts. Here it suggests there is OD in addition to the zero-inflation.\n\n\n# compare to the negative binomial model\nmod0 = glm.nb(Satellites~Width+Dark+GoodSpine,data=work)\nsummary(mod0)\n\n\nCall:\nglm.nb(formula = Satellites ~ Width + Dark + GoodSpine, data = work, \n    init.theta = 0.9260423909, link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -3.58218    1.22581  -2.922  0.00347 ** \nWidth         0.17756    0.04521   3.927  8.6e-05 ***\nDarkyes      -0.27798    0.20662  -1.345  0.17852    \nGoodSpineyes  0.02773    0.20725   0.134  0.89355    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.926) family taken to be 1)\n\n    Null deviance: 215.80  on 172  degrees of freedom\nResidual deviance: 196.17  on 169  degrees of freedom\nAIC: 759.21\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.926 \n          Std. Err.:  0.167 \n\n 2 x log-likelihood:  -749.210 \n\n\n\nNB has slightly different report than the zinnb, theta is at the bottom not with the coefficients.\n\n\nAIC(mod0,mod2)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nmod0\n5\n759.2097\n\n\nmod2\n9\n719.5533\n\n\n\n\n\n\n\nAgain AIC shows the zero-indlated model is favored.\n\n\n\nHurdle Models\n\nAll zeroes are assumed to be true zeroes.\nProb of zero is a constant.\nZip and hurdle are likelihood based and can be compared with AIC\npscl::hurdle()\n\n\nmod3 &lt;-  hurdle(Satellites~Width+Dark+GoodSpine,\n            dist=\"poisson\",\n            data=work)\n\nsummary(mod3)\n\n\nCall:\nhurdle(formula = Satellites ~ Width + Dark + GoodSpine, data = work, \n    dist = \"poisson\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.6902 -0.8307 -0.2903  0.6526  4.4756 \n\nCount model coefficients (truncated poisson with log link):\n             Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   0.65727    0.60292   1.090    0.276\nWidth         0.03014    0.02206   1.366    0.172\nDarkyes      -0.02529    0.10487  -0.241    0.809\nGoodSpineyes  0.12623    0.09942   1.270    0.204\nZero hurdle model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -11.0042     2.7142  -4.054 5.03e-05 ***\nWidth          0.4609     0.1035   4.452 8.50e-06 ***\nDarkyes       -0.7473     0.3793  -1.970   0.0488 *  \nGoodSpineyes  -0.3145     0.4077  -0.772   0.4404    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nNumber of iterations in BFGS optimization: 11 \nLog-likelihood: -361.9 on 8 Df\n\n\n\nWhen to use zeroinf or hurdle.\nIf there is a justification for there being excess then ZIP\nIf there’s a difference in the inference, consider the implications on inference.\nAre there excess zeroes and true zeroes or just true zeroes. What’s the reason.\n\n\nmod4 = hurdle(Satellites ~ Width + Dark + GoodSpine, \ndist = \"negbin\",\ndata = work)\n\nsummary(mod4)\n\n\nCall:\nhurdle(formula = Satellites ~ Width + Dark + GoodSpine, data = work, \n    dist = \"negbin\")\n\nPearson residuals:\n    Min      1Q  Median      3Q     Max \n-1.3632 -0.7527 -0.2436  0.5574  3.7123 \n\nCount model coefficients (truncated negbin with log link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.49533    0.89424   0.554    0.580    \nWidth         0.03459    0.03267   1.059    0.290    \nDarkyes      -0.02047    0.14993  -0.137    0.891    \nGoodSpineyes  0.13915    0.14398   0.966    0.334    \nLog(theta)    1.55246    0.35598   4.361 1.29e-05 ***\nZero hurdle model coefficients (binomial with logit link):\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -11.0042     2.7142  -4.054 5.03e-05 ***\nWidth          0.4609     0.1035   4.452 8.50e-06 ***\nDarkyes       -0.7473     0.3793  -1.970   0.0488 *  \nGoodSpineyes  -0.3145     0.4077  -0.772   0.4404    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nTheta: count = 4.7231\nNumber of iterations in BFGS optimization: 19 \nLog-likelihood: -350.5 on 9 Df\n\nAIC(mod0,mod1,mod2,mod3,mod4)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nmod0\n5\n759.2097\n\n\nmod1\n8\n739.8864\n\n\nmod2\n9\n719.5533\n\n\nmod3\n8\n739.8008\n\n\nmod4\n9\n719.0879\n\n\n\n\n\n\n\n\nStrategies\nRecall:\n\nPoisson is count in time or space.\nThe Poisson regression, log-linear model, reads as a log Beta_j increase when others are held fixed.\nAn e^beta_j multiplicative increase.\nOD can be due to unaccounted clustering or any type of unaccounted variable.\nIf we don’t account for the OD, the inference is invalid. the confint is too narrow and the p-value is off.\nUnderdispersion will not be addressed here.\nAssume there is OD and check. dev-gof, psi and resids.\n\nWe’ve covered:\n\nquisiPoisson with glm and family = quasipoisson\nnegative binomial with glm.nb\nZero-inf with zeroinfl function and either dist = poisson or negbin\nhurdle models with hurdle function and poisson or negbin.\n\nZero inflation and overdisperssion\n\nLook at the raw counts.\nAre there lots of large values, lots of zeroes, lots different from zero.\nWhat system created the counts. What makes sense.\n\nFor e^x by x, the poisson prob of y being zero."
  },
  {
    "objectID": "6_Dispersion_Zero_Inflation.html#lab",
    "href": "6_Dispersion_Zero_Inflation.html#lab",
    "title": "6 Disp & 0 Inflation",
    "section": "Lab",
    "text": "Lab"
  },
  {
    "objectID": "6_Dispersion_Zero_Inflation.html#hw",
    "href": "6_Dispersion_Zero_Inflation.html#hw",
    "title": "6 Disp & 0 Inflation",
    "section": "HW",
    "text": "HW"
  },
  {
    "objectID": "6_Dispersion_Zero_Inflation.html#quizzes",
    "href": "6_Dispersion_Zero_Inflation.html#quizzes",
    "title": "6 Disp & 0 Inflation",
    "section": "Quizzes",
    "text": "Quizzes\n\nR\nAll questions rely on the data in the bioChemists dataset in the pscl library. The dataset contains information about the numbers of articles (art) published by each member of a sample of 915 biochemistry graduate students during the final three years of the PhD study. You can look at ?bioChemists to learn about the other variables in the dataset.\n\ndata(bioChemists)\ndf &lt;- bioChemists\n# ?bioChemists\n\n\nhist(df$art)\n\n\n\n\n\n\n\n\nThere is clear evidence of zero-inflation.\n\n# names(df)\nmod.poi &lt;- glm(art~fem+mar+kid5+phd+ment, \n              family = \"poisson\", \n              data = df)\nsummary(mod.poi)\n\n\nCall:\nglm(formula = art ~ fem + mar + kid5 + phd + ment, family = \"poisson\", \n    data = df)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.304617   0.102981   2.958   0.0031 ** \nfemWomen    -0.224594   0.054613  -4.112 3.92e-05 ***\nmarMarried   0.155243   0.061374   2.529   0.0114 *  \nkid5        -0.184883   0.040127  -4.607 4.08e-06 ***\nphd          0.012823   0.026397   0.486   0.6271    \nment         0.025543   0.002006  12.733  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1817.4  on 914  degrees of freedom\nResidual deviance: 1634.4  on 909  degrees of freedom\nAIC: 3314.1\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n1634.4/909 \n\n[1] 1.79802\n\n\nThere is evidence of over dispersion because the residual deviance is a lot bigger than the corresponding degrees of freedom.\n\nmod.nb &lt;- glm.nb(art~fem+mar+kid5+phd+ment,\n              data = df)\nsummary(mod.nb)\n\n\nCall:\nglm.nb(formula = art ~ fem + mar + kid5 + phd + ment, data = df, \n    init.theta = 2.264387695, link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  0.256144   0.137348   1.865 0.062191 .  \nfemWomen    -0.216418   0.072636  -2.979 0.002887 ** \nmarMarried   0.150489   0.082097   1.833 0.066791 .  \nkid5        -0.176415   0.052813  -3.340 0.000837 ***\nphd          0.015271   0.035873   0.426 0.670326    \nment         0.029082   0.003214   9.048  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.2644) family taken to be 1)\n\n    Null deviance: 1109.0  on 914  degrees of freedom\nResidual deviance: 1004.3  on 909  degrees of freedom\nAIC: 3135.9\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.264 \n          Std. Err.:  0.271 \n\n 2 x log-likelihood:  -3121.917 \n\n\nThe over dispersion is confirmed.\nFit a zero-inflated or hurdle negative binomial regression model to check on the potential zero-inflation problem.\nFirst attempt was 3 of 4.\n2nd, changing to Most of the counts are less than 5.\nThat was it.\nQuestion 1\nCreate a histogram of the art counts. Check the one observation you observe.\nThere is clear evidence of zero-inflation.\nMore than half of the counts are zeroes.\nMost of the counts are less than 5.\nQuestion 2\nFit a log linear (Poisson regression) model to the article counts, including all of the explanatory variables in the model. Examine the model summary information and check the best possible observation.\nThe model is a poor fit because the residual deviance is not that much smaller than the null deviance.\nThere is evidence of over dispersion because the largest deviance residual is over 5.\nThere is evidence of over dispersion because the residual deviance is a lot bigger than the corresponding degrees of freedom.\nThere is evidence of zero-inflation because the intercept estimate is statistically significant.\nQuestion 3\nNow use the glm.nb function from the MASS library to fit the negative binomial regression model using the same explanatory information as you used in question 2. Check the one best observation.\nIt seems clear that there’s no zero-inflation.\nThe over dispersion is confirmed.\nThe maximum residual is still larger than 3, we should be concerned about this.\nThe negative binomial model is a better fit because the residual deviance from the negative binomial regression model is so much lower than the residual deviance from the Poisson regression model.\nQuestion 4\nThere may be several things that you could do next to proceed with a data analysis of the bioChemists data? Which one of the following options is best?\nThere’s nothing more to do but summarize the results of the model you fit in question 3.\nPerform a drop in deviance test to see if you can remove phd and mar from the model you fit in question 3.\nFit a zero-inflated or hurdle negative binomial regression model to check on the potential zero-inflation problem.\n\n\nC\nQuestion 11 pts What’s the best way to determine whether a hurdle model or a zero-inflated model is most appropriate in a situation where there are more zeroes than what you should expect from a Poisson distribution? Group of answer choices\nThe models are essentially the same so it doesn’t really matter.\nFit both models and pick the one that gives smaller standard errors.\nThink carefully about the data generating mechanism and determine whether the concept of “true zeroes” or “excess zeroes” is more appropriate.\nUse a drop in deviance test to compare the models.\nFlag question: Question 2 Question 21 pts Which one of the following is true about over dispersion and zero-inflation? Group of answer choices\nOver dispersion results from counts that have more variation than can be accounted for by a Poisson distribution, whereas zero-inflation results from there being more zeroes in a distribution of counts than can be accounted for by a Poisson (or negative binomial) distibution.\nIf there is over dispersion, there is guaranteed to also be zero-inflation.\nIf there is zero-inflation, there is guaranteed to also be over dispersion\nFlag question: Question 3 Question 31 pts Consider the following partial output from the fit of a zero-inflated regression model. Which one of the choices given below the model output can you conclude?\nCount model coefficients (negbin with log link):\nEstimate Std. Error z value Pr (&gt;|z|) (Intercept) 0.63269 0.04723 13.395 &lt; 2e-16  femWomen -0.24720 0.07208 -3.430 0.000605  Log (theta) 0.56589 0.10570 5.354 8.61e-08 ***\nZero-inflation model coefficients (binomial with logit link):\nEstimate Std. Error z value Pr(&gt;|z|) (Intercept) -10.436 85.226 -0.122 0.903 femWomen -2.842 208.220 -0.014 0.989 Group of answer choices\nThere is evidence of over dispersion and zero-inflation.\nThere is not enough information to determine anything about over dispersion or zeroinflation.\n**There is evidence of zero-inflation but no evidence of over *dispersion. Wrong**\nThere is evidence of over dispersion but no evidence of zero-inflation.\nFlag question: Question 4 Question 41 pts True or False? You can use a likelihood ratio test (a drop in deviance test) to compare a Poisson regression model to a negative binomial regression model, provided that they both have the same explanatory information. Group of answer choices\nTrue\nFalse Wrong"
  },
  {
    "objectID": "8_Evaluating_Models.html",
    "href": "8_Evaluating_Models.html",
    "title": "8 Model Eval",
    "section": "",
    "text": "Learning Objectives\n\n\n\n\n\nAt the end of this week you should be able to:\n\nDiscuss issues having to with making predictions of binary outcomes\nDescribe methods for prediction of categorical and count data\nDescribe the statistical concerns to be aware of in the big data setting\n\nIn R:\n\nMake predictions from generalized linear models\nEvaluate different models using cross validation methods\nPrepare and submit an R markdown script.\n\nTask list\nIn order to achieve these learning outcomes, please make sure to complete the following:\n\nReview Module 8 Readings and Lectures\nSubmit Module 8 Homework\nSubmit Module 8 Lab\nTake the Module 8 Content Quiz and R Quiz\nParticipate in the Module 8 Discussion\nlibrary(tidyverse)"
  },
  {
    "objectID": "8_Evaluating_Models.html#lectures",
    "href": "8_Evaluating_Models.html#lectures",
    "title": "8 Model Eval",
    "section": "Lectures",
    "text": "Lectures\n\nBinary Classification\n(Binary Classification.pdf)\n\n\nComparing Predictions\n(Comparing Predictions.pdf)\n\n\nClassifier Example\n(Classifier Example.pdf)\n\n\nClassifier.Rmd\n\n\nCross Validation\n(Cross Validation.pdf)\n\n\nBig Data Issues\n(Big Data Issues.pdf)"
  },
  {
    "objectID": "8_Evaluating_Models.html#lab",
    "href": "8_Evaluating_Models.html#lab",
    "title": "8 Model Eval",
    "section": "Lab",
    "text": "Lab"
  },
  {
    "objectID": "8_Evaluating_Models.html#hw",
    "href": "8_Evaluating_Models.html#hw",
    "title": "8 Model Eval",
    "section": "HW",
    "text": "HW"
  },
  {
    "objectID": "8_Evaluating_Models.html#quizzes",
    "href": "8_Evaluating_Models.html#quizzes",
    "title": "8 Model Eval",
    "section": "Quizzes",
    "text": "Quizzes"
  },
  {
    "objectID": "8_Evaluating_Models.html#quizzes-1",
    "href": "8_Evaluating_Models.html#quizzes-1",
    "title": "8 Model Eval",
    "section": "Quizzes",
    "text": "Quizzes\n\n# Set the number of simulations (and different random seeds)\n# to try. Don't pick a number that is much bigger than 10,000\n# or it will take quite a long time and possibly crash your \n# computer.\n\nnSim &lt;- 1000\n\n# Create an empty vector (just a vector of zeroes) that will\n# be used to store the p-values from each new simulation.\n\npvals &lt;- rep(0, nSim)\n\n# Set the sample size n.\n\nn &lt;- 1000000\n\nfor(i in 1:nSim){\n    # The lines below ('print(i)', etc.) are just to tell us how far \n    # through the nSim iterations we have gotten. This is \n    # slow with a large sample size because of the iterative\n    # nature of the glm solution. \n    \n    if(i %% 20 == 0) print(i)\n    \n    # For the ith simulation, we are using 'i' as the random seed,\n    # so the first simulation will use 1 as the random seed, the second\n    # will use 2, and so on.  We could instead randomly generate new \n    # random seeds, but I wanted to keep this simple and easily\n    # reproducible.  \n            \n    set.seed(i)\n    \n    # Generate the data Y and X as in the quiz question, with\n    # the designated sample size n.\n    \n    Y &lt;- rbinom(n, 1, 0.3)\n    X &lt;- rnorm(n, 0, 1)\n    out &lt;- glm(Y~X, family = binomial) \n    \n    # Store the p-value resulting from the estimated logistic\n    # regression model.  This can be found as the element in row 2,\n    # column 4 of the 'coefficients' object of the summary output.\n    \n    pvals[i] &lt;- summary(out)$coeff[2,4]\n}\n\n# Count how many of the resulting p-values are less than \n# 0.05.  Here we show several ways to do that.  First, we\n# use the 'table' function to tabulate how many of the p-values\n# were &lt;= 0.05, and how many were &gt; 0.05.  A 'TRUE' value means\n# the p-value was &lt;= 0.05, while a 'FALSE' value means the p-value\n# was &gt; 0.05.\n\ntable(pvals &lt;= 0.05)\n\n### Output:\n### -------\n### FALSE  TRUE \n###  952    48 \n\n\n# Another way of counting how many p-values are &lt;= 0.05.  Note that\n# R treats 'TRUE' as a 1 and 'FALSE' as a 0, so when we add up a \n# vector of 'TRUE's and 'FALSE's, we are just counting how many 'TRUE's \n# there were.\n\nsum(pvals &lt;= 0.05)\n\n### Output:\n### -------\n### [1] 48\n\n# Now to calculate the proportion of p-values &lt;= 0.05, we just divide\n# the number that were &lt;= 0.05 by the total number of simulations we \n# did:\n\nsum(pvals &lt;= 0.05)/nSim\n\n### Output:\n### -------\n### [1] 0.048\n\n# Or we could do that in one step using the 'mean' function, since\n# the mean of a vector of 1's and 0's is just the proportion of 1's:\n\nmean(pvals &lt;= 0.05)\n\n### Output:\n### -------\n### [1] 0.048\n\n# Same thing, but for a smaller significance level (0.006 instead of\n# 0.05)\n\ntable(pvals &lt;= 0.006)\n\n### Output:\n### -------\n### FALSE  TRUE \n###  994     6 \n\nmean(pvals &lt;= 0.006)\n\n### Output:\n### -------\n### [1] 0.006\n\n##################################################\n\n# Repeat all of the above, but with n = 50 instead of n = 1000000\n\nnSim &lt;- 1000\npvals &lt;- rep(0, nSim)\nn &lt;- 50\n\nfor(i in 1:nSim){\n    if(i %% 20 == 0) print(i)\n    set.seed(i)\n    Y &lt;- rbinom(n, 1, 0.3)\n    X &lt;- rnorm(n, 0, 1)\n    out &lt;- glm(Y~X, family = binomial) \n    pvals[i] &lt;- summary(out)$coeff[2,4]\n}\n\ntable(pvals &lt;= 0.05)\nmean(pvals &lt;= 0.05)\n\ntable(pvals &lt;= 0.006)\nmean(pvals &lt;= 0.006)\n\n##################################################\n\n# Consider a single example with n = 50:\n\nset.seed(304)\nY &lt;- rbinom(50, 1, 0.3)\nX &lt;- rnorm(50, 0, 1)\nout &lt;- glm(Y~X, family = binomial) \nsummary(out)"
  },
  {
    "objectID": "aHW_1.html",
    "href": "aHW_1.html",
    "title": "ST-518 HW 1",
    "section": "",
    "text": "For each of the following, determine whether the response variable is numerical or categorical. If the response variable is categorical, is it binary? If it is not binary, list possible categories for the response variable.\nThe first one is confusing because it isn’t a response variable. I am going to ignore the “response” part.\n\nIn a survey, college students were asked how many hours per week they spend on the internet.\n\nNumerical or categorical\n\nI’d treat Hours as categorical, They will be estimating not measuring, nominally they spend x hours.\n\nBinary?\n\nNo\n\nList possible categories\n0-4, 4-8, 8-12, … or 1, 2, 3, 4,…\n\nIn a survey, college students were asked, “What percentage of the time that you spend on the internet is not for course work?”\n\nNumerical or categorical\n\nAgain, they aren’t measuring the time, they are estimating. I’d treat it as Categorical.\n\nBinary?\n\nNo\n\nList possible categories\n\n0-10%, 10-20% etc.\n\n\nIn a survey, college students were asked, “What is your primary mode of transportation when traveling between campus and home?”\n\nNumerical or categorical\n\nCategorical\n\nBinary?\n\nNo\n\nList possible categories\n\npersonal vehicle, foot, bike, metro, cab, other.\n\n\nIn a survey, college students were asked whether or not they live on campus.\n\nNumerical or categorical\n\nCatergorical\n\nBinary?\n\nYes\n\nList possible categories\n\nYes or No\n\n\nIn a survey, college students were asked how many of their meals they prepare at home per week.\n\nNumerical or categorical\n\nEither, they could actually count this. How to treat it in a model depends on what you are trying to get.\n\nBinary?\n\nNo\n\nList possible categories\n\n1, 2, 3,… or 1-5, 6-10, …\n\n\nIn a survey, college students were asked, “Which of the five main food groups constitutes the majority of your diet?”\n\nNumerical or categorical\n\nCategorical\n\nBinary?\n\nNo\n\nList possible categories\n\nGrain, Fruit, Veg, Dairy, …\n\n\nIn a survey, smart phone users were asked whether or not they have used a web-based taxi service like Uber or Lyft.\n\nNumerical or categorical\n\nCategorical\n\nBinary?\n\nYes\n\nList possible categories\n\nYes or No\n\n\nIn a survey, smart phone users were asked how many times they used a web-based taxi service in the past three months.\n\nNumerical or categorical\n\nEither, that data could be pulled from the phone. If you wanted to use it quantitatively you could. If it’s an estimate, it’s better as a categorical.\n\nBinary?\n\nNo\n\nList possible categories\n\n0, 1-10, …\n\n\n\n\n\n\n\nOn a multiple-choice exam, each of the 20 questions has 2 possible answers and only one correct response. Suppose, for each question, one student selects his responses completely at random.\nRe-write: On a multiple choice test there are 2 options and 1 correct answer. Bob selects his responses at random (a) For Bob, X’s 1 through 20 represent if he answered correctly. Y is the total number answered correctly What is the distribution of \\(X_i\\)? What is the distribution of \\(Y\\)?\n\nLet \\(X_i,\\ i = 1,...,20\\) represent whether the student answered the \\(i\\)th question correctly, and let \\(Y\\) represent the total number of answers the student gets correct. What is the distribution of \\(X_i\\)? What is the distribution of \\(Y\\)?\n\nThe question boils down to what are the proper distributions for binary data and count data. Bernoulli distributions are for binary data, Binomial for the sum of binary variables.\n\\(Pr(Z = 1) = 0.5^1(1−0.5)^{1−1}\\ = \\ 0.5 \\times 1 \\ = \\ .5\\)\n\\(Pr(X = y) = \\begin{pmatrix} n \\\\ 20 \\end{pmatrix}0.5^{20}(1-0.5)^{n-20}\\)\n\nWhat is the probability that the student passes the test (i.e., scores at least 70%)? (You will learn more about this distribution in the next module, but you should be able to calculate this in R using the pbinom function.)\n\n\\(Pr(X = 14) = \\begin{pmatrix} 14 \\\\ 20 \\end{pmatrix}0.5^{20}(1-0.5)^{14-20}\\)\n\nprint(paste(\"The probability of getting a 70 percent by guessing with 50 50 odds is\",\n            pbinom(q = .7*(20), size = 20, prob = .5, lower.tail = F) |&gt; round(4)))\n\n[1] \"The probability of getting a 70 percent by guessing with 50 50 odds is 0.0207\"\n\n\n\n\nAnswer to Part b) is incorrect. We want \\(P(Y ≥ 14) = 1 - P(Y ≤ 13) = 1 - pbinom(x=13, n=20, p=0.5)=.058\\)\n\n1 - (pbinom(q = 13, size = 20, prob = .5) |&gt; round(4))\n\n[1] 0.0577\n\n# same as\npbinom(q = 13, size = 20, prob = .5, lower.tail = F) |&gt; round(4)\n\n[1] 0.0577\n\n\n\ndf &lt;- NULL\n\nsuccess &lt;- (0:20)/20\nnums &lt;- dbinom(0:20, 20, .5)\ndf &lt;- data.frame(success, nums)\n\ndf |&gt; ggplot() + \n  aes(success, nums) + \n  geom_point() + \n  geom_vline(xintercept = .7)\n\n\n\n\n\n\n\n\nLooking for the area on the right of the line That is\n\n\n\n\n\nDo you prefer taking courses online, on campus, or a hybrid of the two? Suppose these preferences occur with probabilities (\\(p_1, p_2, p_3\\)). For \\(N = 3\\) independent subjects, let the observed frequencies be \\((n_1, n_2, n_3)\\). That is, we observe \\(n_1\\) subjects who prefer taking courses online, etc.\n\nExplain how you can determine \\(n_3\\) from knowing \\(n_1\\) and \\(n_2\\).\nIf there are three people and each gets to pick one preference, then 3 minus the number who prefer online or hybrid is the number left who like campus.\nList all the possible observations \\((n_1, n_2, n_3)\\), with \\(n = 3\\).\n\n\nx &lt;- expand.grid(0:3, 0:3, 0:3)\nx |&gt; mutate(sums = rowSums(x[,1:3])) |&gt; \n  filter(sums == 3) |&gt; \n  select(1:3)\n\n\n\n\n\nVar1\nVar2\nVar3\n\n\n\n\n3\n0\n0\n\n\n2\n1\n0\n\n\n1\n2\n0\n\n\n0\n3\n0\n\n\n2\n0\n1\n\n\n1\n1\n1\n\n\n0\n2\n1\n\n\n1\n0\n2\n\n\n0\n1\n2\n\n\n0\n0\n3"
  },
  {
    "objectID": "aHW_1.html#numerical-or-categorical",
    "href": "aHW_1.html#numerical-or-categorical",
    "title": "ST-518 HW 1",
    "section": "",
    "text": "For each of the following, determine whether the response variable is numerical or categorical. If the response variable is categorical, is it binary? If it is not binary, list possible categories for the response variable.\nThe first one is confusing because it isn’t a response variable. I am going to ignore the “response” part.\n\nIn a survey, college students were asked how many hours per week they spend on the internet.\n\nNumerical or categorical\n\nI’d treat Hours as categorical, They will be estimating not measuring, nominally they spend x hours.\n\nBinary?\n\nNo\n\nList possible categories\n0-4, 4-8, 8-12, … or 1, 2, 3, 4,…\n\nIn a survey, college students were asked, “What percentage of the time that you spend on the internet is not for course work?”\n\nNumerical or categorical\n\nAgain, they aren’t measuring the time, they are estimating. I’d treat it as Categorical.\n\nBinary?\n\nNo\n\nList possible categories\n\n0-10%, 10-20% etc.\n\n\nIn a survey, college students were asked, “What is your primary mode of transportation when traveling between campus and home?”\n\nNumerical or categorical\n\nCategorical\n\nBinary?\n\nNo\n\nList possible categories\n\npersonal vehicle, foot, bike, metro, cab, other.\n\n\nIn a survey, college students were asked whether or not they live on campus.\n\nNumerical or categorical\n\nCatergorical\n\nBinary?\n\nYes\n\nList possible categories\n\nYes or No\n\n\nIn a survey, college students were asked how many of their meals they prepare at home per week.\n\nNumerical or categorical\n\nEither, they could actually count this. How to treat it in a model depends on what you are trying to get.\n\nBinary?\n\nNo\n\nList possible categories\n\n1, 2, 3,… or 1-5, 6-10, …\n\n\nIn a survey, college students were asked, “Which of the five main food groups constitutes the majority of your diet?”\n\nNumerical or categorical\n\nCategorical\n\nBinary?\n\nNo\n\nList possible categories\n\nGrain, Fruit, Veg, Dairy, …\n\n\nIn a survey, smart phone users were asked whether or not they have used a web-based taxi service like Uber or Lyft.\n\nNumerical or categorical\n\nCategorical\n\nBinary?\n\nYes\n\nList possible categories\n\nYes or No\n\n\nIn a survey, smart phone users were asked how many times they used a web-based taxi service in the past three months.\n\nNumerical or categorical\n\nEither, that data could be pulled from the phone. If you wanted to use it quantitatively you could. If it’s an estimate, it’s better as a categorical.\n\nBinary?\n\nNo\n\nList possible categories\n\n0, 1-10, …"
  },
  {
    "objectID": "aHW_1.html#multiple-choice-exam",
    "href": "aHW_1.html#multiple-choice-exam",
    "title": "ST-518 HW 1",
    "section": "",
    "text": "On a multiple-choice exam, each of the 20 questions has 2 possible answers and only one correct response. Suppose, for each question, one student selects his responses completely at random.\nRe-write: On a multiple choice test there are 2 options and 1 correct answer. Bob selects his responses at random (a) For Bob, X’s 1 through 20 represent if he answered correctly. Y is the total number answered correctly What is the distribution of \\(X_i\\)? What is the distribution of \\(Y\\)?\n\nLet \\(X_i,\\ i = 1,...,20\\) represent whether the student answered the \\(i\\)th question correctly, and let \\(Y\\) represent the total number of answers the student gets correct. What is the distribution of \\(X_i\\)? What is the distribution of \\(Y\\)?\n\nThe question boils down to what are the proper distributions for binary data and count data. Bernoulli distributions are for binary data, Binomial for the sum of binary variables.\n\\(Pr(Z = 1) = 0.5^1(1−0.5)^{1−1}\\ = \\ 0.5 \\times 1 \\ = \\ .5\\)\n\\(Pr(X = y) = \\begin{pmatrix} n \\\\ 20 \\end{pmatrix}0.5^{20}(1-0.5)^{n-20}\\)\n\nWhat is the probability that the student passes the test (i.e., scores at least 70%)? (You will learn more about this distribution in the next module, but you should be able to calculate this in R using the pbinom function.)\n\n\\(Pr(X = 14) = \\begin{pmatrix} 14 \\\\ 20 \\end{pmatrix}0.5^{20}(1-0.5)^{14-20}\\)\n\nprint(paste(\"The probability of getting a 70 percent by guessing with 50 50 odds is\",\n            pbinom(q = .7*(20), size = 20, prob = .5, lower.tail = F) |&gt; round(4)))\n\n[1] \"The probability of getting a 70 percent by guessing with 50 50 odds is 0.0207\"\n\n\n\n\nAnswer to Part b) is incorrect. We want \\(P(Y ≥ 14) = 1 - P(Y ≤ 13) = 1 - pbinom(x=13, n=20, p=0.5)=.058\\)\n\n1 - (pbinom(q = 13, size = 20, prob = .5) |&gt; round(4))\n\n[1] 0.0577\n\n# same as\npbinom(q = 13, size = 20, prob = .5, lower.tail = F) |&gt; round(4)\n\n[1] 0.0577\n\n\n\ndf &lt;- NULL\n\nsuccess &lt;- (0:20)/20\nnums &lt;- dbinom(0:20, 20, .5)\ndf &lt;- data.frame(success, nums)\n\ndf |&gt; ggplot() + \n  aes(success, nums) + \n  geom_point() + \n  geom_vline(xintercept = .7)\n\n\n\n\n\n\n\n\nLooking for the area on the right of the line That is"
  },
  {
    "objectID": "aHW_1.html#online-on-campus-or-a-hybrid",
    "href": "aHW_1.html#online-on-campus-or-a-hybrid",
    "title": "ST-518 HW 1",
    "section": "",
    "text": "Do you prefer taking courses online, on campus, or a hybrid of the two? Suppose these preferences occur with probabilities (\\(p_1, p_2, p_3\\)). For \\(N = 3\\) independent subjects, let the observed frequencies be \\((n_1, n_2, n_3)\\). That is, we observe \\(n_1\\) subjects who prefer taking courses online, etc.\n\nExplain how you can determine \\(n_3\\) from knowing \\(n_1\\) and \\(n_2\\).\nIf there are three people and each gets to pick one preference, then 3 minus the number who prefer online or hybrid is the number left who like campus.\nList all the possible observations \\((n_1, n_2, n_3)\\), with \\(n = 3\\).\n\n\nx &lt;- expand.grid(0:3, 0:3, 0:3)\nx |&gt; mutate(sums = rowSums(x[,1:3])) |&gt; \n  filter(sums == 3) |&gt; \n  select(1:3)\n\n\n\n\n\nVar1\nVar2\nVar3\n\n\n\n\n3\n0\n0\n\n\n2\n1\n0\n\n\n1\n2\n0\n\n\n0\n3\n0\n\n\n2\n0\n1\n\n\n1\n1\n1\n\n\n0\n2\n1\n\n\n1\n0\n2\n\n\n0\n1\n2\n\n\n0\n0\n3"
  },
  {
    "objectID": "aHW_1.html#consider-ex2117",
    "href": "aHW_1.html#consider-ex2117",
    "title": "ST-518 HW 1",
    "section": "4. Consider ex2117",
    "text": "4. Consider ex2117\nConsider the data in ex2117 of the Sleuth3 package.\n\nIn what format are these data (case, tabular, frequency, other)? Please explain.\nex2117 is the Effect of Stress During Conception on Odds of a Male Birth.\n\n\nex2117 |&gt; head()\n\n\n\n\n\nGroup\nTime\nNumber\nPctBoys\n\n\n\n\nControl\nnone\n20337\n51.2\n\n\nExposed\n13-16mo\n71\n52.1\n\n\nExposed\n12-7mo\n789\n49.6\n\n\nExposed\n0-6mo\n1922\n48.9\n\n\nExposed\n1st trimester\n290\n46.0\n\n\n\n\n\n\nIt’s pretty much a frequency table. I am not sure if a the two numerical columns change that. If one were to convert the numeric columns to the number of boys alone, that would be an ideal frequency table.\n\nCreate a new R data frame for the data, called HW1data. In that data frame, create a NumBoys column that represents the number of births that were boys (be sure to round to the nearest integer).\n\n\nHW1data &lt;- ex2117 |&gt; mutate(\n  NumBoys = (PctBoys/100)*Number, \n  NumBoys = round(NumBoys)\n)\n\nHW1data \n\n\n\n\n\nGroup\nTime\nNumber\nPctBoys\nNumBoys\n\n\n\n\nControl\nnone\n20337\n51.2\n10413\n\n\nExposed\n13-16mo\n71\n52.1\n37\n\n\nExposed\n12-7mo\n789\n49.6\n391\n\n\nExposed\n0-6mo\n1922\n48.9\n940\n\n\nExposed\n1st trimester\n290\n46.0\n133\n\n\n\n\n\n\n\n\nUse an appropriate R command or commands to change the format to something else (you can pick what).\n\n\nHW1data |&gt; expand.dft(freq = \"NumBoys\") |&gt; head()\n\n\n\n\n\nGroup\nTime\nNumber\nPctBoys\n\n\n\n\nControl\nnone\n20337\n51.2\n\n\nControl\nnone\n20337\n51.2\n\n\nControl\nnone\n20337\n51.2\n\n\nControl\nnone\n20337\n51.2\n\n\nControl\nnone\n20337\n51.2\n\n\nControl\nnone\n20337\n51.2\n\n\n\n\n\ny &lt;- xtabs(NumBoys ~ Group + Time + Number, HW1data)\ny\n\n, , Number = 71\n\n         Time\nGroup     0-6mo 12-7mo 13-16mo 1st trimester  none\n  Control     0      0       0             0     0\n  Exposed     0      0      37             0     0\n\n, , Number = 290\n\n         Time\nGroup     0-6mo 12-7mo 13-16mo 1st trimester  none\n  Control     0      0       0             0     0\n  Exposed     0      0       0           133     0\n\n, , Number = 789\n\n         Time\nGroup     0-6mo 12-7mo 13-16mo 1st trimester  none\n  Control     0      0       0             0     0\n  Exposed     0    391       0             0     0\n\n, , Number = 1922\n\n         Time\nGroup     0-6mo 12-7mo 13-16mo 1st trimester  none\n  Control     0      0       0             0     0\n  Exposed   940      0       0             0     0\n\n, , Number = 20337\n\n         Time\nGroup     0-6mo 12-7mo 13-16mo 1st trimester  none\n  Control     0      0       0             0 10413\n  Exposed     0      0       0             0     0"
  },
  {
    "objectID": "aHW_3.html",
    "href": "aHW_3.html",
    "title": "ST-518 HW 3",
    "section": "",
    "text": "R Question\n\n\n1) GRE, GPA, & Prestige vs Admissions\n(4 points) A researcher is interested in studying how (if?) GRE (Graduate Record Exam scores), GPA (grade point average) and prestige of undergraduate institution are associated with admission into graduate school. The response variable, Admit, is a binary variable (1 == admit). This dataset can be found in admissions.csv available for download right underneath where you downloaded/opened this homework assignment. Treat the variables GRE and GPA as continuous, and treat RANK, which takes values 1 through 4, as a factor variable. A rank of 1 indicates that the student’s undergraduate institution has the highest prestige, while a rank of 4 indicates that it has the lowest prestige.\n\n# Admit = log, gre & gpa = num, rank = factor w 1 = best. \nadmissions &lt;- read_csv(\"../../Data/admissions.csv\", \n                       col_types = \"innf\")\nad &lt;- admissions |&gt; mutate(\n  rank = factor(rank, levels = c(1, 2,3,4)) #, levels = c(4,3,2,1))\n)\n# str(admissions)\nstr(ad)\n\ntibble [400 × 4] (S3: tbl_df/tbl/data.frame)\n $ admit: int [1:400] 0 1 1 1 0 1 1 0 1 0 ...\n $ gre  : num [1:400] 380 660 800 640 520 760 560 400 540 700 ...\n $ gpa  : num [1:400] 3.61 3.67 4 3.19 2.93 ...\n $ rank : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 3 3 1 4 4 2 1 2 3 2 ...\n\n\n\na Fit models\n\nFit a logistic regression model to these data, with the variable admit as the response and gpa, gre, and rank as explanatory variables. Fit another model without gre. Comment on how these models are different.\n\n\nmod_full &lt;- glm(admit ~ gpa + gre + rank,\n            family = binomial(link = \"logit\"),\n            data = ad)\n\nmod_red &lt;- glm(admit ~ gpa + rank,\n            family = binomial(link = \"logit\"),\n            data = ad)\n\ns_red &lt;- summary(mod_red)\n\ns_full &lt;- summary(mod_full)\n\ns_red\n\n\nCall:\nglm(formula = admit ~ gpa + rank, family = binomial(link = \"logit\"), \n    data = ad)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -3.4636     1.1003  -3.148 0.001645 ** \ngpa           1.0521     0.3102   3.392 0.000694 ***\nrank2        -0.6810     0.3141  -2.168 0.030181 *  \nrank3        -1.3919     0.3419  -4.071 4.68e-05 ***\nrank4        -1.5943     0.4152  -3.840 0.000123 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 499.98  on 399  degrees of freedom\nResidual deviance: 462.88  on 395  degrees of freedom\nAIC: 472.88\n\nNumber of Fisher Scoring iterations: 4\n\ns_full\n\n\nCall:\nglm(formula = admit ~ gpa + gre + rank, family = binomial(link = \"logit\"), \n    data = ad)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.989979   1.139951  -3.500 0.000465 ***\ngpa          0.804038   0.331819   2.423 0.015388 *  \ngre          0.002264   0.001094   2.070 0.038465 *  \nrank2       -0.675443   0.316490  -2.134 0.032829 *  \nrank3       -1.340204   0.345306  -3.881 0.000104 ***\nrank4       -1.551464   0.417832  -3.713 0.000205 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 499.98  on 399  degrees of freedom\nResidual deviance: 458.52  on 394  degrees of freedom\nAIC: 470.52\n\nNumber of Fisher Scoring iterations: 4\n\n# Smaller mod first. \nanova(mod_red, mod_full)\n\n\n\n\n\nResid. Df\nResid. Dev\nDf\nDeviance\nPr(&gt;Chi)\n\n\n\n\n395\n462.8752\nNA\nNA\nNA\n\n\n394\n458.5175\n1\n4.357759\n0.0368407\n\n\n\n\n\n\n\ns_red$coefficients |&gt; exp()\n\n              Estimate Std. Error     z value Pr(&gt;|z|)\n(Intercept) 0.03131623   3.005111  0.04294460 1.001646\ngpa         2.86352334   1.363657 29.72120143 1.000694\nrank2       0.50612454   1.369087  0.11443972 1.030641\nrank3       0.24860056   1.407620  0.01705876 1.000047\nrank4       0.20306061   1.514682  0.02150075 1.000123\n\n# s_red$coefficients[1:5] |&gt; exp()\ns_full$coefficients |&gt; exp()\n\n             Estimate Std. Error     z value Pr(&gt;|z|)\n(Intercept) 0.0185001   3.126615  0.03019338 1.000465\ngpa         2.2345451   1.393501 11.28099028 1.015507\ngre         1.0022670   1.001095  7.92374081 1.039214\nrank2       0.5089309   1.372302  0.11834270 1.033374\nrank3       0.2617923   1.412423  0.02062602 1.000104\nrank4       0.2119375   1.518665  0.02440100 1.000205\n\n\nThe reduced model doesn’t have GRE, the reduced model’s intercept is higher, gpa estimate is higher, and ranks are lower.\nGPA, GRE, and all Ranks are significant in the full model, the same for the reduced except it doesn’t have GRE.\nDrop in deviance is 4.3578. Indicating the full model may be better (p-val = 0.0368, drop in deviance test, df = 1).\n\n# 1 - pchisq(4.3578, 1) #lower.tail = F\npchisq(4.3578, 1, lower.tail = F)\n\n[1] 0.03683985\n\n\n\n\nb. Scatter plot\n\nProduce a scatter plot of admit against GPA and overlay 4 separate fitted lines, one for each rank, from the regression with gpa and rank as explanatory variables.\n\n\nlogistic &lt;- function(x){exp(x)/(1 + exp(x))}\n\n# Obtain 95% pointnwise confidence bands from predict.glm()\nglm_pred &lt;- predict.glm(mod_red, type=\"link\", se.fit=TRUE)\nlow &lt;- glm_pred$fit - 1.96 * glm_pred$se.fit\nupp &lt;- glm_pred$fit + 1.96 * glm_pred$se.fit\n\n# back-transform everything to the data scale\nglm_fit &lt;- logistic(glm_pred$fit)\nglm_lower &lt;- logistic(low)\nglm_upper &lt;- logistic(upp)\n\n# augment the Donner data frame\naugment_df &lt;- as.data.frame(cbind(ad, glm_fit, glm_lower, glm_upper))\n\n\naugment_df |&gt;  ggplot() + \n  aes(y = admit, x = gpa, color = rank) +\n  geom_point() + \n  \n  geom_line(aes(x = gpa, \n        y = glm_fit, \n         color = rank)) + \n  \n  geom_ribbon(\n    aes(x = gpa, \n        fill = rank, \n        ymin = glm_lower, \n        ymax = glm_upper), \n    alpha = .2\n  ) + \n  \n  scale_fill_brewer(palette =\"Dark2\") +\n  scale_color_brewer(palette =\"Dark2\")+\n  facet_grid(\n      cols = vars(rank)\n      ) \n\n\n\n\n\n\n\n\n\n\nc. Summary\n\nWrite a short paragraph discussing your findings\n\nIt looks like the prestige of one’s undergraduate institution has an effect on admissions to grad school. With a 4.0 GPA, someone from a prestigious school has between 53% & 80% probability of getting admitted. Whereas someone with the same gpa from a low ranked school has between 17% & 47% probability of getting admitted.\n\n# augment_df |&gt; filter(rank == 1 & gpa == 4.0)\n# augment_df |&gt; filter(rank == 4 & gpa == 4.0)\n\n\n\n\nConceptual Questions\n\n\n2. Donner\n(3 points) In 1846, the Donner and Reed families left Springfield, Illinois, for California by covered wagon. Along the way, more families and individuals joined the Donner Party, as it came to be known, until it reached its full size of 87 people. The group become stranded in the eastern Sierra Nevada mountains when the region was hit by heavy snows in late October. By the time the last survivor was rescued in April 1847, 40 of the 87 members had died from famine and exposure to extreme cold.\n\na. independence\n\nOne assumption underlying the correct use of logistic regression is that observations are independent of each other. Is there some basis for thinking this assumption might be violated in the Donner Party data?\n\nThere may be some violations of this assumption. The party was composed of families and groups that traveled together. Those groups are not independent. Families will share similar genetics. Their health may be affected as a group by their diets before the incident. Groups that travel together would share a similar effect.\n\ndonner = case2001 \n# donner |&gt; head()\n\n\n\nb. The over 50’s\n\nWhy should one be reluctant to draw conclusions about the ratio of male and female odds of survival for Donner Party members over 50? (Hint: Look again the graph of the Donner Party data from lecture, where status is plotted against age.)\n\nThere are fewer observations in the over 50 crowd, especially among the female group. This makes inference outside the bounds of the data precarious.\n\n\nc. Survival is 50%\n\nIn this week’s lecture, it was found that the estimated logistic regression equation is:\n\n\\(\\hat{logit(p)} = 1.63 − 0.078Age + 1.60Female\\), where Female is an indicator variable equal to one for females and zero for males.\n\nWhat is the age at which the estimated probability of survival is 50% for women? What about for men?\n\n\nf &lt;- 1\n# logOdds = 1.63 - 0.078*a + 1.60*f\nagef = (1.63 + 1.60*f - log(1)) / (0.078)\n\nf &lt;- 0\nagem = (1.63 + 1.60*f - log(1)) / (0.078)\n\nagef |&gt; round()\n\n[1] 41\n\nagem |&gt; round()\n\n[1] 21\n\n\nFor the Donner party, at 41 years old the estimated probability of survival for women is 50%. It’s 21 for men.\n\n\n\n3. The common brushtail possum\n(3 points) The common brushtail possum of the Australia region is a bit cuter than its distant cousin, the American opossum. We consider 104 brushtail possums from two regions in Australia, where the possums may be considered a random sample from a larger population. The first region is Victoria, and the second region consists of New South Wales and Queensland.\nWe use logistic regression to differentiate between possums in these two regions. The outcome variable population takes value 1 if the possum is from Victoria and 0 if it is from New South Wales and Queensland. Five predictors are considered: sex_male, an indicator for a possum being male, head_length, skull_width, total_length, and tail_length. A full and reduced logistic model are summarized in the following table:\n----------  Full Model -----------------------|--- Reduced Model--------------------------\n            Estimate  SE      Z     Pr(&gt; |Z|) | Estimate      SE          Z        Pr(&gt; |Z|)\n(Intercept)  39.2349   11.5368 3.40   0.0007    |  33.5095    9.9053     3.38     0.0007\nsex_male     -1.2376   0.6662  -1.86  0.0632    | -1.4207     0.6457    -2.20     0.0278\nhead_length  -0.1601   0.1386  -1.16  0.2480    |\nskull_width  -0.2012   0.1327  -1.52  0.1294    | -0.2787     0.1226    -2.27     0.0231\ntotal_length 0.6488    0.1531   4.24  0.0000    |  0.5687     0.1322     4.30     0.0000\ntail_length  -1.8708   0.3741  -5.00  0.0000    | -1.8057     0.3599    -5.02     0.0000\n\nfull_m &lt;- c(39.2349, -1.2376, -0.1601, -0.2012, 0.6488, -1.8708)\nred_m &lt;- c(33.5095, -1.4207, -0.2787, 0.5687, -1.8057)\n\n\na. The remaining estimates\n\nThe variable head_length was taken out for the reduced model based on its p-value in the full model. Why did the remaining estimates change between the two models?\n\nThere was less information available to use in the equation. While head length may have been essentially useless, it was still being used in the full model. Without it in there, whatever effect it was estimated to have had to be taken up by the other variables.\n\n\nb. Probability it’s from Victoria?\n\nSuppose we see a male possum with a 65 mm wide skull, a 32 cm long tail, and a total length of 80 cm. If we know this possum was captured in the wild in Australia, what is the probability that this possum is from Victoria (using the reduced model)?\n\na male possum\n65 mm wide skull 32 cm long tail of 80 cm total length\n\nred_m\n\n[1] 33.5095 -1.4207 -0.2787  0.5687 -1.8057\n\nM &lt;- 1\nsw &lt;- 65\nt &lt;- 32\nlen &lt;- 80\n\n# ln(odds) &lt;- 33.5095 -1.4207*M -0.2787*sw + 0.5687*len - 1.8057*t\n\nodds &lt;- exp(33.5095) + exp(-1.4207*M) + exp(-0.2787*sw) + exp(0.5687*len) + exp(-1.8057*t)\nodds\n\n[1] 5.736731e+19\n\nprob &lt;- odds/(1 + odds)\nprob*100\n\n[1] 100\n\n\nThe probability of this possum being from Victoria is estimated to be 100%. I am assuming that these were all given in the correct dimensions. If they were all supposed to be in mm or cm, then it could be different.\n\nM &lt;- 1\nsw &lt;- 65/1000\nt &lt;- 32/100\nlen &lt;- 80/100\n\nodds &lt;- exp(33.5095) + exp(-1.4207*M) + exp(-0.2787*sw) + exp(0.5687*len) + exp(-1.8057*t)\nodds\n\n[1] 3.572654e+14\n\nprob &lt;- odds/(1 + odds)\nprob*100\n\n[1] 100\n\n\nMaking all of the measurements in meters, didn’t change it."
  },
  {
    "objectID": "aHW_5.html",
    "href": "aHW_5.html",
    "title": "ST-518 HW 5",
    "section": "",
    "text": "output: pdf_document"
  },
  {
    "objectID": "aHW_5.html#log-lin-reg-on-obeisty",
    "href": "aHW_5.html#log-lin-reg-on-obeisty",
    "title": "ST-518 HW 5",
    "section": "1. Log-lin Reg on obeisty",
    "text": "1. Log-lin Reg on obeisty\n\n(2 points) Recall the obesity problem from Homework 1. The data are as follows:\n\n        CVD Death\n\n            Yes         No\nObese       16        2045\nNot obese   7         1044\nUsing Poisson log linear regression, test for independence between obesity and CVD death outcome. (Hint: this is equivalent to testing that the interaction term in the model is zero.) How does your answer compare to a chi-square test on the same data?\n\no &lt;- expand.grid(\n  ob = factor(c(\"Obese\", \"NotObese\"), levels = c(\"Obese\", \"NotObese\")),\n  death = factor(c(\"Yes\", \"No\"), levels = c(\"Yes\", \"No\"))\n)\no$Freq &lt;- c(16, 7, 2045,  1044)\n\no_tab &lt;- xtabs(data = o, Freq~ob + death)\no_tab\n\n          death\nob          Yes   No\n  Obese      16 2045\n  NotObese    7 1044\n\no\n\n\n\n\n\nob\ndeath\nFreq\n\n\n\n\nObese\nYes\n16\n\n\nNotObese\nYes\n7\n\n\nObese\nNo\n2045\n\n\nNotObese\nNo\n1044\n\n\n\n\n\no2 &lt;- expand.dft(o)\n\n\nm1 &lt;- glm(data = o, \n    family = poisson, \n    Freq~ob+death)\ns1 &lt;- summary(m1)\ns1\n\n\nCall:\nglm(formula = Freq ~ ob + death, family = poisson, data = o)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.7234     0.2089   13.04   &lt;2e-16 ***\nobNotObese   -0.6734     0.0379  -17.77   &lt;2e-16 ***\ndeathNo       4.9001     0.2093   23.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4376.49698  on 3  degrees of freedom\nResidual deviance:    0.11741  on 1  degrees of freedom\nAIC: 32.796\n\nNumber of Fisher Scoring iterations: 3\n\n\n\npchisq(m1$deviance, df = m1$df.residual, lower.tail = FALSE)\n\n[1] 0.7318639\n\n\n\nm1 &lt;- glm(data = o_tab, \n    family = poisson, \n    Freq~ob+death)\ns1 &lt;- summary(m1)\ns1\n\n\nCall:\nglm(formula = Freq ~ ob + death, family = poisson, data = o_tab)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.7234     0.2089   13.04   &lt;2e-16 ***\nobNotObese   -0.6734     0.0379  -17.77   &lt;2e-16 ***\ndeathNo       4.9001     0.2093   23.41   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 4376.49698  on 3  degrees of freedom\nResidual deviance:    0.11741  on 1  degrees of freedom\nAIC: 32.796\n\nNumber of Fisher Scoring iterations: 3\n\n\n\npchisq(0.11741, df = 1, lower.tail = F)\n\n[1] 0.7318607\n\nchisq.test(o_tab, correct = F)\n\n\n    Pearson's Chi-squared test\n\ndata:  o_tab\nX-squared = 0.11541, df = 1, p-value = 0.7341\n\n\n\nchisq.test(o_tab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  o_tab\nX-squared = 0.014031, df = 1, p-value = 0.9057\n\n\nChi squared test for independence suggests evidense of an association.\nThe chi squared test of independence and the log-linear regression chi squared stat are the same. At least, they are if I turn off the continuity correction"
  },
  {
    "objectID": "aHW_5.html#elephants",
    "href": "aHW_5.html#elephants",
    "title": "ST-518 HW 5",
    "section": "2. Elephants",
    "text": "2. Elephants\n(3 points) Although male elephants are capable of reproducing by 14 to 17 years of age, younger adult males are usually unsuccessful in competing with their larger elders for the attention of receptive females. Since male elephants continue to grow throughout their lifetimes, and since larger males tend to be more successful at mating, the males most likely to pass their genes to future generations are those whose characteristics enable them to live long lives. Joyce Poole studied a population of African elephants in Amboseli National Park, Kenya, for 8 years. You can explore this data set in case2201 in the Sleuth3 library. This data frame contains the number of successful matings and ages (at the study’s beginning) of 41 male elephants.\n\nrm(list = ls())\ndata(case2201)\ndf &lt;- case2201\nhead(df)\n\n\n\n\n\nAge\nMatings\n\n\n\n\n27\n0\n\n\n28\n1\n\n\n28\n1\n\n\n28\n1\n\n\n28\n3\n\n\n29\n0\n\n\n\n\n\n\nGive an estimated model for describing the number of successful matings as a function age, using\n\nA. Model w/ lm and sqrt\n\nsimple linear regression after taking a square root transformation of the number of successful matings;\n\n\nlmsqrt &lt;- lm(sqrt(Matings)~Age, data = df)\nsummary(lmsqrt)\n\n\nCall:\nlm(formula = sqrt(Matings) ~ Age, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.90532 -0.33654  0.07767  0.45871  1.09468 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.81220    0.56867  -1.428 0.161187    \nAge          0.06320    0.01561   4.049 0.000236 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6493 on 39 degrees of freedom\nMultiple R-squared:  0.296, Adjusted R-squared:  0.2779 \nF-statistic:  16.4 on 1 and 39 DF,  p-value: 0.0002362\n\n\n\\[\nsqrt(Matings) = -.81 + .063Age\n\\] First mating around 12.9 years.\n\n\nB. lm w/ log + 1\nsimple linear regression after taking a logarithmic transformation (after adding 1);\n\ndf$mlp1 &lt;- log(df$Matings + 1)\n\nlmlp1 &lt;- lm(mlp1~Age, data = df)\nsummary(lmlp1)\n\n\nCall:\nlm(formula = mlp1 ~ Age, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.49087 -0.33939  0.06607  0.35376  0.81171 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.69893    0.45861  -1.524 0.135567    \nAge          0.05093    0.01259   4.046 0.000238 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5237 on 39 degrees of freedom\nMultiple R-squared:  0.2957,    Adjusted R-squared:  0.2776 \nF-statistic: 16.37 on 1 and 39 DF,  p-value: 0.0002385\n\n\n\\[\nlog(Matings + 1) = -0.69893 + 0.05093Age\n\\]\n\n0.69893/0.05093\n\n[1] 13.72335\n\n\nFirst mating around 13.7 years.\n\n\nC. log-linear\nlog-linear regression.\nBe sure to examine residuals from each of these models. How do the models compare? Please be specific. Is there evidence of over dispersion? If so, fit another model and report results from that model. If not, why not?\n\ndf_tab &lt;- table(df[,1:2])\ndf_tab\n\n    Matings\nAge  0 1 2 3 4 5 6 7 9\n  27 1 0 0 0 0 0 0 0 0\n  28 0 3 0 1 0 0 0 0 0\n  29 3 0 3 0 0 0 0 0 0\n  30 0 1 0 0 0 0 0 0 0\n  32 0 0 1 0 0 0 0 0 0\n  33 0 0 1 3 1 0 0 0 0\n  34 0 2 1 1 0 0 0 0 0\n  36 0 0 0 0 0 1 1 0 0\n  37 0 2 0 0 0 0 1 0 0\n  38 0 0 1 0 0 0 0 0 0\n  39 0 1 0 0 0 0 0 0 0\n  41 0 0 0 1 0 0 0 0 0\n  42 0 0 0 0 1 0 0 0 0\n  43 1 0 1 1 1 0 0 0 1\n  44 0 0 0 1 0 0 0 0 0\n  45 0 0 0 0 0 1 0 0 0\n  47 0 0 0 0 0 0 0 1 0\n  48 0 0 1 0 0 0 0 0 0\n  52 0 0 0 0 0 0 0 0 1\n\n\n\nglm1 &lt;- glm(data = df, \n            family = poisson, \n            Matings~Age)\nsummary(glm1)\n\n\nCall:\nglm(formula = Matings ~ Age, family = poisson, data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.58201    0.54462  -2.905  0.00368 ** \nAge          0.06869    0.01375   4.997 5.81e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 75.372  on 40  degrees of freedom\nResidual deviance: 51.012  on 39  degrees of freedom\nAIC: 156.46\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nglm1psi &lt;- 51.012/39 \n\nPsi of 1.3 isn’t wild.\n\\[\nlog(\\mu_{ij}) = -1.58201 + 0.06869 \\lambda_{ij}^{Age}\n\\]\nProbability of mating given age of 50 is 87%.\n\nplogis((-1.58201 + 0.06869*27), lower.tail = T)\n\n[1] 0.567736\n\n\n\ndf$sqres &lt;- residuals(lmsqrt)\ndf$p1res &lt;- residuals(lmlp1)\ndf$glmres &lt;- residuals(glm1)\n\n\ndf |&gt; ggplot() + \n  aes(x = Age, y = sqres) + \n  geom_point() + \n  labs(title = \"sqrt\")\n\n\n\n\n\n\n\ndf |&gt; ggplot() + \n  aes(x = Age, y = p1res) + \n  geom_point()+ \n  labs(title = \"log + 1\")\n\n\n\n\n\n\n\ndf |&gt; ggplot() + \n  aes(x = Age, y = glmres) + \n  geom_point()+ \n  labs(title = \"glm\")\n\n\n\n\n\n\n\n\nThere are a couple of values in the glm that are on the edge of the plus or minus 2 cutoff for outliers. That same low point at age equal to 43 is a little off in all the residual plots.\n\nnb &lt;- glm.nb(data = df, \n       Matings~Age)\nsummary(nb)\n\n\nCall:\nglm.nb(formula = Matings ~ Age, data = df, init.theta = 16.48629005, \n    link = log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.58837    0.59393  -2.674  0.00749 ** \nAge          0.06887    0.01519   4.534  5.8e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(16.4863) family taken to be 1)\n\n    Null deviance: 65.199  on 40  degrees of freedom\nResidual deviance: 44.498  on 39  degrees of freedom\nAIC: 157.92\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  16.5 \n          Std. Err.:  25.7 \n\n 2 x log-likelihood:  -151.923 \n\n\n\n44.498/ 39\n\n[1] 1.140974\n\n\nPsi is a little lower, but it wasn’t bad before.\n\ndf$nbres &lt;- residuals(nb)\n\ndf |&gt; ggplot() + \n  aes(x = Age, y = nbres) + \n  geom_point()+ \n  labs(title = \"nb\")\n\n\n\n\n\n\n\n\nThe negative binomial residuals look the same.\n\nsummary(lmsqrt)\n\n\nCall:\nlm(formula = sqrt(Matings) ~ Age, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.90532 -0.33654  0.07767  0.45871  1.09468 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.81220    0.56867  -1.428 0.161187    \nAge          0.06320    0.01561   4.049 0.000236 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6493 on 39 degrees of freedom\nMultiple R-squared:  0.296, Adjusted R-squared:  0.2779 \nF-statistic:  16.4 on 1 and 39 DF,  p-value: 0.0002362\n\n\nAn increase of 1 year in Age results in a .06 more matings. This one has a lower intercept than the log plus one lm.\n\nsummary(lmlp1)\n\n\nCall:\nlm(formula = mlp1 ~ Age, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.49087 -0.33939  0.06607  0.35376  0.81171 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.69893    0.45861  -1.524 0.135567    \nAge          0.05093    0.01259   4.046 0.000238 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5237 on 39 degrees of freedom\nMultiple R-squared:  0.2957,    Adjusted R-squared:  0.2776 \nF-statistic: 16.37 on 1 and 39 DF,  p-value: 0.0002385\n\n\nAn increase of 1 year in Age results in a .05 more matings.\n\nsgl &lt;- summary(glm1)\nsgl\n\n\nCall:\nglm(formula = Matings ~ Age, family = poisson, data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.58201    0.54462  -2.905  0.00368 ** \nAge          0.06869    0.01375   4.997 5.81e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 75.372  on 40  degrees of freedom\nResidual deviance: 51.012  on 39  degrees of freedom\nAIC: 156.46\n\nNumber of Fisher Scoring iterations: 5\n\nsgl$coefficients |&gt; exp()\n\n             Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept) 0.2055619   1.723955   0.05476055 1.003682\nAge         1.0711071   1.013841 148.02412630 1.000001\n\n\nAn increase of 1 year in Age results in a 7% increase in matings.\n\npchisq(51.012, df = 39, lower.tail = F)\n\n[1] 0.09425638\n\n\np-values for all three models are low, but glm is the highest."
  },
  {
    "objectID": "aHW_5.html#log-lin-v-linear-transfromed.",
    "href": "aHW_5.html#log-lin-v-linear-transfromed.",
    "title": "ST-518 HW 5",
    "section": "3. Log-lin v Linear transfromed.",
    "text": "3. Log-lin v Linear transfromed.\n(2 points) What is the difference between a log-linear model and a linear model after the log transformation of the response?\nIf the log transformation results in constant variance then, MLR could be used. However, glms don’t assume constant variance or normality.\nMultiplicative vs additivity in error terms is the major difference. In MLR additivity is assumed."
  },
  {
    "objectID": "aHW_5.html#elephants-1",
    "href": "aHW_5.html#elephants-1",
    "title": "ST-518 HW 5",
    "section": "4. Elephants",
    "text": "4. Elephants\n(3 points) This question refers to the elephant mating data from question 2 above.\n\nA.\nBoth the binomial and the Poisson distributions provide probability models for random counts. Which distribution is more appropriate to model the number of successful matings for male African elephants, and why?\nElephant mating doesn’t have fixed sample size or constant probability, so Poisson is better in this instance.\n\n\nB\nIn the following plot, we see that the spread of responses is larger for larger values of the mean response. Is this something to be concerned about if we perform a Poisson log-linear regression?\n\nggplot(df) + aes(Age, Matings) + geom_point() + \n  geom_smooth(se = T, method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nPoisson assumes that variance will go up with mean. The lambda parameter is the only parameter, if one goes up so does the other.\n\n\nC\n\nPerforming a Poisson log-linear regression results in the following output:\n\n                Estimate    Std. Error z value    Pr(&gt; |z|)\n(Intercept)     -1.58201    0.54462     -2.905    0.00368 **\nAge             0.06869     0.01375     4.997     5.81e-07 ***\nResidual Deviance: 51.01 on 39 degrees of freedom\nWhat are of the mean and variance of the distribution of counts of successful matings (in 8 years) for elephants who are aged 25 years at the beginning of the observation period? What are the mean and variance for elephants who are aged 45 years?\nI do not know what that means, but lets try and figure it out. 25 to 33 year old elephants. Distribution of counts suggests we are not talking about the glm at all. I guess it wants me to filter by age and get the mean and variance.\n\nd &lt;- df |&gt; filter(Age &gt; 24 & Age &lt; 34)\nmean(d$Matings)  \n\n[1] 1.666667\n\nsd(d$Matings)^2\n\n[1] 1.529412\n\n\nThe mean and variance of the distribution of Matings for elephants 25 to 33 are 1.66 and 1.53 respectively.\n\nMV &lt;- function(A) {-1.58201 + 0.06869*A}\n\nmean(MV(seq(25, 33, 1))) |&gt; exp()\n\n[1] 1.506818\n\n(sd(MV(seq(25, 33, 1)))^2) |&gt; exp()\n\n[1] 1.036021\n\n\nFor the estimated distribution between 25 and 33, mean is 1.5 and var is 1.04.\n\nA &lt;- 45\nMV(A) |&gt; exp()\n\n[1] 4.522387\n\n\nThe mean and variance for elephants at 45 is 4.5 Matings."
  },
  {
    "objectID": "aHW_7.html",
    "href": "aHW_7.html",
    "title": "ST-518 HW 7",
    "section": "",
    "text": "output: pdf_document"
  },
  {
    "objectID": "aHW_7.html#r-question",
    "href": "aHW_7.html#r-question",
    "title": "ST-518 HW 7",
    "section": "R Question",
    "text": "R Question\n\n(5 points) Recall the data in ex2119 in the Sleuth3 library. These data record results from 10 different studies in which the relationship between breast cancer and whether or not a woman had breast fed her child(ren) was examined. Earlier in the course, you looked at these data, and treated study as a fixed effect. Another way to consider these data is by taking study to be a random effect.\n\nFit an appropriate GLMM to the breast cancer data, using study as a random effect. Report the estimated random effect variance and the fixed effect estimate for the Lactate variable, as well as its standard error.\nCreate a normal probability plot of the random effects. Do you notice anything unusual?\nWrite a few sentences about how you might proceed with an analysis from here. There are several different approaches you could take—just decide on one and describe it briefly."
  },
  {
    "objectID": "aHW_7.html#conceptual-questions",
    "href": "aHW_7.html#conceptual-questions",
    "title": "ST-518 HW 7",
    "section": "Conceptual Questions",
    "text": "Conceptual Questions\n\n(3 points) Please answer true or false to the following. Explain/justify your answers.\n\nOne reason for using a mixed effects model is to account for the similarities among observations that are clustered together in groups.\nIf a GLMM does not converge in R, we should just go back to using a GLM approach.\nIf an estimated random efect variance is small, that’s an indication that we don’t need that random effect in the model.\n\n(2 points) Consider the following R output from fitting a GLMM to the Donner party data (’Donner‘ in the ’vcdExtra‘ package) using ’family‘ as a random effect.\nI am not fixing this right now. Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod]  Family: binomial ( logit )  Formula: survived ~ age + sex + (1 | family)  Data: Don  AIC BIC logLik deviance df.resid  116.1 126.1 -54.1 108.1 86  Scaled residuals:  Min 1Q Median 3Q Max  -2.3824 -0.6896 0.3774 0.6315 1.7398  Random effects:  Groups Name Variance Std.Dev.  1  family (Intercept) 0.6738 0.8209  Number of obs: 90, groups: family, 10  Fixed effects:  Estimate Std. Error z value Pr(&gt;|z|)  (Intercept) 1.73785 0.62108 2.798 0.00514 **  age -0.03452 0.01632 -2.115 0.03445 *  sexMale -1.21847 0.54514 -2.235 0.02541 *  ---  Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1  Write a short paragraph that describes the results from fitting this model."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reference",
    "section": "",
    "text": "Gradescope\nLectures"
  },
  {
    "objectID": "index.html#git-stuff",
    "href": "index.html#git-stuff",
    "title": "Reference",
    "section": "Git stuff",
    "text": "Git stuff\nAdd, commit, and publish the folder to the github repo\n\ngit add .\ngit commit -m “comment”\ngit push origin main\n\nSet the location of the github repo\n\ngit remote set-url origin url\ngit remote -v\ngit remote show origin\n\n\nHere are some quarto commands:\n\nquarto publish gh-pages\nquarto publish gh-pages document.qmd\nquarto publish gh-pages - -no-prompt\nquarto render .qmd - -to pdf"
  },
  {
    "objectID": "index.html#reading-list",
    "href": "index.html#reading-list",
    "title": "Reference",
    "section": "Reading list",
    "text": "Reading list\nCat Data Anal 3rd\nStat. Meth 3rd\nOpen Stats 4th ed\nR4DS 1st\n\nExtra Reading\nMathmatical Stats 8th\nPractical Stats for DS\n\n\nModule 1\n\nCategorical Data Analysis, Sections 1.1, 1.2\nStatistical Methods, Section 12.1\nOpenIntro Statistics, Section 6.1\nR for Data Science, Look over Chapters 1, 2, and 3\n\n\n\nModule 2\n\nCategorical Data Analysis, Sections 1.2, 1.3.\nStatistical Methods, Section 12.2-12.4.\nOpenIntro Statistics, Section 6.2-6.4\nR for Data Science (Lab references Chapter 22)\n\n\n\nModule 3\n\nCategorical Data Analysis, Sections 4.1, 4.2 (through 4.2.5); 5.1-5.3 (through 5.3.6). Please note: content not in lectures.\nStatistical Methods, Sections 13.1-13.2.\nOpenIntro Statistics, Section 8.4. and Section 9.5\n\n\n\nModule 4\n\nCategorical Data Analysis, Sections 4.7, 6.2\n\n\n\nModule 5\n\nCategorical Data Analysis, Sections 4.3, 9.1 (through 9.1.3; some of the notation here may be difficult, but it is equivalent to using indicator functions to denote different categories).\n\n\n\nModule 6\n\nAn Application of Claim Frequency Data using Zero Inflated and Hurdle Models in General Insurance\n\n\n\nModule 7\n\nCategorical Data Analysis, Chapter 13, through Section 13.1.4; Section 13.3. Please note: models are given in matrix notation.\n\n\n\nModule 8\n\nCategorical Data Analysis, Chapter 6, 6.3.1, 6.3.3 and 6.3.4\nOpenIntro Statistics, Section 8.4"
  },
  {
    "objectID": "index.html#website",
    "href": "index.html#website",
    "title": "Reference",
    "section": "Website",
    "text": "Website\nThis is from the github repo creation page\nPush an existing repository from the command line:\n\ngit remote add origin url\ngit branch -M main\ngit push -u origin main\n\n\nSetting up the website:\n\nCreate a new git repository\nCreate a quarto project website\nRender the project\nAdd _site & .quarto to the .gitignore file\ngit remote add origin\ngit branch -M main\ngit add .\ngit commit\ngit push\nrefresh github.com/name\nview all branches -&gt; New -&gt; “gh-pages”\nsettings -&gt; pages -&gt; deploy from gh-pages\nquarto publish gh-pages\n\nIt should work ever after by just typing quarto publish gh-pages. There may be a need to get a personal access token at the start. I did that my first go around so I’m not sure. Sometimes the site doesn’t render immediately. You have to wait for it to finish in the actions tab of github."
  },
  {
    "objectID": "z1_learnR.html",
    "href": "z1_learnR.html",
    "title": "1 Types of Categoricals",
    "section": "",
    "text": "Lab 1"
  },
  {
    "objectID": "z1_learnR.html#setup",
    "href": "z1_learnR.html#setup",
    "title": "1 Types of Categoricals",
    "section": "Setup",
    "text": "Setup\nFor this lab, we’ll use the following packages, so you can go ahead and run this chunk of code (unless of course you decided to “Run All” already).\n\nlibrary(gnm)\nlibrary(vcdExtra)\nlibrary(Sleuth3)\nlibrary(tidyverse)"
  },
  {
    "objectID": "z1_learnR.html#formats",
    "href": "z1_learnR.html#formats",
    "title": "1 Types of Categoricals",
    "section": "Formats",
    "text": "Formats\n\nCase Format\nThis familiar format, applicable to both continuous and categorical data, is what R for Data Science calls “tidy data” (see vignette('tidy-data') for much more on this idea). The data are arranged in an n x p rectangular array (e.g. a data frame), where n is the number of observations and p the number of variables. That is, there is one observation per row and one variable per column. This is a good starting point for most analyses.\n\nX &lt;- data.frame(\n V1 = c('Up', 'Up', 'Down', 'Down', 'Up', 'Up'), \n V2 = c('Left', 'Left', 'Right', 'Right', 'Left', 'Right'),\n V3 = c('B','B','A','B', 'A', 'B'))\nX\n\n\n\n\n\nV1\nV2\nV3\n\n\n\n\nUp\nLeft\nB\n\n\nUp\nLeft\nB\n\n\nDown\nRight\nA\n\n\nDown\nRight\nB\n\n\nUp\nLeft\nA\n\n\nUp\nRight\nB\n\n\n\n\n\n\n\nHow many variables are in X? How many observations?\n\n3\nThe case or “tidy” format is fully general it’s applicable to data sets consisting of (complete) observations on any combination of continuous and/or categorical variables. In contrast, the next two formats are specific to data sets where all the variables are categorical (or where any continuous variables can be ignored or discretized).\n\n\nFrequency Format\nIn this format, the data are still arranged in a 2-D rectangular array, but with the number of rows equal to the number of combinations of factor levels, and the number of columns is p + 1. The extra column (typically the last) contains the counts, or frequencies, observed at each of the possible combinations of factor levels.\n\nlibrary(kableExtra)\n\nX %&gt;% table %&gt;% as.data.frame |&gt;kbl() |&gt; \n kable_styling(bootstrap_options = \"striped\", full_width = F, position = \"left\") \n\n\n\n\n\nV1\nV2\nV3\nFreq\n\n\n\n\nDown\nLeft\nA\n0\n\n\nUp\nLeft\nA\n1\n\n\nDown\nRight\nA\n1\n\n\nUp\nRight\nA\n0\n\n\nDown\nLeft\nB\n0\n\n\nUp\nLeft\nB\n2\n\n\nDown\nRight\nB\n1\n\n\nUp\nRight\nB\n1\n\n\n\n\n\n\n\n# don't worry about this code for now\n\nNotice that I used the pipe operator in this last R chunk to first perform the table() function on X and then perform the as.data.frame() function on that. The equivalent, nested functions are shown in the table below. Please refer back to M1Lab0.Rmd to learn more about the pipe operator.\n\nCan you see why there are 8 rows in this display? Think about the number of levels for each of the three categorical variables.\n\nthe number of combinations of factor levels\n\n\nTabular Format\nIn this format, the data are arranged in a p-dimensional array of frequencies, where p is the number of variables. The dimensions of the array are the number of factor levels for each variable. The elements in the array are the observed frequencies at each of the possible combinations of factor levels.\n\nX_tab &lt;- table(X)\n\nObserve that since there are a 3 variables in X, the table object is a 3-dimensional array.\n\n## Dimensions of the 3-dimensional array that contains the frequencies of the factor-level combinations of the 3 \n# variables in `X`.\n(dims &lt;- dim(X_tab))\n\n[1] 2 2 2\n\n# This is why there are 8 rows in the frequency table \nprod(dims)\n\n[1] 8\n\n\n\nX &lt;- data.frame(\n V1 = c('Up', 'Up', 'Down', 'Down', 'Up', 'Up'), \n V2 = c('Left', 'Left', 'Right', 'Right', 'Left', 'Right'),\n V3 = c('B','B','A','B', 'A', 'B'))\nX\n\n\n\n\n\nV1\nV2\nV3\n\n\n\n\nUp\nLeft\nB\n\n\nUp\nLeft\nB\n\n\nDown\nRight\nA\n\n\nDown\nRight\nB\n\n\nUp\nLeft\nA\n\n\nUp\nRight\nB\n\n\n\n\n\nX_tab &lt;- table(X)\n# 2-D slices of 3-D table\nX_tab\n\n, , V3 = A\n\n      V2\nV1     Left Right\n  Down    0     1\n  Up      1     0\n\n, , V3 = B\n\n      V2\nV1     Left Right\n  Down    0     1\n  Up      2     1\n\n\nSince this table is a 3-D object, trying to print it to the 2-D screen disassembles it. You’ll see much more on this issue in later sections. The R terminology makes no distinction between the multidimensional table and its 2-D representation both are “tables”. When confusion may arise between these concepts later on, I will generally refer to the higher-dimensional object as a (tabular) array and a 2-D view of it as a (tabular) display.\n\n\nConverting Between Formats\nThe table below lists some functions you can use to convert between each of these three standard categorical data formats. In practice, there are other possible formats this does not cover every possible arrangement but many categorical data sets will resemble one of these forms. You are not expected to be familiar with these functions already this table is just a reference. In the next section, we will illustrate some of these transformations using a real data set, one which begins in a less-standard format (i.e., not one of case, frequency, or tabular format).\n\n\n\n\n\n\n\n\n\nConvert: Row to column\nCase form\nFrequency form\nTabular form\n\n\n\n\nCase form\nN/A\nas.data.frame(table(X))\ntable(X) or xtabs( ~ V1 + V2 +…+ Vp, X)\n\n\nFrequency form\nexpand.dft(X)\nN/A\nxtabs(Freq ~ V1 + V2 +…+ Vp, X)\n\n\nTabular form\nexpand.dft(X)\nas.data.frame(X)\nN/A\n\n\n\nIn the table above, X is a data frame/table, V1,…,Vp are variable columns, and Freq is a column of counts.\nNote: when considering a single factor, frequency format and table format are the same. When there are no other variables to combine, the counts at each “combination” of levels of every variable (frequency format) is simply the count at each level of the one variable (table format)."
  },
  {
    "objectID": "z1_learnR.html#dataset-race-and-the-death-penalty",
    "href": "z1_learnR.html#dataset-race-and-the-death-penalty",
    "title": "1 Types of Categoricals",
    "section": "Dataset: Race and the Death Penalty",
    "text": "Dataset: Race and the Death Penalty\nFor the remainder of this lab, we will work with the death penalty data in case1902 from the Sleuth3 package. These data come from a study embedded in an extensive literature on racial patterns in death sentencing. Other studies have examined whether black felons are more likely to receive the death penalty than white felons for comparable crimes. This study restricted attention to black murderers, asking whether blacks were more likely to be sentenced to death for murdering whites than for murdering other blacks, even when the crimes were otherwise comparable. Take a look at the data, and read the documentation in the help file.\n\npenalty &lt;- case1902\npenalty\n\n\n\n\n\nAggravation\nVictim\nDeath\nNoDeath\n\n\n\n\n1\nWhite\n2\n60\n\n\n1\nBlack\n1\n181\n\n\n2\nWhite\n2\n15\n\n\n2\nBlack\n1\n21\n\n\n3\nWhite\n6\n7\n\n\n3\nBlack\n2\n9\n\n\n4\nWhite\n9\n3\n\n\n4\nBlack\n2\n4\n\n\n5\nWhite\n9\n0\n\n\n5\nBlack\n4\n3\n\n\n6\nWhite\n17\n0\n\n\n6\nBlack\n4\n0\n\n\n\n\n\nstr(penalty)\n\n'data.frame':   12 obs. of  4 variables:\n $ Aggravation: int  1 1 2 2 3 3 4 4 5 5 ...\n $ Victim     : Factor w/ 2 levels \"Black\",\"White\": 2 1 2 1 2 1 2 1 2 1 ...\n $ Death      : int  2 1 2 1 6 2 9 2 9 4 ...\n $ NoDeath    : int  60 181 15 21 7 9 3 4 0 3 ...\n\n\n\nExample: Reformatting the penalty Dataset\nThe format of the penalty data does not quite fit into any of the three categories described above, this is something like a “flat table”. The biggest difference here is that the levels of one of the factors, let’s call it “Sentence”, have been split into two columns – “Death” and “NoDeath.” Later we will see how to produce a flat table from a tabular array, but for now we will see how to transform these data into one of the standard formats.\n\n\nFrequency Format\nLet’s see if we can first get these data into frequency format. This means figuring out what the variables are, and putting each variable into its own column. The key thing to notice is that the actual unit of observation is the post-conviction sentencing decision for a single murder trial, and the outcome of sentencing from a single conviction can be either Death or NoDeath. That is, as we mentioned above, Death and NoDeath are not separate, logically-independent variables, when measured at the level of individual murder trials, but are two levels of the same (as yet unnamed) variable.\ntidyr to the rescue:\n\nYou use pivot_longer() when you notice that you have columns that are not variables, but rather levels of a single variable.\n\nWe’ll use pivot_longer() to collapse the Death and NoDeath columns into a new column named Sentence.\n\npenalty_freq &lt;- pivot_longer(\n  data = penalty, \n  cols = c(\"Death\", \"NoDeath\"), names_to = \"Sentence\", values_to = \"Freq\", cols_vary = \"slowest\")\n\n# cols_vary = \"slowest\" keeps individual columns from cols close together in the output. \n# Here, this keeps the data ordered by Aggravation.\n\nObserve how the data in each row of penalty takes up two rows in penalty_freq (namely, rows 1 and 13).\n\npenalty[1,]\n\n\n\n\n\nAggravation\nVictim\nDeath\nNoDeath\n\n\n\n\n1\nWhite\n2\n60\n\n\n\n\n\n\n\npenalty_freq[c(1,13),]\n\n\n\n\n\nAggravation\nVictim\nSentence\nFreq\n\n\n\n\n1\nWhite\nDeath\n2\n\n\n1\nWhite\nNoDeath\n60\n\n\n\n\n\n\nYou can View() penalty_freq to check that it looks like it should.\n\n\nCase Format\nNow suppose we want to see all the individual observations, each trial on a separate row. Referring to the table of conversion functions, we can use expand.dft() to get from a frequency format to a case format.\n\n# the other functions in that table are available in base R, but expand.dft() is from vcdExtra.\npenalty_case &lt;- expand.dft(penalty_freq)\nhead(penalty_case)\n\n\n\n\n\nAggravation\nVictim\nSentence\n\n\n\n\n1\nWhite\nDeath\n\n\n1\nWhite\nDeath\n\n\n1\nBlack\nDeath\n\n\n2\nWhite\nDeath\n\n\n2\nWhite\nDeath\n\n\n2\nBlack\nDeath\n\n\n\n\n\n\n# Add {r} after backticks to make executable, or just type this command in the console.\nView(penalty_case)\nWhen expanded to case format, there are 362 rows (observations) and 3 columns (variables). Note that from case format, we could encode the categorical variables using binary indicators. Each categorical variable takes two possible values, so we only need one binary indicator for each.\n\npenalty_indicators&lt;- mutate(penalty_case, .keep = \"none\",\n        Aggravation = Aggravation,\n        White = ifelse(Victim == \"White\", 1, 0), \n        Death = ifelse(Sentence == \"Death\", 1, 0))\n# another binary encoding: model.matrix( ~ Sentence + Victim + Aggravation, data = penalty_case)\nhead(penalty_indicators)\n\n\n\n\n\nAggravation\nWhite\nDeath\n\n\n\n\n1\n1\n1\n\n\n1\n1\n1\n\n\n1\n0\n1\n\n\n2\n1\n1\n\n\n2\n1\n1\n\n\n2\n0\n1\n\n\n\n\n\n\nTypically we will leave the indicator variables behind the scenes, where they will be created as needed by modeling functions. If you want to see what this looks like, you can produce an explicit indicator-encoding for a whole data frame at once, without writing out a page of if-else statements, using the model.matrix() function.\n\n\nTabular Format\nStarting from either the frequency or case format, we can create a variety of tabular structures using table() or xtabs(). I find the xtabs() interface more convenient. With a minor change in the formula specification, xtabs() can tabulate either case form or frequency form data.\n\nTo tabulate frequency-format data, write the name of the frequency column on the left-hand side of the formula, and the other variables on the right-hand side. For case-format data, leave the left-hand side of the formula empty.\n\n\n# The following are equivalent:\npenalty_tab &lt;- xtabs(~ Sentence + Victim + Aggravation, penalty_case)\n# penalty_tab &lt;- xtabs(Freq ~ Sentence + Victim + Aggravation, penalty_freq)\n\nUnderstanding the tabular form is very important when dealing with categorical data. The next section treats tabular data with more depth."
  },
  {
    "objectID": "z1_learnR.html#working-with-tabular-data",
    "href": "z1_learnR.html#working-with-tabular-data",
    "title": "1 Types of Categoricals",
    "section": "Working with Tabular Data",
    "text": "Working with Tabular Data\nThe penalty data has 3 variables, so a complete tabulation produces a 3-D array. The “spatial orientation” of this array depends on the order of the variables on the right-hand side of the xtabs() formula:\n\nxtabs(~ Sentence + Victim + Aggravation, penalty_case) %&gt;% dim\n\n[1] 2 2 6\n\n\n\nxtabs(~ Sentence + Aggravation + Victim, penalty_case) %&gt;% dim\n\n[1] 2 6 2\n\n\nInstead of rearranging the formula, we can “rotate” the array using aperm() (“array permutation”).\n\naperm(penalty_tab, perm = c(1, 2, 3)) %&gt;% dim\n\n[1] 2 2 6\n\n\n\n# the 2nd and 3rd dimensions switched places -- we've turned the array on its end\naperm(penalty_tab, perm = c(1, 3, 2)) %&gt;% dim \n\n[1] 2 6 2\n\n\nSo far we still haven’t shown the tabular array we’ve built! Displaying a table with three or more dimensions on a 2-D computer screen (or page) takes a little thought. There are two main ways to reduce the dimension of an array we can condition (“slice”) or marginalize (“squash”).\n\nConditioning\nIn general, to slice an n-dimensional array into m-dimensional pieces, we must fix “condition on” each of the possible values of the other n - m variables. For penalty_tab, we can get 2-D slices by conditoning on just one other variable. Let’s try this with Sentence as the conditioning variable the relevant function is co_table() (“condition table”). Based on the table dimensions we just saw, this should create two 2-D (2x6) slices.\n\n(penalty_given_sentence &lt;- co_table(penalty_tab,'Sentence'))\n\n$Death\n       Aggravation\nVictim   1  2  3  4  5  6\n  Black  1  1  2  2  4  4\n  White  2  2  6  9  9 17\n\n$NoDeath\n       Aggravation\nVictim    1   2   3   4   5   6\n  Black 181  21   9   4   3   0\n  White  60  15   7   3   0   0\n\n\nConditioning preserves all of the information in the array. We can display the whole tabular array by laying out each slice end to end. The slices are named by the levels of the conditioning variable, and naming a particular level returns that slice:\n\npenalty_given_sentence$Death\n\n       Aggravation\nVictim   1  2  3  4  5  6\n  Black  1  1  2  2  4  4\n  White  2  2  6  9  9 17\n\n\nOf course, if you condition on two out of three variables at once (using a vector of conditioning variables) you’ll get 1-D slices, and conditioning on all three variables cuts up the table into all of its individual frequency components. In higher-dimensional tables this will be different. For instance, if we started with a 6-D table, conditioning on three variables would return 3-D slices. You are welcome to play around with using the death penalty data and see what weirdness you can produce!\nWe can arrange 2D array slices into a single tabular display by using ftable() (“flat table”) or structable(). Both of these functions can take an existing table object as input, or create new tables directly from data using a formula interface.\nHere’s an example with pre-tabulated data from above:\n\npenalty_tab %&gt;% aperm(c(3, 1, 2)) %&gt;% ftable\n\n                     Victim Black White\nAggravation Sentence                   \n1           Death               1     2\n            NoDeath           181    60\n2           Death               1     2\n            NoDeath            21    15\n3           Death               2     6\n            NoDeath             9     7\n4           Death               2     9\n            NoDeath             4     3\n5           Death               4     9\n            NoDeath             3     0\n6           Death               4    17\n            NoDeath             0     0\n\n\nAnd here’s an example of the formula interface for structable() and ftable(), which is somewhat different from the xtabs() formula interface (because it’s intended to produce a different kind of object), but still quite intuitive.\nThe following tables are fairly wide, so to view them in the R Markdown file, you’ll have to expand the width of the source pane (or, you could click Preview and see the table in the Viewer pane, which you may also have to widen!).\n\nftable(Aggravation + Victim ~ Sentence, penalty_case)\n\n         Aggravation     1           2           3           4           5           6      \n         Victim      Black White Black White Black White Black White Black White Black White\nSentence                                                                                    \nDeath                    1     2     1     2     2     6     2     9     4     9     4    17\nNoDeath                181    60    21    15     9     7     4     3     3     0     0     0\n\n\n\nstructable(Sentence + Aggravation ~ Victim, penalty_case)\n\n       Sentence    Death                     NoDeath                    \n       Aggravation     1   2   3   4   5   6       1   2   3   4   5   6\nVictim                                                                  \nBlack                  1   1   2   2   4   4     181  21   9   4   3   0\nWhite                  2   2   6   9   9  17      60  15   7   3   0   0\n\n\nYou can see that the variables on right hand side of the formula control the recursive column splits, and the variables on the left hand side control the recursive row splits (variable order matters on both sides).\nAnalogous to the way that the table orientation defined by the order of an xtabs() formula can be “rearranged” with aperm(), a structable()’s split orientation can be “rearranged” using the direction argument:\n\npenalty_tab %&gt;% aperm(c(2, 1, 3)) %&gt;% structable(direction = c(\"v\", \"v\", \"h\"))\n\n            Victim   Black         White        \n            Sentence Death NoDeath Death NoDeath\nAggravation                                     \n1                        1     181     2      60\n2                        1      21     2      15\n3                        2       9     6       7\n4                        2       4     9       3\n5                        4       3     9       0\n6                        4       0    17       0\n\n\n\nTry playing with the order of dimensions and/or directions of table splits in the structable() call until you get a flat display arranged like the original case1902 data frame.\n\n\n\nMarginalizing\nIn addition to slicing the tabular array, we can also squash it by summing across one or more dimension(s). We can do this simply by omitting from the xtabs() formula specification the variables we wish to collapse along.\n\nxtabs(~ Victim + Sentence, penalty_case) # collapse along Aggravation axis\n\n       Sentence\nVictim  Death NoDeath\n  Black    14     218\n  White    45      85\n\n\n\nxtabs(~ Sentence, penalty_case) # collapse along Aggravation and Victim axes\n\nSentence\n  Death NoDeath \n     59     303 \n\n\nAlternatively, starting with a complete array, we can collapse it using margin.table(). As with the formula specification above, omitted variables get collapsed.\n\nmargin.table(penalty_tab, margin = c(1,2)) \n\n         Victim\nSentence  Black White\n  Death      14    45\n  NoDeath   218    85\n\n# penalty_tab was defined with the formula ~ Sentence + Victim + Aggravation. Sentence and Victim, as the first two variables in the formula, will be retained, while Aggravation will get squashed. \n\n\n# Aggravation is the 3rd variable in the formula, so here it will be retained while `Victim` and `Sentence` get squashed.\nmargin.table(penalty_tab, margin = c(3))\n\nAggravation\n  1   2   3   4   5   6 \n244  39  24  18  16  21 \n\n\nmargin.table(penalty_tab) with no other arguments predictably returns the table total. All variables are omitted, so all dimensions are collapsed.\nWe’ve been talking about “collapsing” tables, and somewhat confusingly there is a function named collapse.table(), that behaves slightly differently. Instead of squashing omitted dimensions flat, it shortens a specified dimension by reducing the number of factor levels along that axis. Say we want a table where Aggravation levels 1-3 are grouped together as “Low” and levels 4-6 “High”. Without editing the original data, we could use collapse.table():\n\npenalty_tab %&gt;% collapse.table('Aggravation' = c(rep(\"Low\", 3), c(rep(\"High\", 3))))\n\n, , Aggravation = Low\n\n         Victim\nSentence  Black White\n  Death       4    10\n  NoDeath   211    82\n\n, , Aggravation = High\n\n         Victim\nSentence  Black White\n  Death      10    35\n  NoDeath     7     3\n\n\n\n\nTables of Proportions\nFrom a table of counts, we often wish to make a table of proportions or percentages, where the proportions may be taken with respect to rows, columns, tables, etc.\n\n# Table of counts\n(sentence_victim_tab &lt;- margin.table(penalty_tab, margin = c(1,2)))\n\n         Victim\nSentence  Black White\n  Death      14    45\n  NoDeath   218    85\n\n# Table of proportions\nprop.table(sentence_victim_tab) %&gt;% round(2) # rounding all proportions to 2 decimal points to avoid visual clutter\n\n         Victim\nSentence  Black White\n  Death    0.04  0.12\n  NoDeath  0.60  0.23\n\n\nThe proportions above are taken with respect to the whole table. We’re actually more interested in the proportions of Death Sentences within each Victim level:\n\n# Table of column proportions\ncol_prop_tab &lt;- prop.table(sentence_victim_tab, margin = 2)\ncol_prop_tab %&gt;% round(2)\n\n         Victim\nSentence  Black White\n  Death    0.06  0.35\n  NoDeath  0.94  0.65\n\n# Table of column percents\n100 * col_prop_tab %&gt;% round(3)\n\n         Victim\nSentence  Black White\n  Death     6.0  34.6\n  NoDeath  94.0  65.4"
  },
  {
    "objectID": "z1_learnR.html#visualizing-categorical-data",
    "href": "z1_learnR.html#visualizing-categorical-data",
    "title": "1 Types of Categoricals",
    "section": "Visualizing Categorical Data",
    "text": "Visualizing Categorical Data\nIn earlier stats courses, you’ve no doubt seen barcharts for categorical data. You can get regular or stacked barcharts for 1 or 2 variables respectively using barplot() on a table object:\n\nbarplot(xtabs(~Sentence + Aggravation, penalty_case))\n\n\n\n\n\n\n\n\nor with qplot(geom = \"bar\") on a data frame of cases.\n\nqplot(data = penalty_case, x = Aggravation, fill = Sentence, geom = \"bar\")\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\n\n\n\n\nAnother very useful graphic is the mosaic plot, which can take as input either a table, or the xtabs() formula that would produce a table.\n\nmosaic(~ Victim + Sentence, penalty_case)\n\n\n\n\n\n\n\n\nIn this plot, the proportion in each cell of the table is represented by the area of the corresponding rectangle. The proportion of Victims who were black vs white is represented by the relative heights of the upper vs. lower sets of rectangles, and the widths of each rectangle represent the proportions of Sentences within each victim category. This plot makes clear that death sentences were more likely to be given for murders of whites, when not accounting for Aggravation.\nWe can actually extend the mosaic plot to show the third dimension as well, using a conditioning approach. Consider the flat table produced by the following R chunk (widen panes as needed for full view):\n\nflat_table &lt;- xtabs(~ Sentence + Victim + Aggravation, penalty_case) %&gt;%\n  prop.table(margin = c(2, 3)) %&gt;% \n  aperm(c(3,2,1)) %&gt;% \n  structable(direction = c(\"v\",\"v\",\"h\"))\n\nflat_table %&gt;% round(2)\n\n         Aggravation     1           2           3           4           5           6      \n         Victim      Black White Black White Black White Black White Black White Black White\nSentence                                                                                    \nDeath                 0.01  0.03  0.05  0.12  0.18  0.46  0.33  0.75  0.57  1.00  1.00  1.00\nNoDeath               0.99  0.97  0.95  0.88  0.82  0.54  0.67  0.25  0.43  0.00  0.00  0.00\n\n# You may want to make a new chunk wherein you can unpack this code a bit, and take a look at some of the intermediate objects. I find this particular code it somewhat obnoxiously convoluted, because prop.table() doesn't operate correctly on flat tables. This requires the marginal proportions to be calculated from the regular table, *then* passed as such into structable()/ftable() to be flattened for display. \n\n# If you can find a nicer way to make this flat table, I'd like to see it!\n\nAnd now, you can look at a mosaic plot of that flat table. This is a visual representation of the proportions in the flat table.\n\nmosaic(flat_table)\n\n\n\n\n\n\n\n\nFrom this plot, there’s evidence that across levels of Aggravation, the racial disparity in sentencing remains, at least in this sample of murder trials. You can see this by considering the two vertical bars that correspond to each aggravation level. If sentencing did not differ based on race (given aggravation level), then the splits between Death and NoDeath should be at the same height for both Black and White victims. You might wonder if this disparity that we see is larger than we could reasonably expect to observe by chance in a sample of 362 murder trials. We will begin to address these types of questions in the following lab, where we will explore statistical tests of association for categorical variables.\n\nOpen question: It is not obvious that prop.table(margin = c(2,3)) represents the only “correct” set of proportions for answering looking at whether the racial effect on sentencing persists after accounting for aggravation. Can you think of a different set of proportions that might also address this?"
  },
  {
    "objectID": "z1_learnR.html#instructions",
    "href": "z1_learnR.html#instructions",
    "title": "1 Types of Categoricals",
    "section": "Instructions",
    "text": "Instructions\nFor this assignment, you are asked to create a self-contained R Markdown script that can generate a document which answers the questions below. You will submit the .Rmd script, and you will be graded based on the HTML document that it generates.\n\n\n\n\n\n\nR Markdown for submission\n\n\n\n\n\nThe following describes the process of creating and submitting .Rmd and .pdf files as your lab assignment. You will follow this procedure after each lab in this course.\nNOTE: If you are reading these instructions from the HTML preview in the Viewer pane, they will be overwritten in the following steps. You can avoid this by “popping out” the current HTML preview into an external browser window, by clicking the the “Show in new window” icon (to the right of the broom icon in the Viewer pane).\nAlternatively, you can read the instructions right from the .Rmd script, keeping in mind that you will need to switch back to the lab script tab to view the rest of the instructions once you create a new script. You could also copy and paste the whole Lab 1 Assignment Instructions section into your new document while you’re working on it, and then delete the instructions before you submit it.\nClick “File” -&gt; “New File” -&gt; “R Markdown”, and dialog box will pop up. Change the title to “Lab Assignment 1” and name yourself as author. Select PDF as the Default Output Format, then click OK. The header of your new file should look something like this:\n---\ntitle: \"Lab Assignment 1\"\nauthor: \"Ronald Fisher\"\ndate: \"2024-05-17\"\noutput: pdf_document\n---\n\n\nThe file will initially contain some examples to get you started with RMarkdown, which you should replace with your lab content. Save the notebook as something like “Lab_Assignment_1” using “File” –&gt; “Save As…”\nIn your new .Rmd script, answer the questions in the “Questions” section below. Include all the code you need to produce the requested outputs. Your script should include a top-level section heading for each question, for example:\n# Question 1\n\nstuff here\n\n# Question 2\n\nother stuff\nWhether or not you include the text of the questions in your script is up to you.\n\nDo be sure to include, near the top of your script, a code chunk that loads any non-default packages you use (such as vcdExtra or Sleuth3).\n\nWithin the question sections, you can chunk your code in whatever way seems reasonable. Incorporate any written answers outside the code chunks using Markdown formatting as needed (see “Help” -&gt; “RMarkdown Quick Reference” for text formatting help).\nTo ensure that your .Rmd script will be fully self-contained (i.e. it will not depend on objects that were defined during the lab, and could be run as-is if you sent it to someone else), you should clear the workspace before you begin.\n\nTo clear the workspace, click the broom icon in the Environment pane.\n\nOnce you’ve answered the questions in your new .Rmd script and you have verified your code is self contained, you should Run -&gt; Run All Chunks and generate a .pdf file of your document, to check that everything looks like you want it to. Having concluded that your .Rmd script produces a pdf document that includes all the output you want, submit both the Lab_Assignment_1.Rmd file and the pdf document on Canvas as your Lab Assignment 1.\nFeel free to post on the discussion board if you have any questions or encounter any difficulties with this process."
  },
  {
    "objectID": "z1_learnR.html#questions",
    "href": "z1_learnR.html#questions",
    "title": "1 Types of Categoricals",
    "section": "Questions:",
    "text": "Questions:\n\nQ1.\n\n\n\n\n\n\nProduce a flat table\n\n\n\n\n\nStarting from the case1902 data file in the Sleuth3 package, produce a flat table With Aggravation level as the rows, with Death/NoDeath as the two wide columns that contain Black/White within them. The skeleton of your table should look like:\n\n\n\n.\nDeath\n\nNoDeath\n\n\n\n\n\n.\nBlack\nWhite\nBlack\nWhite\n\n\n1\n.\n.\n.\n.\n\n\n2\n.\n.\n.\n.\n\n\n3\n.\n.\n.\n.\n\n\n4\n.\n.\n.\n.\n\n\n5\n.\n.\n.\n.\n\n\n6\n.\n.\n.\n.\n\n\n\n\n\n\n\n\nlibrary(Sleuth3)\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\ndf &lt;- case1902\n\ndf2 &lt;- df |&gt;  pivot_longer(\n      cols = c(\"Death\", \"NoDeath\"), \n      names_to = \"Sentence\", \n      values_to = \"Freq\", \n      cols_vary = \"slowest\") |&gt; \n  expand.dft()\n\nftable(Sentence + Victim ~ Aggravation, df2)\n\n            Sentence Death       NoDeath      \n            Victim   Black White   Black White\nAggravation                                   \n1                        1     2     181    60\n2                        1     2      21    15\n3                        2     6       9     7\n4                        2     9       4     3\n5                        4     9       3     0\n6                        4    17       0     0\n\n\n\n\nQ2.\n\n\n\n\n\n\nCreate a mosaic plot of the flat table\n\n\n\n\n\n\nCreate a mosaic plot of the flat table you produced in question 1.\nAre there problems with your plot?\nIs it easy to understand?\n\nYou are welcome to play around with making it more interpretable and/or visually appealing, but that’s optional for this assignment.\n\n\n\n\nAnswer\n\nftable(Sentence + Victim ~ Aggravation, df2)\n\n            Sentence Death       NoDeath      \n            Victim   Black White   Black White\nAggravation                                   \n1                        1     2     181    60\n2                        1     2      21    15\n3                        2     6       9     7\n4                        2     9       4     3\n5                        4     9       3     0\n6                        4    17       0     0\n\n\n\nmosaic(Sentence + Victim ~ Aggravation, df2)\n\n\n\n\n\n\n\n\n\nflat_table &lt;- xtabs(~ Aggravation + Victim + Sentence, df2)%&gt;%\n  prop.table(margin = c(2, 3)) %&gt;% \n  aperm(c(3,2,1)) %&gt;% \n  structable(direction = c(\"v\",\"v\",\"h\"))\n\n\nmosaic(flat_table)"
  },
  {
    "objectID": "z1_learnR.html#b",
    "href": "z1_learnR.html#b",
    "title": "1 Types of Categoricals",
    "section": "b",
    "text": "b\nBlack/White, Death NoDeath are easy to understand, but Aggravation isn’t. At least it isn’t apparant what that means."
  },
  {
    "objectID": "z1_learnR.html#c",
    "href": "z1_learnR.html#c",
    "title": "1 Types of Categoricals",
    "section": "c",
    "text": "c\nI think the plot is easy to read, with the exception that I don’t know what aggravation means."
  },
  {
    "objectID": "z3_learnR.html",
    "href": "z3_learnR.html",
    "title": "3 Log-Reg",
    "section": "",
    "text": "In the previous lab, we introduced some simple statistical inference procedures for analyzing data in contingency tables. These procedures were “randomization-based,” in that they involved either directly constructing a randomization distribution of the data under a hypothesis of complete independence between two variables or approximating such a randomization distribution.\nIn most real data analysis situations, we will want to ask and answer more sophisticated questions than “are any variables related to any others.” We may have research questions like “how does the relationship between X and Y depend on the changing level of Z?” Or, “How do the odds of success change when we increase the value of a certain explanatory variable?” In these situations, we will need to move beyond randomization methods and begin using statistical models for categorical responses.\nAs you will see in this lab, modeling categorical responses with statistical methods designed for continuous ones can go sideways almost immediately, so we will use new approaches Such as generalized linear models, of which logistic regression is a special case.\nPlease run the following chunk of R code to load the packages we will use for this lab.\n\n\nCode\nlibrary(vcdExtra)\nlibrary(tidyverse)\nlibrary(magrittr)"
  },
  {
    "objectID": "z3_learnR.html#exploration",
    "href": "z3_learnR.html#exploration",
    "title": "3 Log-Reg",
    "section": "Exploration",
    "text": "Exploration\nThe variable age is continuous, the response survived is binary, and so far, we don’t have any tools for that situation. When all you have is a chi-square test, everything looks like a contingency table, and if we just collapse age away, we can produce a familiar 2x2 table of counts:\n\n\nCode\n(tbl1 &lt;- xtabs(data = Donner, ~ sex + survived))\n\n\n        survived\nsex       0  1\n  Female 10 25\n  Male   32 23\n\n\nAnd see the proportions surviving in each sex\n\n\nCode\nprop.table(tbl1, margin = 1) %&gt;% round(2)\n\n\n        survived\nsex         0    1\n  Female 0.29 0.71\n  Male   0.58 0.42\n\n\nOf the original 55 males, 42% survived, and of the original 35 females, 71% survived,\n\n\nCode\nchisq.test(tbl1)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  tbl1\nX-squared = 6.392, df = 1, p-value = 0.01146\n\n\nand the p-value for the difference in survival by sex is fairly small (but remember that a p-value doesn’t really make sense here without a population to point to).\nFrom the proportions, we can get the odds of survival for males and females, respectively:\n\n\nCode\n(male_odds &lt;- 0.42/0.58)\n\n\n[1] 0.7241379\n\n\nCode\n(female_odds &lt;- 0.71/0.29)\n\n\n[1] 2.448276\n\n\nAnd the odds ratio for survival by sex:\n\n\nCode\n(mf_odds_ratio &lt;- male_odds/female_odds)\n\n\n[1] 0.2957746\n\n\nIgnoring age, the odds of survival for males is 30% of the odds of survival for females.\nWe really don’t want to base any conclusions on this simple aggregation, however we actually do want to use the information about the continuous variable age, and the relationship between sex and survival may be different at different age values. Let’s see how we might proceed treating age as continuous.\n\nLooking at the Data\nIf you looked at Module 1 Lab 0, you already saw a plot of the Donner Party data. Let’s look at a similar plot:\n\n\nCode\nggplot(data=Donner,aes(age,survived,color=sex,shape=sex)) + geom_point()\n\n\n\n\n\n\n\n\n\nAlso, remember that in Lab 0, we showed you these data with some jitter added so that the overlapping points are given a little separation. Here is the plot with jitter:\n\n\nCode\nggplot(data = Donner) + \n # plot jittered data\n geom_jitter(aes(x = age, \n         y = survived,\n         color = sex,\n         shape = sex),\n       height = 0.05, width = 0.2)\n\n\n\n\n\n\n\n\n\nIt’s still not at all obvious what’s going on here. You can see from this jittered version of the plot that there do seem to be a higher proportion of females that survived than males (survived == 1 corresponds to survival), and maybe that there was a “sweet spot” in terms of the ages of the females that survived (i.e., between the ages of about 5 and 35, it looks like most of the females survived)."
  },
  {
    "objectID": "z3_learnR.html#the-logit-transformation",
    "href": "z3_learnR.html#the-logit-transformation",
    "title": "3 Log-Reg",
    "section": "The Logit Transformation",
    "text": "The Logit Transformation\nWe will use the logit (or “log-odds”) function to link the probabilities to the linear combination of predictors. The logit function looks like this:\n\\[\\mathrm{logit}(p) = \\log(p/(1-p))\\]\n\n\nCode\nlogit &lt;- function(p){log(p/(1-p))}\n\n\nThis is a smooth, invertible function from the \\([0,1]\\) interval to the whole real line, \\((-\\infty,\\infty)\\). Plug in a probability, get the (natural) log of the odds. You can see this transformation, as well as the probability to odds transformation, compared in the plot below. The probability to odds transformation takes us from \\([0,1]\\) to \\([0,\\infty)\\), and the log transformation of that takes us from \\([0,\\infty)\\) to \\((-\\infty,\\infty)\\).\nThe y-axis on the plot below ranges only from \\([-3, 3]\\), but remember that the odds function is actually defined all the way from 0 to \\(\\infty\\), and the logit ranges all the way from \\(-\\infty\\) to \\(\\infty\\). The identity transformation, \\(f(p) = p\\), is included for reference.\n\n\nCode\nprob &lt;- seq(0.05, 0.95, length = 100) # restricting the range of probabilities shown in order to keep the transformed values finite.  \nodds &lt;- prob/(1-prob)\nlogits &lt;- log(odds)\ntransformations &lt;- data.frame(identity = prob, odds, logits) %&gt;% gather() %&gt;% rename(transform_function = key)\nggplot(data = transformations, aes(x = rep(prob, 3), y = value, color = transform_function)) + \n scale_y_continuous(limits = c(-3, 3), breaks = c(-3:3)) + \n geom_line() + \n geom_hline(yintercept = 0, lty = 2) + \n geom_vline(xintercept = 0.5, lty = 2) + \n xlab(\"original probabilities\") +\n ylab(\"transformed values\") + \n ggtitle(\"Possible transformations\n     from probability scale\")\n\n\n\n\n\n\n\n\n\nThe logit is not the only invertible transformation from the probability interval to the entire real line, but it has several desirable properties.\nFrom this plot, we can see that probabilities greater than 1/2 are mapped to positive logits and probabilities less than 1/2 are mapped to negative logits (remember \\(p = 1/2 =&gt; odds = 1 =&gt; \\log(odds) = 0\\)) so the sign of the logit of a probability has a straightforward interpretation if the log-odds is positive, the event is more likely than not to occur.\nIn the context of our Donner problem, we can apply the logit function to the survival probability to get a new logistic regression model that might work better than the linear probability model we tried before. We’ll write the new model as:\n\\[\n\\mathrm{logit}(P(Survived|Sex, Age)) = \\beta_0 + \\beta_1Age + \\beta_2Sex + \\beta_3Age \\times Sex\n\\]\nThat is, a non-linear function of survival probability is equal to the linear predictor.\nThe inverse of the logit function is called the logistic function. It looks like this:\n\\[\nf(x) = (e^x)/(1 + e^x)\n\\]\n\n\nCode\nlogistic &lt;- function(x){exp(x)/(1 + exp(x))}\n\n\nThe logit and logistic function are inverses in the same way that the log and exponential functions are inverses:\n\n\nCode\np &lt;- 0.7 # Start with a probability p\n(lp &lt;- logit(p))\n## [1] 0.8472979\nlogistic(lp) # Recover the original p\n## [1] 0.7\n\nx &lt;- -17 # Start with any real number\n(lx &lt;- logistic(x))\n## [1] 4.139938e-08\nlogit(lx) # Recover the original x\n## [1] -17\n\n\nApplying the logistic function to both sides of the model equation gives another equivalent way to write the model: \\[P(Survived|Sex, Age) = logistic(\\beta_0 + \\beta_1Age + \\beta_2Sex + \\beta_3Age \\times Sex)\\] Hence the name “logistic regression”. Now we have survival probability on it’s own, but it’s equal to nonlinear function of the linear predictor.\nWe could also pull out the log from the logit (log-odds), and write the model as\n\\[odds(Survived|Sex, Age) = \\exp{(\\beta_0 + \\beta_1Age + \\beta_2Sex + \\beta_3Age \\times Sex)}\\]\nThis leads to a useful interpretation. To see this, let’s drop back to a simpler logistic regression model with one predictor \\(X\\) and a binary response \\(Y\\), where \\(p = P(Y = 1)\\). The equation for this simple model is\n\\[\\log(p/(1 - p)) = \\beta_0 + \\beta_1X\\]\nif we exponentiate both sides to get back to the odds scale, we have\n\\[p/(1-p) = e^{\\beta_0 + \\beta_1X}\\]\nLet’s sort out what happens to \\(\\log(p/(1-p))\\) when \\(X\\) changes by one:\n\\([\\beta_0 + \\beta_1(X+1)] - [\\beta_0 + \\beta_1X] = \\beta_1\\)\nSo a one-unit increase in \\(X\\) corresponds to a \\(\\beta_1\\)-unit change in the log odds. And, because we can exponentiate both sides, a one-unit increase in \\(X\\) corresponds to a multiplicative change of \\(e^{\\beta_1}\\). You already saw this result for the Donner Party data from the Sleuth3 library, and we’ll give another example of interpreting logistic regression coefficients later in this lab."
  },
  {
    "objectID": "z3_learnR.html#fitting-the-binary-logistic-regression-model",
    "href": "z3_learnR.html#fitting-the-binary-logistic-regression-model",
    "title": "3 Log-Reg",
    "section": "Fitting the Binary Logistic Regression Model",
    "text": "Fitting the Binary Logistic Regression Model\nYou already saw an R demonstration of the logistic regression model fit to the Donner Party data from the Sleuth3 package. Let’s look at the model fit to the full Donner Party dataset in R:\n\n\nCode\nglm1 = glm(survived ~ sex * age, family = binomial(link = \"logit\"), data = Donner)\nsummary(glm1)\n\n\n\nCall:\nglm(formula = survived ~ sex * age, family = binomial(link = \"logit\"), \n    data = Donner)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  1.85515    0.67108   2.764   0.0057 **\nsexMale     -1.62177    0.82673  -1.962   0.0498 * \nage         -0.04565    0.02480  -1.841   0.0657 . \nsexMale:age  0.01957    0.03120   0.627   0.5305   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 124.37  on 89  degrees of freedom\nResidual deviance: 110.73  on 86  degrees of freedom\nAIC: 118.73\n\nNumber of Fisher Scoring iterations: 4\n\n\nIt doesn’t look like the interaction term, sexMale:age is needed, so we’ll refit the model without it, and use that model to examine a few things and make interpretations.\n\n\nCode\nglm2 &lt;- glm(survived ~ sex + age, family = binomial(link = \"logit\"), data = Donner)\nsummary(glm2)\n\n\n\nCall:\nglm(formula = survived ~ sex + age, family = binomial(link = \"logit\"), \n    data = Donner)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   1.5992     0.5041   3.172  0.00151 **\nsexMale      -1.2068     0.4790  -2.519  0.01176 * \nage          -0.0338     0.0151  -2.238  0.02525 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 124.37  on 89  degrees of freedom\nResidual deviance: 111.13  on 87  degrees of freedom\nAIC: 117.13\n\nNumber of Fisher Scoring iterations: 4\n\n\nIn the same way that we examined the (poor) fit of the multiple linear regression model above, let’s examine the (better) fit of this logistic regression model and see what we notice:\n\n\nCode\n# Obtain 95% pointwise confidence bands from predict.glm()\nglm_pred &lt;- predict.glm(glm2, type=\"link\", se.fit=TRUE)\nlow &lt;- glm_pred$fit - 1.96 * glm_pred$se.fit\nupp &lt;- glm_pred$fit + 1.96 * glm_pred$se.fit\n\n# back-transform everything to the data scale\nglm_fit &lt;- logistic(glm_pred$fit)\nglm_lower &lt;- logistic(low)\nglm_upper &lt;- logistic(upp)\n\n# augment the Donner data frame\naugment_Donner &lt;- as.data.frame(cbind(Donner, glm_fit, glm_lower, glm_upper))\n\n# Big plot\nggplot(data = augment_Donner) + \n # plot jittered data\n geom_jitter(aes(x = age, \n         y = survived,\n         color = sex,\n         shape = sex),\n         height = 0.05, width = 0.2) + \n \n # plot fitted lines\n geom_line(aes(x = age, \n        y = glm_fit, \n         color = sex)) + \n\n# plot 95% pointwise confidence bands\n geom_ribbon(aes(x = age, \n         fill = sex, \n         ymin = glm_lower, \n         ymax = glm_upper),\n       alpha = 0.2) +\n \n # plot reference lines at 0 and 1 (minimum and maximum possible probabilities)\n \n geom_hline(yintercept = 0, lty = 2, alpha = 0.4) +\n geom_hline(yintercept = 1, lty = 2, alpha = 0.4) +\n facet_grid(.~sex) + \n ggtitle(\"Generalized linear model for Donner Party\")\n\n\n\n\n\n\n\n\n\nIn this plot, we show the fitted line for both males and females, and the 95% confidence bands for both. Just like our confidence bands from the linear model we fit before, these are pointwise confidence bands. They do not represent 95% confidence that the band contains the entire survival curve, only 95% confidence that the survival probability is within the band at each individual point.\nSimultaneous confidence bands for curves are much more theoretically challenging to construct than pointwise bands, but intuitively, a 95% simultaneous confidence band for the whole curve would be wider than the 95% pointwise band shown here. As explained above, prediction intervals do not make sense in principle for binary data, so we do not calculate any from this model.\nBinary logistic regression models can be used as classifiers where a new combination of explanatory information is mapped to a 0 or a 1. Recall from Data Analytics I that a prediction from a multiple linear regression model is our best guess at a new observation from a Normal population distribution, conditioned on specific, known values for the explanatory variables.\nIn the present case, a prediction should be our best guess at a new observation (i.e., survived or died) from a binary distribution, conditioned on an age and a sex for a new individual (supposing we didn’t already know the survival status of all the possible Donner Party members). The predictive distribution for a new observation at each point is Bernoulli(p), where p is the fitted probability at the specific values of the new combination of explanatory information. Obtaining a new prediction at a given setting of the predictor variables involves either drawing from this Bernoulli distribution, or setting a probability threshold (typically 1/2) and predicting a value of 1 if the fitted probability exceeds the threshold, 0 otherwise. For example, you could predict that a man like Jacob Donner, age 65, would not survive according to the 1/2 probability threshold:\n\n\nCode\nlike_Jacob_Donner &lt;- data.frame(age = 65, sex = \"Male\")\nlike_Jacob_Donner$age %&lt;&gt;% as.numeric()\n# fitted probability that a 65 year old man would survive\npredict(glm2, newdata = like_Jacob_Donner, type = \"response\")\n\n\n       1 \n0.141301 \n\n\nIt’s really important to notice that neither the fitted lines nor the 95% pointwise confidence bands go outside the horizontal band given by the y = 0 and y = 1 lines. This is what we should expect, a much more satisfactory result from the logistic regression model than from the multiple linear regression model. Conceptually, this is because the logistic regression model is designed for modeling data such as those in the Donner Party example, where the response variable is binary. Mathematically, it is because the logistic function that maps the fitted values and confidence bounds back from the log-odds scale to the probability scale is only capable of outputting values between 0 and 1."
  },
  {
    "objectID": "z3_learnR.html#assessing-model-fit",
    "href": "z3_learnR.html#assessing-model-fit",
    "title": "3 Log-Reg",
    "section": "Assessing Model Fit",
    "text": "Assessing Model Fit\nIn the case of binary responses, it’s not necessary or even all that meaningful to examine residuals. Since the only response values are 0’s and 1’s, and the fitted values (once we back transform to the data scale) are probabilities, there is not a wide range of possible values for the residuals and they tend to be not very informative.\nIn the case of the Donner Party data, and as you can see from the plot above, the model fit is not terrific. For example, the model did not seem to pick up the “sweet spot” we noted earlier, females between the ages of about 5 and 25 seem to have all survived. Perhaps a more curvy or wiggly function would provide a better fit? Consider the following plot:\n\n\nCode\nggplot(data = augment_Donner) + \n # plot jittered data\n geom_jitter(aes(x = age, \n         y = survived,\n         color = sex,\n         shape = sex),\n         height = 0.05, width = 0.2) + \n \n # plot loess smoother\n geom_smooth(aes(x = age, \n        y = survived,\n         color = sex)) + \n \nfacet_grid(.~sex) + \n ggtitle(\"Loess Smooth for Donner Party\")\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe loess smoother that ggplot() used to fit a line and plot confidence bands is called a non-parametric scatterplot smoother. It does seem that these non-monotonic wiggly lines do a better job of modeling survival probability as a function of age, although both the fitted line and 95% confidence bands go outside of the 0 and 1 boundaries, which is troubling.\nUnfortunately, the details of loess and other non-parametric approaches are beyond the scope of this class. A big drawback to this non-parametric model fit, however, is that we can’t make any inferences about the relationships among age, sex and survival from it. That is, all we have is the plot above and a wiggly fitted line which we could use to make predictions. For all our talk about the process of making predictions from a logistic regression model, we can’t actually make much use of a purely predictive model for these particular data whose survival are we to predict, anyway?!\nInstead, we’ll go back to our imperfect logistic regression model and make inferences about the relationships among sex, age and survival using that model. There’s a famous quote, attributed to George Box (1919-2013), a well-respected British statistician who spent a large part of his academic career in the US:\n\n“All models are wrong, but some are useful.”\n\nThis is certainly the case with our logistic regression model. It may not be the “correct” model, or even the “best” one for the Donner Party data (you might try adding a quadratic term in age and see if that looks better than either of the preceding approaches). Nevertheless, we can use it to make some useful statements about the data."
  },
  {
    "objectID": "z3_learnR.html#interpreting-the-fitted-model",
    "href": "z3_learnR.html#interpreting-the-fitted-model",
    "title": "3 Log-Reg",
    "section": "Interpreting The Fitted Model",
    "text": "Interpreting The Fitted Model\nLet’s look again at the summary information from the logistic regression model we fit:\n\n\nCode\nsummary(glm2)\n\n\n\nCall:\nglm(formula = survived ~ sex + age, family = binomial(link = \"logit\"), \n    data = Donner)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   1.5992     0.5041   3.172  0.00151 **\nsexMale      -1.2068     0.4790  -2.519  0.01176 * \nage          -0.0338     0.0151  -2.238  0.02525 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 124.37  on 89  degrees of freedom\nResidual deviance: 111.13  on 87  degrees of freedom\nAIC: 117.13\n\nNumber of Fisher Scoring iterations: 4\n\n\nIt appears that both age and sex are important for helping us to understand the odds of survival using this model. Since sexMale is an indicator function, we can write the fitted model in two parts, one for females:\n\\(log(odds of survival) = 1.60 - 0.03age\\)\nAnd one for males:\n\\(log(odds of survival) = 0.39 - 0.03age\\)\nIn this second sub-model, 0.3924 = 1.5992 - 1.2068, and we rounded to the hundredths to get 0.39.\nIt’s from these model fits that we can obtain some estimate of the relative odds of survival for men and women of the same age. As you saw in the narrated lecture materials, because there’s no interaction term in this model, we can just exponentiate the coefficient on sexMale (-1.2068) and obtain an estimate of the multiplicative difference in odds of survival for a male and female of the same age. We can also exponentiate the upper and lower bounds of the 95% confidence interval for the regression coefficient on sexMale.\n\n\nCode\nexp(-1.2068)\n\n\n[1] 0.299153\n\n\nCode\nexp(confint(glm2))\n\n\nWaiting for profiling to be done...\n\n\n                2.5 %     97.5 %\n(Intercept) 1.9486563 14.3550499\nsexMale     0.1128658  0.7481205\nage         0.9367677  0.9945734\n\n\nThe odds of survival for a male are estimated to be roughly 30% of the odds of survival for a female, when comparing individuals of the same age (remember this is exactly the result we got from the contingency table when we ignored age, because in our final logistic regression model we’ve decided not to include any interaction between age and sex). A 95% confidence interval for this multiplicative difference runs from 11% to 75%.\nYou can also use the logistic back-transformation to make a comparison in terms of the probability of survival:\n\n\nCode\nlogistic(-1.2068)\n## [1] 0.2302677\nci &lt;- confint(glm2)\n## Waiting for profiling to be done...\nlogistic(ci)\n##                 2.5 %    97.5 %\n## (Intercept) 0.6608625 0.9348748\n## sexMale     0.1014191 0.4279571\n## age         0.4836758 0.4986397\n\n\nThe probability of survival for a male is estimated to be 0.23 lower than that of a female, when comparing two individuals of the same age. A 95% confidence interval for this (additive) difference runs from 0.10 to 0.43."
  },
  {
    "objectID": "z3_learnR.html#data-scale-vs-model-scale-back-transformation",
    "href": "z3_learnR.html#data-scale-vs-model-scale-back-transformation",
    "title": "3 Log-Reg",
    "section": "Data Scale vs Model Scale, Back-transformation",
    "text": "Data Scale vs Model Scale, Back-transformation\nNotice that the two interpretations just given are both on back-transformed scales. In general, people have a better appreciation for and understanding of probabilities and odds than they do (have) of log-odds.\n\nThe logistic regression model is fit on the log-odds scale. We call this the model scale. When we back-transform to probabilities, we get back to the data scale (i.e., the same scale as the data).\n\nThe odds scale is intermediate between the the data scale and the model scale, and it affords another option for how we interpret and communicate the results of a logistic regression model."
  },
  {
    "objectID": "z3_learnR.html#model",
    "href": "z3_learnR.html#model",
    "title": "3 Log-Reg",
    "section": "Model",
    "text": "Model\n\n\nCode\ndf &lt;- ResumeNames |&gt; select(call, college, reqeduc, industry, experience) |&gt; \n  mutate(call = as.integer(ifelse(call == \"yes\", 1, 0)))\n\nmod1 &lt;- glm(call ~ experience + college, \n            family = binomial(link = \"logit\"), \n            data = df)\n\nsummary(mod1)\n\n\n\nCall:\nglm(formula = call ~ experience + college, family = binomial(link = \"logit\"), \n    data = df)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.720539   0.128876 -21.110  &lt; 2e-16 ***\nexperience   0.038896   0.009182   4.236 2.27e-05 ***\ncollegeyes  -0.052563   0.116189  -0.452    0.651    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2726.9  on 4869  degrees of freedom\nResidual deviance: 2710.0  on 4867  degrees of freedom\nAIC: 2716\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\nCode\nmod1$coefficients |&gt; exp()\n\n\n(Intercept)  experience  collegeyes \n 0.06583927  1.03966205  0.94879423 \n\n\n\n\nCode\nCI &lt;- confint.default(mod1)\nCI\n##                  2.5 %      97.5 %\n## (Intercept) -2.9731304 -2.46794731\n## experience   0.0208992  0.05689221\n## collegeyes  -0.2802904  0.17516373\nexp(CI)\n##                  2.5 %     97.5 %\n## (Intercept) 0.05114296 0.08475866\n## experience  1.02111912 1.05854171\n## collegeyes  0.75556430 1.19144128"
  },
  {
    "objectID": "z3_learnR.html#interpretting",
    "href": "z3_learnR.html#interpretting",
    "title": "3 Log-Reg",
    "section": "Interpretting",
    "text": "Interpretting\nThe model is:\n\\[\n\\hat{logit}(odds_{call}) = -2.72 + 0.039 Experience - 0.053 College\n\\]\nLogit is log odds:\n\\[\nlogit(p) = log(\\frac{p}{1-p}) = -2.72 + 0.039 Exp - 0.053 Col\n\\]\nIf we exp(logit) we get odds.\n\\[\nOdds = e^{(-2.72 + 0.039 Exp - 0.053 Col)}\n\\] Odds are:\n\\[\nOdds = \\frac{p}{1-p}\n\\]\nP is:\n\\[\np = Odds \\times (1-p) = Odds- Odds\\times p\n\\] \\[\np + pOdds = Odds\n\\] \\[\np = \\frac{Odds}{1+Odds}\n\\]"
  },
  {
    "objectID": "z3_learnR.html#odds",
    "href": "z3_learnR.html#odds",
    "title": "3 Log-Reg",
    "section": "Odds",
    "text": "Odds\nSetting up a function to compute the odds and probabilities.\n\n\nCode\nmod1$coefficients\n## (Intercept)  experience  collegeyes \n## -2.72053887  0.03889571 -0.05256333\no &lt;- exp(mod1$coefficients)\np &lt;- o/(1+o)\no\n## (Intercept)  experience  collegeyes \n##  0.06583927  1.03966205  0.94879423\np*100\n## (Intercept)  experience  collegeyes \n##    6.177223   50.972270   48.686219\n\n\n\n\nCode\n# Checking my math below. \n0.06583927 + 0.94879423\n\n\n[1] 1.014633\n\n\n\n\nCode\nex &lt;- 0\ncol &lt;- 0\n\nodds &lt;- exp(-2.720539) + ex * exp(0.038896) + col * exp(-0.052563)\nodds\n## [1] 0.06583926\n\ncol &lt;- 1\nodds &lt;- exp(-2.720539) + ex * exp(0.038896) + col * exp(-0.052563)\nodds\n## [1] 1.014634\n\n# exp(logt) != odds\n\n\n\n\nCode\nodds_call &lt;- function(col, ex) {\n  odds &lt;- exp(-2.720539) + ex * exp(0.038896) + col * exp(0.052563)\n  odds\n}\n\nprob_call &lt;- function(col, ex) { \n  odds &lt;- exp(-2.720539) + ex * exp(0.038896) + col * exp(0.052563)\n  p &lt;- odds/(1 + odds)\n  p\n}"
  },
  {
    "objectID": "z3_learnR.html#plotting-the-odds-by-experience",
    "href": "z3_learnR.html#plotting-the-odds-by-experience",
    "title": "3 Log-Reg",
    "section": "Plotting the odds by experience",
    "text": "Plotting the odds by experience\n\n\nCode\nodds_w_col &lt;- odds_call(col = 1, ex = 0:20)\nodds_wo_col &lt;- odds_call(col = 0, ex = 0:20)\n\n\nd &lt;- data.frame(\n  col = odds_w_col, \n  nocol = odds_wo_col, \n  years = 0:20\n)\n\nd2 &lt;- d |&gt; pivot_longer(cols = c('col', 'nocol'),\n  names_to = \"Coll\", values_to = \"Odds\")\n\nggplot(d2) + \n  aes(x = years, y = Odds, color = Coll) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(title = \"Odds of a call back by years of experiece\", \n       subtitle = \"For applicants with and without college degrees over 20 years of experience\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCode\nodds_wo_col[1] - odds_w_col[1]\n## [1] -1.053969\nodds_wo_col[20] - odds_w_col[20]\n## [1] -1.053969"
  },
  {
    "objectID": "z3_learnR.html#plotting-probability-by-experience.",
    "href": "z3_learnR.html#plotting-probability-by-experience.",
    "title": "3 Log-Reg",
    "section": "Plotting Probability by experience.",
    "text": "Plotting Probability by experience.\n\n\nCode\ndf &lt;- ResumeNames |&gt; select(call, college, reqeduc, industry, experience) |&gt; \n  mutate(call = as.integer(ifelse(call == \"yes\", 1, 0)))\n\nmod1 &lt;- glm(call ~ experience + college, \n            family = binomial(link = \"logit\"), \n            data = df)\n\nlogistic &lt;- function(x){exp(x)/(1 + exp(x))}\n\n# Obtain 95% pointwise confidence bands from predict.glm()\nglm_pred &lt;- predict.glm(mod1, type=\"link\", se.fit=TRUE)\nlow &lt;- glm_pred$fit - 1.96 * glm_pred$se.fit\nupp &lt;- glm_pred$fit + 1.96 * glm_pred$se.fit\n\n# back-transform everything to the data scale\nglm_fit &lt;- logistic(glm_pred$fit)\nglm_lower &lt;- logistic(low)\nglm_upper &lt;- logistic(upp)\n\n# augment the Donner data frame\naugment_df &lt;- as.data.frame(cbind(df, glm_fit, glm_lower, glm_upper))\n\n\n# Big plot\nggplot(data = augment_df) + \n # plot jittered data\n geom_jitter(aes(x = experience, \n         y = call,\n         color = college),\n         height = 0.05, width = 0.2) + \n \n # plot fitted lines\n geom_line(aes(x = experience, \n        y = glm_fit, \n         color = college)) + \n\n# plot 95% pointwise confidence bands\n geom_ribbon(aes(x = experience, \n         fill = college, \n         ymin = glm_lower, \n         ymax = glm_upper),\n       alpha = 0.2) +\n \n\n  \n   # plot reference lines at 0 and 1 (minimum and maximum possible probabilities)\n \n geom_hline(yintercept = 0, lty = 2, alpha = 0.4) +\n geom_hline(yintercept = 1, lty = 2, alpha = 0.4) +\n facet_grid(.~college) +\n ggtitle(\"Generalized linear model for df\")"
  },
  {
    "objectID": "z5_learnR.html#some-data-exploration",
    "href": "z5_learnR.html#some-data-exploration",
    "title": "5 Log Lin Reg",
    "section": "Some data exploration",
    "text": "Some data exploration\nWe’ll start with some exploration of the data.\n\nggplot(data = salamanders, aes(x = PctCover, y = Salamanders)) + geom_point() + ggtitle(\"Salamanders vs Percent Cover\")\n\n\n\n\n\n\n\n\nThis first figure seems to indicate that there are two distinct types of sites those with PctCover below about 53% and those with PctCover greater than 75%. It also seems clear that only sites with PctCover greater than 75% have Salamander counts higher than 2.\nHere’s another plot:\n\nggplot(data = salamanders, aes(x = ForestAge, y = Salamanders)) + geom_point() + ggtitle(\"Salamanders vs Forest Age\")\n\n\n\n\n\n\n\n\nThere doesn’t appear to be anything remarkable about this plot, though it’s important to notice the range of the x-axis scale – it’s fairly large. This suggests that we might observe something more informative if we look at ForestAge on the log scale.\n\nggplot(data = salamanders, aes(x = log(ForestAge + 1/2), y = Salamanders)) + geom_point() + ggtitle(\"Salamanders vs log(Forest Age)\")\n\n\n\n\n\n\n\n\nNotice that we used x = log(ForestAge + 1/2) in the ggplot() function call because some of the ForestAge values are zero, and log(0) is undefined.\nThis plot seems to indicate a clearer relationship between ForestAge and Salamanders as ForestAge increases on the log scale, the salamander counts tend to increase and they get more variable. Let’s also look at the relationship between the two explanatory variables:\n\n(ggplot(data = salamanders, aes(x = log(ForestAge + 1/2), y = PctCover)) + geom_point() + ggtitle(\"Percent Cover vs log(Forest Age\"))\n\n\n\n\n\n\n\n\nThis plot tells and interesting story almost all of the older sites are those with PctCover greater than 75%. For the younger sites, there is a increasing (perhaps curvilinear) relationship with PctCover.\nRemember that multicollinearity is a problem when two or more explanatory variables are highly correlated. Let’s check the correlation between log-transformed PctCover and the ForestAge variable.\n\nsalamanders %&lt;&gt;% mutate(Site = Site, Salamanders = Salamanders, ForestAge = ForestAge, logPctCover = log(PctCover + 1/2))\ncor(salamanders$ForestAge,salamanders$logPctCover)\n\n[1] 0.5352604\n\n\nThe correlation is not actually so high that we should be concerned about it. Remember, too, that correlation tells us about the linear association between two variables. In terms of a linear association, these two variables are moderately correlated – even though from our last plot we see that there is a strong relationship between them.\nBecause of the distinctive cut-point in the PctForest variable, we’ll create a new variable, called CovGroup, that just takes the value 0 if PctCover &lt; 75) and 1 otherwise.\n\nsalamanders$CovGroup &lt;- ifelse(salamanders$PctCover &lt; 75,0,1)\n\nFinally, as a last bit of exploration, let’s just take a look at the histogram of Salamander counts.\n\nggplot(salamanders,aes(Salamanders)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nYou can see that there are a lot of zeroes in among the Salamander counts. One method for analyzing Poisson count data is to take the log of the counts, and then perform a multiple linear regression. We don’t recommend that here, since there are so many zeroes – you’d have to first add a small amount to the zero counts, then take logs, and that means that interpretations will be difficult.\nInstead, we’ll turn to fitting the log linear model (another special case of a generalized linear model)."
  },
  {
    "objectID": "z5_learnR.html#model-fitting",
    "href": "z5_learnR.html#model-fitting",
    "title": "5 Log Lin Reg",
    "section": "Model Fitting",
    "text": "Model Fitting\nIn this part of the lab, we’ll fit several different models, and make some comparisons among them. This is a little bit of data snooping, and we will likely end up with biased estimates in the model we do select (recall the simulation you saw back in Data Analytics I). So, please, consider this to be the academic exercise it’s intended to be!\n\n# model with PctCover only\npois_mod1 &lt;- glm(data = salamanders, Salamanders ~ PctCover, family = poisson)\n\n# model the log(Forest Age + 1/2) only\npois_mod2 &lt;- glm(data = salamanders, Salamanders ~ log(ForestAge + 1/2), family = poisson)\n\n# model with both explanatory variables\npois_mod3 &lt;- glm(data = salamanders, Salamanders ~ PctCover + log(ForestAge + 1/2), family = poisson)\n\n# model with both explanatory variables, plus their interaction\npois_mod4 &lt;- glm(data = salamanders, Salamanders ~ PctCover * log(ForestAge + 1/2), family = poisson)\n\n# comparison of the models\nLRstats(pois_mod1, pois_mod2, pois_mod3, pois_mod4)\n\n\n\n\n\n\nAIC\nBIC\nLR Chisq\nDf\nPr(&gt;Chisq)\n\n\n\n\npois_mod1\n210.3639\n214.0642\n121.3050\n45\n0\n\n\npois_mod2\n243.1239\n246.8242\n154.0650\n45\n0\n\n\npois_mod3\n212.0690\n217.6195\n121.0101\n44\n0\n\n\npois_mod4\n213.7578\n221.1584\n120.6989\n43\n0\n\n\n\n\n\n\nIn terms of the AIC comparisons, there’s not much difference between models 1, 2 and 4; and the same is true if we use the BIC comparisons. This is somewhat surprising – from the exploratory plots above, you might have suspected that both PctCover and ForestAge, and maybe even their interaction might be important. Let’s take a look at the summary information for pois_mod4.\n\nsummary(pois_mod4)\n\n\nCall:\nglm(formula = Salamanders ~ PctCover * log(ForestAge + 1/2), \n    family = poisson, data = salamanders)\n\nCoefficients:\n                               Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)                   -0.969454   0.820929  -1.181  0.23763   \nPctCover                       0.029067   0.011184   2.599  0.00935 **\nlog(ForestAge + 1/2)          -0.213107   0.293009  -0.727  0.46704   \nPctCover:log(ForestAge + 1/2)  0.001957   0.003423   0.572  0.56741   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 190.22  on 46  degrees of freedom\nResidual deviance: 120.70  on 43  degrees of freedom\nAIC: 213.76\n\nNumber of Fisher Scoring iterations: 5\n\n\nIt looks like there pretty clear evidence of over dispersion, the residual deviance divided by the residual degrees of freedom is\n\n120.7/43\n\n[1] 2.806977\n\n\nThat’s pretty big. Before we talk a lot more about model fitting and model comparison in terms of what explanatory information to include, we should address the over dispersion. Remember that we can do this using the family = quasipoisson argument to the glm() function, or we can do this using the glm.nb function. We’ll leave it to you to try the quasi-poisson approach, and we’ll go over the negative binomial approach here. We’ll simply fit the same four models as above, but using the negative binomial likelihood rather than the Poisson likelihood.\n\n# model with PctCover only\nnb_mod1 &lt;- glm.nb(data = salamanders, Salamanders ~ PctCover)\n\n# model the log(Forest Age + 1/2) only\nnb_mod2 &lt;- glm.nb(data = salamanders, Salamanders ~ log(ForestAge + 1/2))\n\n# model with both explanatory variables\nnb_mod3 &lt;- glm.nb(data = salamanders, Salamanders ~ PctCover + log(ForestAge + 1/2))\n\n# model with both explanatory variables, plus their interaction\nnb_mod4 &lt;- glm.nb(data = salamanders, Salamanders ~ PctCover * log(ForestAge + 1/2))\n\n# comparison of the models\nLRstats(nb_mod1, nb_mod2, nb_mod3, nb_mod4)\n\n\n\n\n\n\nAIC\nBIC\nLR Chisq\nDf\nPr(&gt;Chisq)\n\n\n\n\nnb_mod1\n176.9625\n182.5130\n47.60608\n45\n0.3670830\n\n\nnb_mod2\n188.2859\n193.8363\n47.99615\n45\n0.3523296\n\n\nnb_mod3\n178.8296\n186.2302\n47.56748\n44\n0.3295507\n\n\nnb_mod4\n180.5434\n189.7941\n47.48537\n43\n0.2948841\n\n\n\n\n\n\nAgain, there’s no clear winner here in terms of either AIC or BIC, so we’ll go with Occam’s Razor and look at results for the simplest model, nb_mod1.\n\nsummary(nb_mod1)\n\n\nCall:\nglm.nb(formula = Salamanders ~ PctCover, data = salamanders, \n    init.theta = 1.26199236, link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.416365   0.527696  -2.684  0.00727 ** \nPctCover     0.031513   0.006655   4.735 2.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.262) family taken to be 1)\n\n    Null deviance: 75.691  on 46  degrees of freedom\nResidual deviance: 47.606  on 45  degrees of freedom\nAIC: 176.96\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.262 \n          Std. Err.:  0.478 \n\n 2 x log-likelihood:  -170.963 \n\n\nRemember that we still didn’t use the CovGroup indicator variable that we created above. Let’s fit a couple more models using that variable, and see where we are.\n\n# model with CovGroup only \nnb_mod5 &lt;- glm.nb(data = salamanders, Salamanders ~ CovGroup)\n\n# model with CovGroup*log(ForestAge + 1/2)\nnb_mod6 &lt;- glm.nb(data = salamanders, Salamanders ~ CovGroup * log(ForestAge + 1/2))\n\n# compare with the other models\nLRstats(nb_mod1,nb_mod2,nb_mod3,nb_mod4,nb_mod5,nb_mod6)\n\n\n\n\n\n\nAIC\nBIC\nLR Chisq\nDf\nPr(&gt;Chisq)\n\n\n\n\nnb_mod1\n176.9625\n182.5130\n47.60608\n45\n0.3670830\n\n\nnb_mod2\n188.2859\n193.8363\n47.99615\n45\n0.3523296\n\n\nnb_mod3\n178.8296\n186.2302\n47.56748\n44\n0.3295507\n\n\nnb_mod4\n180.5434\n189.7941\n47.48537\n43\n0.2948841\n\n\nnb_mod5\n176.7513\n182.3018\n47.17214\n45\n0.3838253\n\n\nnb_mod6\n180.7331\n189.9838\n47.16892\n43\n0.3060094\n\n\n\n\n\n\nNow it seems like there’s really not much difference among any of these models (except that many nb_mod2 is a clear-ish loser) in terms of AIC or BIC. We’ll continue with nb_mod1 at this point. Let’s take a look at the model and it’s fit.\n\nsummary(nb_mod1)\n\n\nCall:\nglm.nb(formula = Salamanders ~ PctCover, data = salamanders, \n    init.theta = 1.26199236, link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.416365   0.527696  -2.684  0.00727 ** \nPctCover     0.031513   0.006655   4.735 2.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.262) family taken to be 1)\n\n    Null deviance: 75.691  on 46  degrees of freedom\nResidual deviance: 47.606  on 45  degrees of freedom\nAIC: 176.96\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.262 \n          Std. Err.:  0.478 \n\n 2 x log-likelihood:  -170.963 \n\nsalamanders$resid &lt;- residuals(nb_mod1)\nfits &lt;- predict.glm(nb_mod1,scale=\"data\",se.fit=TRUE)\nsalamanders$fits &lt;- exp(fits$fit)\nsalamanders$low &lt;- exp(fits$fit-1.96*fits$se.fit)\nsalamanders$upp &lt;- exp(fits$fit+1.96*fits$se.fit)\nggplot(salamanders,aes(PctCover,Salamanders)) + geom_point() +      \n  geom_line(aes(x = PctCover, \n                 y = fits)) + \n  geom_ribbon(aes(x = PctCover, \n                  ymin = low, \n                  ymax = upp),\n                  alpha = 0.2)\n\n\n\n\n\n\n\n\nThe model fit is not bad – remember that the solid line in the figure above is the model estimate of the Poisson rate parameter at each value of PctCover, and the shaded bands are 95% pointwise confidence intervals. The model output gives strong evidence of a positive association between PctCover and the number of salamanders at a site.\nNotice also that the residual deviance divided by its degrees of freedom for nb_mod1 is very close to 1. The negative binomial model also gives an estimate of the “Theta” parameter. In the negative binomial model, if the expected count is \\(E(Y)\\), the variance of the count is \\(Var(Y) = E(Y) + [E(Y)^2]/\\theta\\).\nSince the negative binomial model uses the log-link as does the Poisson model, the interpretation of the coefficient on PctCover is the same as in the Poisson model – an increase of 1% in forest cover is associated with an \\(exp(0.0315) = 1.03\\)-fold increase in the expected number of salamanders. In other words, a 1% increase in forest cover is associated with a 3% increase in expected number of salamanders at a site."
  },
  {
    "objectID": "z5_learnR.html#model-evaluation",
    "href": "z5_learnR.html#model-evaluation",
    "title": "5 Log Lin Reg",
    "section": "Model Evaluation",
    "text": "Model Evaluation\nRecall that the deviance goodness of fit test compares a fitted model to a saturated model, or one in which there are as many parameters as there are data points. In these goodness of fit comparisons, the null hypothesis corresponds to the fitted model (which is a reduced model relative to the saturated model), and the alternative hypothesis corresponds to the saturated model. In the case of Poisson counts, the goodness of fit should only be used as a guideline, not as a firm decision making tool.\n\nLRstats(nb_mod1)\n\n\n\n\n\n\nAIC\nBIC\nLR Chisq\nDf\nPr(&gt;Chisq)\n\n\n\n\nnb_mod1\n176.9625\n182.513\n47.60608\n45\n0.367083\n\n\n\n\n\n\nThis large p-value may be an indication of an adequate model, but there are many small counts in the salamanders data, so we should not rely heavily on this result."
  },
  {
    "objectID": "z5_learnR.html#drop-in-deviance-test",
    "href": "z5_learnR.html#drop-in-deviance-test",
    "title": "5 Log Lin Reg",
    "section": "Drop-in-deviance test",
    "text": "Drop-in-deviance test\nJust a reminder that the drop in deviance test is different from the deviance goodness of fit test. Whereas the deviance goodness of fit test provides a comparison between a single fitted model and a saturated model, a drop in deviance test provides a way to compare two fitted models when one of those models is nested within the other one. Put another way, the drop in deviance test is a comparison between a reduced model (null hypothesis) and a full model (alternative hypothesis) – and we use it in cases where the reduced model is reduced from (or nested in) the full model.\nUsing the models we have already fit, let’s use the anova() function to perform a drop in deviance test comparing the model that only contains PctCover to the one that contains PctCover, ForestAge and their interaction.\n\nanova(nb_mod1,nb_mod4,test=\"Chisq\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\ntheta\nResid. df\n2 x log-lik.\nTest\ndf\nLR stat.\nPr(Chi)\n\n\n\n\nPctCover\n1.261992\n45\n-170.9625\n\nNA\nNA\nNA\n\n\nPctCover * log(ForestAge + 1/2)\n1.279151\n43\n-170.5434\n1 vs 2\n2\n0.419181\n0.8109163\n\n\n\n\n\n\nThe p-value of the drop in deviance test is rather large, giving us strong evidence that the simpler model is sufficient in this case, as compared to the more complicated model."
  },
  {
    "objectID": "z5_learnR.html#looking-at-residuals",
    "href": "z5_learnR.html#looking-at-residuals",
    "title": "5 Log Lin Reg",
    "section": "Looking at Residuals",
    "text": "Looking at Residuals\nAs in the case of binomial logistic regression, it can be helpful to look at the deviance and/or Pearson residuals from our negative binomial (or Poisson) regression mode to (a) evaluate the model fit and (b) check for outliers. Provided that the counts are fairly large, both the deviance and Pearson residuals should look like draws from a standard Normal distribution, so too many residuals outside of the [-2,2] interval may be cause for concern. Here, we’ll look at plots of both the deviance and Pearson residuals.\n\nsalamanders$residuals_deviance &lt;- residuals(nb_mod1)\nsalamanders$residuals_pearson &lt;- residuals(nb_mod1, type = \"pearson\")\nggplot(data = salamanders, aes(PctCover,residuals_deviance)) + geom_point()\n\n\n\n\n\n\n\nggplot(data = salamanders, aes(PctCover,residuals_pearson)) + geom_point()\n\n\n\n\n\n\n\nggplot(data = salamanders, aes(residuals_deviance,residuals_pearson)) + geom_point()\n\n\n\n\n\n\n\n\nFirst, you should notice that there are some distinctive patterns in both the deviance and Pearson residual plots. These kinds of patterns are quite common when we are dealing with count data, and they are result of the discreteness of those counts. In these residual plots, we are more concerned with detecting potential outliers, and there do not appear to be any here.\nNext, the plot of the two types of residuals against each other shows the strong relationship between them – in this case it’s not a linear relationship as it was in the case of binomial logistic regression – but it’s a strong relationship nonetheless."
  },
  {
    "objectID": "z5_learnR.html#questions",
    "href": "z5_learnR.html#questions",
    "title": "5 Log Lin Reg",
    "section": "Questions",
    "text": "Questions\n\nexploration\n\nmarriage_tab |&gt; ftable()\n\n                                     opinion Agree Neutral Disagree\neduc                  relig                                        \nHigh school or less   Liberal                   11       5        6\n                      Moderate                   8       3        9\n                      Fundamentalist             6       2       10\nAt least some college Liberal                   22       4        1\n                      Moderate                  21       3        5\n                      Fundamentalist             4       2       11\n\n\nI am assuming the log relationship due to this being the lab for that scenario.\nmarriage |&gt; ggplot() + \n  aes(x = educ, y = log(Freq), color = opinion, shape = relig) + \n  geom_point()  +\n  scale_x_discrete(guide = guide_axis(angle = 90)) \nmarriage |&gt; ggplot() + \n  aes(x = relig, y = log(Freq), color = opinion) + \n  geom_point() + facet_wrap(~educ)\n\n\n\n\n\n\n\n\n\n\nSome college is more spread out than high school, opinions cluster more. There is a single count of Liberal, college, disagree that is a potential outlier. In both sets, disagreement increases as liberal goes to fundamentalist and vice versa, agreement goes down.\nNeutrality decreases as liberal goes to fundamentalist.\n\nmarriage |&gt; ggplot() + \n  aes(x = educ, y = log(Freq), color = opinion) + \n  geom_point()  +\n  scale_x_discrete(guide = guide_axis(angle = 90)) + \n  facet_wrap(~relig)\n\n\n\n\n\n\n\n\nFor college vs religion, among liberals agreement goes up with education, neutrality slightly down. For moderates, it’s the same, but more folks disagree and neutrality might go a little up. For fundamentalists, agreement goes down and disagree up. That is different. Neutrality is roughly the same."
  },
  {
    "objectID": "z5_learnR.html#fit-two-way-interctions.",
    "href": "z5_learnR.html#fit-two-way-interctions.",
    "title": "5 Log Lin Reg",
    "section": "1 fit two way interctions.",
    "text": "1 fit two way interctions.\n\nFit a model to the gay marriage data that includes all two-way interactions. What do you conclude from this model? Be specific and try to address questions having to do with the association among the three variables.\n\n\nfit saturated\nLooking at table.\n\nmarriage_tab |&gt; ftable()\n\n                                     opinion Agree Neutral Disagree\neduc                  relig                                        \nHigh school or less   Liberal                   11       5        6\n                      Moderate                   8       3        9\n                      Fundamentalist             6       2       10\nAt least some college Liberal                   22       4        1\n                      Moderate                  21       3        5\n                      Fundamentalist             4       2       11\n\n\n\nm2 &lt;- glm(data = marriage_tab, \n          family = poisson, \n          Freq~relig*opinion + relig*educ + opinion*educ)\ns2 &lt;- summary(m2)\ns2\n\n\nCall:\nglm(formula = Freq ~ relig * opinion + relig * educ + opinion * \n    educ, family = poisson, data = marriage_tab)\n\nCoefficients:\n                                              Estimate Std. Error z value\n(Intercept)                                     2.5263     0.2649   9.535\nreligModerate                                  -0.3176     0.3779  -0.840\nreligFundamentalist                            -1.3054     0.4838  -2.699\nopinionNeutral                                 -0.9123     0.4562  -2.000\nopinionDisagree                                -1.0287     0.4607  -2.233\neducAt least some college                       0.4938     0.3216   1.535\nreligModerate:opinionNeutral                   -0.2255     0.5911  -0.381\nreligFundamentalist:opinionNeutral              0.4139     0.7069   0.585\nreligModerate:opinionDisagree                   0.8969     0.5412   1.657\nreligFundamentalist:opinionDisagree             2.3377     0.5825   4.013\nreligModerate:educAt least some college         0.2881     0.4250   0.678\nreligFundamentalist:educAt least some college   0.1739     0.4957   0.351\nopinionNeutral:educAt least some college       -0.7272     0.5241  -1.388\nopinionDisagree:educAt least some college      -1.0634     0.4359  -2.440\n                                              Pr(&gt;|z|)    \n(Intercept)                                    &lt; 2e-16 ***\nreligModerate                                  0.40067    \nreligFundamentalist                            0.00697 ** \nopinionNeutral                                 0.04554 *  \nopinionDisagree                                0.02556 *  \neducAt least some college                      0.12467    \nreligModerate:opinionNeutral                   0.70287    \nreligFundamentalist:opinionNeutral             0.55823    \nreligModerate:opinionDisagree                  0.09750 .  \nreligFundamentalist:opinionDisagree              6e-05 ***\nreligModerate:educAt least some college        0.49791    \nreligFundamentalist:educAt least some college  0.72573    \nopinionNeutral:educAt least some college       0.16527    \nopinionDisagree:educAt least some college      0.01469 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 72.3623  on 17  degrees of freedom\nResidual deviance:  6.5821  on  4  degrees of freedom\nAIC: 99.078\n\nNumber of Fisher Scoring iterations: 4\n\n\nIt appears that fundamentalists and opinions about gay marriage are main effects that are associated with variation in the table. Those with at least some college who disagree with gay marriage and Fundamentalists who disagree also appear to account for some variation. Also moderates who disagree could also account for some variation.\n\nconfint(m2)\n\nWaiting for profiling to be done...\n\n\n                                                   2.5 %      97.5 %\n(Intercept)                                    1.9652588  3.00852096\nreligModerate                                 -1.0740121  0.41947706\nreligFundamentalist                           -2.3106386 -0.39824367\nopinionNeutral                                -1.8640548 -0.05379958\nopinionDisagree                               -2.0031444 -0.17037201\neducAt least some college                     -0.1285080  1.14077865\nreligModerate:opinionNeutral                  -1.4293902  0.92350177\nreligFundamentalist:opinionNeutral            -1.0566124  1.77303287\nreligModerate:opinionDisagree                 -0.1375381  2.00722939\nreligFundamentalist:opinionDisagree            1.2442200  3.54536159\nreligModerate:educAt least some college       -0.5423790  1.13070428\nreligFundamentalist:educAt least some college -0.7922154  1.16236149\nopinionNeutral:educAt least some college      -1.7733304  0.30270736\nopinionDisagree:educAt least some college     -1.9388926 -0.22115922\n\n\nThe 95% confidence intervals for the coefficients of the interaction terms that include zero are:\n\nreligModerate:opinionNeutral\nreligModerate:opinionDisagree\nreligModerate:educAt least some college\nreligFundamentalist:opinionNeutral\nreligFundamentalist:educAt least some college\nopinionNeutral:educAt least some college\n\nreligModerate:opinionNeutral -1.4293902 0.92350177 religFundamentalist:opinionNeutral -1.0566124 1.77303287 religModerate:opinionDisagree -0.1375381 2.00722939 religFundamentalist:opinionDisagree 1.2442200 3.54536159 religModerate:educAt least some college -0.5423790 1.13070428 religFundamentalist:educAt least some college -0.7922154 1.16236149 opinionNeutral:educAt least some college -1.7733304 0.30270736 opinionDisagree:educAt least some college -1.9388926 -0.22115922\nI am interpreting these to mean that there are no interactions between these terms. The following groups are independent of each other:\n\nReligious moderates and neutrality\nReligious fundamentalists and neutrality\nReligious moderates and disagreeing\nReligious moderates and college\nReligious fundamentalists and At least some college\nAt least some college and Neutrality\n\n\nmarriage |&gt; ggplot() + \n  aes(x = educ, y = log(Freq), color = opinion, size = Freq) + \n  geom_point()  +\n  scale_x_discrete(guide = guide_axis(angle = 90)) + \n  facet_wrap(~relig)\n\n\n\n\n\n\n\n\nIf we are considering opinion the response, it looks to me like the major interaction here is fundamentalists and college. With the exception of fundamentalists, college tends to result in mostly increasing agreement. However, that is not the case for fundamentalists."
  },
  {
    "objectID": "z5_learnR.html#fit-three-way-interactions.",
    "href": "z5_learnR.html#fit-three-way-interactions.",
    "title": "5 Log Lin Reg",
    "section": "2 fit three way interactions.",
    "text": "2 fit three way interactions.\n\nFit a model that includes all two-way and the three-way interactions. Is there anything problematic about this model? Please explain.\n\n\n# m2 &lt;- glm(data = marriage_tab, \n#           family = poisson, \n#           Freq~relig*opinion + relig*educ + opinion*educ)\n# s2 &lt;- summary(m2)\n# s2\n\nm3 &lt;- glm(data = marriage_tab, \n          family = poisson, \n          Freq~relig*opinion*educ)\ns3 &lt;- summary(m3)\ns3\n\n\nCall:\nglm(formula = Freq ~ relig * opinion * educ, family = poisson, \n    data = marriage_tab)\n\nCoefficients:\n                                                              Estimate\n(Intercept)                                                    2.39790\nreligModerate                                                 -0.31845\nreligFundamentalist                                           -0.60614\nopinionNeutral                                                -0.78846\nopinionDisagree                                               -0.60614\neducAt least some college                                      0.69315\nreligModerate:opinionNeutral                                  -0.19237\nreligFundamentalist:opinionNeutral                            -0.31015\nreligModerate:opinionDisagree                                  0.72392\nreligFundamentalist:opinionDisagree                            1.11696\nreligModerate:educAt least some college                        0.27193\nreligFundamentalist:educAt least some college                 -1.09861\nopinionNeutral:educAt least some college                      -0.91629\nopinionDisagree:educAt least some college                     -2.48491\nreligModerate:opinionNeutral:educAt least some college        -0.04879\nreligFundamentalist:opinionNeutral:educAt least some college   1.32176\nreligModerate:opinionDisagree:educAt least some college        0.93204\nreligFundamentalist:opinionDisagree:educAt least some college  2.98568\n                                                              Std. Error\n(Intercept)                                                      0.30151\nreligModerate                                                    0.46466\nreligFundamentalist                                              0.50752\nopinionNeutral                                                   0.53936\nopinionDisagree                                                  0.50752\neducAt least some college                                        0.36927\nreligModerate:opinionNeutral                                     0.86559\nreligFundamentalist:opinionNeutral                               0.97856\nreligModerate:opinionDisagree                                    0.70263\nreligFundamentalist:opinionDisagree                              0.72405\nreligModerate:educAt least some college                          0.55586\nreligFundamentalist:educAt least some college                    0.74366\nopinionNeutral:educAt least some college                         0.76574\nopinionDisagree:educAt least some college                        1.14150\nreligModerate:opinionNeutral:educAt least some college           1.19401\nreligFundamentalist:opinionNeutral:educAt least some college     1.41528\nreligModerate:opinionDisagree:educAt least some college          1.33669\nreligFundamentalist:opinionDisagree:educAt least some college    1.38224\n                                                              z value Pr(&gt;|z|)\n(Intercept)                                                     7.953 1.82e-15\nreligModerate                                                  -0.685   0.4931\nreligFundamentalist                                            -1.194   0.2324\nopinionNeutral                                                 -1.462   0.1438\nopinionDisagree                                                -1.194   0.2324\neducAt least some college                                       1.877   0.0605\nreligModerate:opinionNeutral                                   -0.222   0.8241\nreligFundamentalist:opinionNeutral                             -0.317   0.7513\nreligModerate:opinionDisagree                                   1.030   0.3029\nreligFundamentalist:opinionDisagree                             1.543   0.1229\nreligModerate:educAt least some college                         0.489   0.6247\nreligFundamentalist:educAt least some college                  -1.477   0.1396\nopinionNeutral:educAt least some college                       -1.197   0.2315\nopinionDisagree:educAt least some college                      -2.177   0.0295\nreligModerate:opinionNeutral:educAt least some college         -0.041   0.9674\nreligFundamentalist:opinionNeutral:educAt least some college    0.934   0.3503\nreligModerate:opinionDisagree:educAt least some college         0.697   0.4856\nreligFundamentalist:opinionDisagree:educAt least some college   2.160   0.0308\n                                                                 \n(Intercept)                                                   ***\nreligModerate                                                    \nreligFundamentalist                                              \nopinionNeutral                                                   \nopinionDisagree                                                  \neducAt least some college                                     .  \nreligModerate:opinionNeutral                                     \nreligFundamentalist:opinionNeutral                               \nreligModerate:opinionDisagree                                    \nreligFundamentalist:opinionDisagree                              \nreligModerate:educAt least some college                          \nreligFundamentalist:educAt least some college                    \nopinionNeutral:educAt least some college                         \nopinionDisagree:educAt least some college                     *  \nreligModerate:opinionNeutral:educAt least some college           \nreligFundamentalist:opinionNeutral:educAt least some college     \nreligModerate:opinionDisagree:educAt least some college          \nreligFundamentalist:opinionDisagree:educAt least some college *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance:  7.2362e+01  on 17  degrees of freedom\nResidual deviance: -2.1867e-21  on  0  degrees of freedom\nAIC: 100.5\n\nNumber of Fisher Scoring iterations: 3\n\n\nResidual DF are zero, the model is overfit\n\nconfint(m3)\n\nWaiting for profiling to be done...\n\n\n                                                                     2.5 %\n(Intercept)                                                    1.742480843\nreligModerate                                                 -1.267420510\nreligFundamentalist                                           -1.671871082\nopinionNeutral                                                -1.943435457\nopinionDisagree                                               -1.671871082\neducAt least some college                                     -0.009352458\nreligModerate:opinionNeutral                                  -1.993307908\nreligFundamentalist:opinionNeutral                            -2.450923140\nreligModerate:opinionDisagree                                 -0.637748305\nreligFundamentalist:opinionDisagree                           -0.271365102\nreligModerate:educAt least some college                       -0.812567305\nreligFundamentalist:educAt least some college                 -2.635442109\nopinionNeutral:educAt least some college                      -2.483332868\nopinionDisagree:educAt least some college                     -5.488683217\nreligModerate:opinionNeutral:educAt least some college        -2.420448446\nreligFundamentalist:opinionNeutral:educAt least some college  -1.503710058\nreligModerate:opinionDisagree:educAt least some college       -1.481979451\nreligFundamentalist:opinionDisagree:educAt least some college  0.502282533\n                                                                  97.5 %\n(Intercept)                                                    2.9358420\nreligModerate                                                  0.5859762\nreligFundamentalist                                            0.3601434\nopinionNeutral                                                 0.2228733\nopinionDisagree                                                0.3601434\neducAt least some college                                      1.4546181\nreligModerate:opinionNeutral                                   1.4884261\nreligFundamentalist:opinionNeutral                             1.5435972\nreligModerate:opinionDisagree                                  2.1457413\nreligFundamentalist:opinionDisagree                            2.5975239\nreligModerate:educAt least some college                        1.3871701\nreligFundamentalist:educAt least some college                  0.3397077\nopinionNeutral:educAt least some college                       0.5862740\nopinionDisagree:educAt least some college                     -0.5634587\nreligModerate:opinionNeutral:educAt least some college         2.3367740\nreligFundamentalist:opinionNeutral:educAt least some college   4.1835517\nreligModerate:opinionDisagree:educAt least some college        4.1546178\nreligFundamentalist:opinionDisagree:educAt least some college  6.2766234\n\n\nopinionDisagree:educAt least some college -2.48491 1.14150 -2.177 0.0295 *\nreligFundamentalist:opinionDisagree:educAt least some college 2.98568 1.38224 2.160 0.0308 *\nreligFundamentalist:opinionNeutral -2.450923140 1.5435972 religModerate:opinionDisagree -0.637748305 2.1457413 religFundamentalist:opinionDisagree -0.271365102 2.5975239 religModerate:educAt least some college -0.812567305 1.3871701 religFundamentalist:educAt least some college -2.635442109 0.3397077 opinionNeutral:educAt least some college -2.483332868 0.5862740 opinionDisagree:educAt least some college -5.488683217 -0.5634587 religModerate:opinionNeutral:educAt least some college -2.420448446 2.3367740 religFundamentalist:opinionNeutral:educAt least some college -1.503710058 4.1835517 religModerate:opinionDisagree:educAt least some college -1.481979451 4.1546178 religFundamentalist:opinionDisagree:educAt least some college 0.502282533 6.2766234\nIn the model with three way interactions, there were only two significant terms which may be associated with variation in the model. Those are some college/disagreement and fundamentalists/disagree/college. There are 9 interaction terms that appear to be independent of each other, shown above. It looks like college mostly reduced disagreement, except among fundamentalists. \n\nmarriage |&gt; ggplot() + \n  aes(x = educ, y = log(Freq), color = opinion, size = Freq) + \n  geom_point()  +\n  scale_x_discrete(guide = guide_axis(angle = 90)) + \n  facet_wrap(~relig)"
  },
  {
    "objectID": "z7_learnR.html",
    "href": "z7_learnR.html",
    "title": "7 Mixed Effects",
    "section": "",
    "text": "In this lab we’ll look at some simulated data that provide a nice demonstration of the interpretation problem presented by generalized linear mixed modeling. We’ll also go through another example of fitting a Generalized Linear Mixed Model (GLMM) and making sense of the output.\nTo start off, please load these libraries that you’ll need for this lab. Please note that robustbase is new, so you will likely have to install it first.\nlibrary(tidyverse)\nlibrary(robustbase) # contains data we'll use\nlibrary(ggplot2)\nlibrary(vcdExtra)\nlibrary(magrittr)\nlibrary(MASS)\nlibrary(lme4)     # access the mixed functions"
  },
  {
    "objectID": "z7_learnR.html#picking-the-random-effects",
    "href": "z7_learnR.html#picking-the-random-effects",
    "title": "7 Mixed Effects",
    "section": "Picking the Random Effects",
    "text": "Picking the Random Effects\nIn the model we just fit, we used a random intercepts model that just includes a random effect for patient. Specifically what this means that is the intercept term will be estimated differently for each patient.\nDepending on the particular problem, this may or may not be a reasonable way to think about the variation in the data. In the context of this epilepsy example, it could be that the different patients show different rates of change in their numbers of seizures – this would suggest that each patient have his or her own effect of visit. We can accomplish this by putting in a random effect for visit.\nNext we’ll fit a random intercepts and slopes model with Visit as the random slope. Again, this seems like a reasonable thing to do if we expect that some subjects will have a different rate of increase or decrease of number of seizures over time than other subjects.\n\nmod2 &lt;- glmer(Seizures ~ Trt + Base + Age + Visit + (1 + Visit|ID), family = poisson, data = epil_long)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00368596 (tol = 0.002, component 1)\n\n# oops this didn't converge --- try the initialization trick again:\n(init &lt;- getME(mod2, name = c(\"theta\", \"fixef\")))\n\n$theta\n      ID.(Intercept) ID.Visit.(Intercept)             ID.Visit \n          0.60038496          -0.06873505           0.12686483 \n\n$fixef\n (Intercept) Trtprogabide         Base          Age        Visit \n  0.61274912  -0.25315623   0.02736649   0.01545712  -0.05904358 \n\nmod2 &lt;- glmer(Seizures ~ Trt + Base + Age + Visit + (1 + Visit|ID), family = poisson, data = epil_long, start = init)\nsummary(mod2)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: Seizures ~ Trt + Base + Age + Visit + (1 + Visit | ID)\n   Data: epil_long\n\n     AIC      BIC   logLik deviance df.resid \n  1333.1   1360.8   -658.5   1317.1      228 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.9215 -0.7439 -0.0919  0.5534  6.3674 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr \n ID     (Intercept) 0.36044  0.6004        \n        Visit       0.02082  0.1443   -0.48\nNumber of obs: 236, groups:  ID, 59\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.61284    0.41536   1.475   0.1401    \nTrtprogabide -0.25314    0.15324  -1.652   0.0986 .  \nBase          0.02737    0.00278   9.843   &lt;2e-16 ***\nAge           0.01545    0.01273   1.214   0.2247    \nVisit        -0.05904    0.03252  -1.816   0.0694 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Trtprg Base   Age   \nTrtprogabid -0.290                     \nBase        -0.398 -0.003              \nAge         -0.923  0.122  0.198       \nVisit       -0.128 -0.018  0.009 -0.056\n\n\nThe estimated variance for the Visit random effect is pretty small (0.02), but the fixed effect estimate for Visit is pretty small too (-0.06), so that random effect variance may still be important to consider. Remember that we can compare the two models with the AIC and BIC functions:\n\nAIC(mod1, mod2)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nmod1\n6\n1349.228\n\n\nmod2\n8\n1333.084\n\n\n\n\n\nBIC(mod1, mod2)\n\n\n\n\n\n\ndf\nBIC\n\n\n\n\nmod1\n6\n1370.011\n\n\nmod2\n8\n1360.794\n\n\n\n\n\n\nBoth criteria indicate that the model with random slopes for Visit is somewhat preferred over the model with only random intercepts, though simplicity and that the AIC and BIC are not very different (i.e., each for mod1 vs mod2) would argue for using the model with only one random effect. As mentioned in last lab, in a real problem situation, we really want to think more carefully about what the model should be before fitting anything to the data. Choosing which model after fitting many models is a type of data snooping and should generally be avoided."
  },
  {
    "objectID": "z7_learnR.html#looking-at-the-results",
    "href": "z7_learnR.html#looking-at-the-results",
    "title": "7 Mixed Effects",
    "section": "Looking at the results",
    "text": "Looking at the results\nLet’s go back to the random intercept only model and interpret/understand the model output. This model is already a bit complex but is somewhat simpler than the random intercepts and random slopes model (mod2).\n\nsummary(mod1)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: Seizures ~ Trt + Base + Age + Visit + (1 | ID)\n   Data: epil_long\n\n     AIC      BIC   logLik deviance df.resid \n  1349.2   1370.0   -668.6   1337.2      230 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2867 -0.8240 -0.1332  0.5549  7.2848 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n ID     (Intercept) 0.2856   0.5344  \nNumber of obs: 236, groups:  ID, 59\n\nFixed effects:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.666765   0.410081   1.626  0.10396    \nTrtprogabide -0.261043   0.154119  -1.694  0.09031 .  \nBase          0.027235   0.002799   9.731  &lt; 2e-16 ***\nAge           0.014254   0.012548   1.136  0.25597    \nVisit        -0.058725   0.020178  -2.910  0.00361 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Trtprg Base   Age   \nTrtprogabid -0.289                     \nBase        -0.392 -0.006              \nAge         -0.931  0.114  0.190       \nVisit       -0.119  0.000  0.000  0.000\n\n\nBefore we comment on the model summary information, let’s perform some diagnostics to see if we feel like we have a good model to work with.\n\nResidual Diagnostics\nLet’s also take a look at some residual plots.\n\nepil_long$resid &lt;- residuals(mod1)\nepil_long$fits &lt;- exp(predict(mod1))\n\n# first some plots of the residuals vs. explanatory variables \nggplot(epil_long,aes(Visit,resid)) + geom_point() + facet_wrap(~Trt)\n\n\n\n\n\n\n\nggplot(epil_long,aes(Base,resid)) + geom_point() + facet_wrap(~Trt)\n\n\n\n\n\n\n\nggplot(epil_long,aes(Age,resid)) + geom_point() + facet_wrap(~Trt)\n\n\n\n\n\n\n\n# now a look at the normality of the random effects\nqqnorm(unlist((ranef(mod1)$ID)))\nqqline(unlist((ranef(mod1)$ID)))\n\n\n\n\n\n\n\n# finally, fitted values versus observations\nggplot(epil_long,aes(Seizures,fits)) + geom_point() + facet_wrap(~Trt) + geom_abline()\n\n\n\n\n\n\n\nggplot(epil_long,aes(log(Seizures+0.1),log(fits+0.1))) + geom_point() + facet_wrap(~Trt) + geom_abline()\n\n\n\n\n\n\n\n\nThere are a number of things to discuss based on these plots:\n\nIt looks like there’s evidence of some curvilinearity in the relationship between Visit and Seizures; the nature of that curvilinearity might be different for the two treatment groups (look at plot of resid versus Visit). You could add Visit2 term, the square of Visit, or you could revert Visit back to a factor variable.\nThere is what appears to be one large outlier in the placebo group. If we had access to the original researchers, we might have been able to find out about that unusual value.\nIt seems that the random effects are not strictly Normal, especially in the upper tail. This may be because we haven’t gotten the fixed effects part of the model correctly specified.\nThere are some zeroes among the Seizure values, and the model is not fitting those very well – we may need to think about a zero-inflated model and/or a model for over dispersion."
  },
  {
    "objectID": "z7_learnR.html#more-model-fitting",
    "href": "z7_learnR.html#more-model-fitting",
    "title": "7 Mixed Effects",
    "section": "More Model Fitting",
    "text": "More Model Fitting\nThere is a glmer.nb() function in the lme4 package, so we’ll try using that below. There are zero-inflated GLMM models, but they get rather complicated. We’ll leave it to you to explore those if you’re interested. Also, you might want to investigate what happens when you put terms in the model for the square of Visit and the interactions between Trt and the Visit variables (i.e., Visit and it’s square). Again, we’ll leave this to you for further exploration.\n\n# first, glmer.nb with the same form as above\nmod3 &lt;- glmer.nb(Seizures ~ Trt + Age + Base + Visit + (1|ID), data = epil_long)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.0181557 (tol = 0.002, component 1)\n\ninit &lt;- getME(mod3,name=c(\"theta\",\"fixef\"))\nmod3 &lt;- glmer.nb(Seizures ~ Trt + Age + Base + Visit + (1|ID), data = epil_long, start = init)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00295742 (tol = 0.002, component 1)\n\nsummary(mod3)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: Negative Binomial(7.4718)  ( log )\nFormula: Seizures ~ Trt + Age + Base + Visit + (1 | ID)\n   Data: epil_long\n\n     AIC      BIC   logLik deviance df.resid \n  1269.2   1293.4   -627.6   1255.2      229 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.9219 -0.6026 -0.1096  0.4506  3.6929 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n ID     (Intercept) 0.2522   0.5021  \nNumber of obs: 236, groups:  ID, 59\n\nFixed effects:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.662022   0.416600   1.589   0.1120    \nTrtprogabide -0.260516   0.154359  -1.688   0.0915 .  \nAge           0.014057   0.012567   1.119   0.2633    \nBase          0.027184   0.002806   9.687   &lt;2e-16 ***\nVisit        -0.052231   0.033086  -1.579   0.1144    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Trtprg Age    Base  \nTrtprogabid -0.286                     \nAge         -0.919  0.115              \nBase        -0.387 -0.006  0.189       \nVisit       -0.205  0.004  0.010  0.001\n\n\nLet’s compare this model to the Poisson GLMM above (mod1):\n\nAIC(mod1,mod3)\n\n\n\n\n\n\ndf\nAIC\n\n\n\n\nmod1\n6\n1349.228\n\n\nmod3\n7\n1269.198\n\n\n\n\n\nBIC(mod1,mod3)\n\n\n\n\n\n\ndf\nBIC\n\n\n\n\nmod1\n6\n1370.011\n\n\nmod3\n7\n1293.445\n\n\n\n\n\n\nOK, it seems like the negative binomial model is more appropriate here, so we’ll proceed with that. If you look at the summary information for mod3 it now appears that there’s still only marginal evidence in support of a treatment effect (p = 0.09). Next, we’ve replicated the residual diagnostics that we showed above, but for the mod3 object.\n\nepil_long$resid &lt;- residuals(mod3)\nepil_long$fits &lt;- exp(predict(mod3))\n\n# first some plots of the residuals vs. explanatory variables \nggplot(epil_long,aes(Visit,resid)) + geom_point() + facet_wrap(~Trt)\n\n\n\n\n\n\n\nggplot(epil_long,aes(Base,resid)) + geom_point() + facet_wrap(~Trt)\n\n\n\n\n\n\n\nggplot(epil_long,aes(Age,resid)) + geom_point() + facet_wrap(~Trt)\n\n\n\n\n\n\n\n# now a look at the normality of the random effects\nqqnorm(unlist((ranef(mod1)$ID)))\nqqline(unlist((ranef(mod1)$ID)))\n\n\n\n\n\n\n\n# finally, fitted values versus observations\nggplot(epil_long,aes(Seizures,fits)) + geom_point() + facet_wrap(~Trt) + geom_abline()\n\n\n\n\n\n\n\nggplot(epil_long,aes(log(Seizures+0.1),log(fits+0.1))) + geom_point() + facet_wrap(~Trt) + geom_abline()\n\n\n\n\n\n\n\n\nWe still see many of the same problems we noted above, but despite that we won’t proceed beyond this model for the purpose of this Lab. If this were the final model from which we were to report results, we might say something like:\n\nWe fit a generalized linear mixed model to the epilespy data, assuming that the number of seizures follows a negative binomial distribution and with a log link. The fixed effects are age, baseline number of seizures and visit, and the random effect is subject, to account for the repeated measurements for each subject. From this model, there is no evidence of an effect of the progabide treatment (p = 0.09), and the only factor that appears to be associated with the number of seizures post-treatment is the baseline number of seizures.\n\nOne final note. If our final model does provide evidence of a treatment effect, we can go ahead and report the p-value. It will be difficult to quantify the treatment effect, however, because you’ll have to do that in the context of conditioning on the random subjects."
  }
]